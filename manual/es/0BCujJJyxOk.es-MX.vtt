WEBVTT
Kind: captions
Language: es-MX

00:00:00.190 --> 00:00:02.430
Ahora mismo, en alguna guerra

00:00:02.430 --> 00:00:04.339
todavía en algunas partes

00:00:04.339 --> 00:00:08.820
hay un ser humano que está tomando la decisión
de disparar o no un arma de 

00:00:08.820 --> 00:00:10.569
cualquier tipo

00:00:10.569 --> 00:00:14.129
Si los robots fuesen desarrollados completamente

00:00:14.129 --> 00:00:18.550
y fuesen autónomos, los robots asesinos, 
como me gusta llamarlos, 

00:00:18.550 --> 00:00:22.990
podrían ser programados, enviados al campo de batalla
y ellos podrían tomar sus propias decisiones sobre

00:00:22.990 --> 00:00:27.050
cuándo y a quién atacar. Varios gobiernos,
incluso el de Estados Unidos están

00:00:27.050 --> 00:00:30.390
muy interesados en explorar esto,

00:00:30.390 --> 00:00:35.449
muy interesados en sacar a los 
soldados del campo de batalla

00:00:35.449 --> 00:00:36.560
y colocar máquinas en su lugar

00:00:36.560 --> 00:00:40.120
para disminuir las muertes. No hay
nada en la inteligencia artificial o

00:00:40.120 --> 00:00:41.210
en la robótica

00:00:41.210 --> 00:00:44.830
que pueda discriminar entre un
combatiente y un civil. 

00:00:44.830 --> 00:00:48.120
Sería imposible para un robot
discernir la diferencia entre

00:00:48.120 --> 00:00:49.830
una niña apuntando con un helado

00:00:49.830 --> 00:00:52.200
o alguien apuntando con un rifle

00:00:52.200 --> 00:00:54.180
Los robots asesinos aún no existen

00:00:54.180 --> 00:00:58.810
Lo que hay ahora son sistemas
que pueden tomar decisiones pero

00:00:58.810 --> 00:01:01.940
las mimas pueden ser desautorizadas por un humano

00:01:01.940 --> 00:01:05.280
Con robots completamente autónomos el 
factor humano queda completamente

00:01:05.280 --> 00:01:08.820
fuera. Existen precursores de estas tecnologías en
aire y tierra que son problemáticos

00:01:08.820 --> 00:01:12.430
y son una muestra de que el desarrollo de estas
tecnologías están entrando en un área

00:01:12.430 --> 00:01:18.350
peligrosa. Existe un arma llamada la X47B
producida por los Estados Unidos

00:01:18.350 --> 00:01:23.109
que está diseñada para autoabastecerse
de combustible y aterrizar en un portaaviones

00:01:23.109 --> 00:01:24.350
por sí sola.

00:01:24.350 --> 00:01:29.220
Pero también está diseñada para
cargar armas y si puede volar por sí sola

00:01:29.220 --> 00:01:33.380
como se espera que haga, también podría
identificar objetivos y lanzar sus armas

00:01:33.380 --> 00:01:38.020
sin interferencia humana. 

00:01:38.020 --> 00:01:41.200
El sistema de seguridad y vigilancia
de Samsumg, 

00:01:41.200 --> 00:01:44.520
que tiene la capacidad de detectar, localizar
y de 

00:01:44.520 --> 00:01:48.250
suprimir está diseñado para reemplazar

00:01:48.250 --> 00:01:50.350
guardias humanos, mejorando sus limitaciones. 

00:01:50.350 --> 00:01:53.490
En el campo ya hay un robot vigía usado por
Corea del Sur

00:01:53.490 --> 00:01:57.950
e Israel. El vigía opera identificando
a las personas que entran

00:01:57.950 --> 00:02:01.350
a determinada área. Luego pide permiso
al soldado en la base para disparar o no

00:02:01.350 --> 00:02:05.630
Si el soldado da el permiso
entonces la maquina dispara al individuo. 

00:02:05.630 --> 00:02:10.979
Nuestra preocupación es que ese permiso
no sea requerido siempre y que un robot dispare

00:02:10.979 --> 00:02:14.810
sin intervención humana. Si un robot se equivoca,
¿Quién tiene la culpa?

00:02:14.810 --> 00:02:16.430
Ciertamente no será el robot

00:02:16.430 --> 00:02:17.739
pero podría ser 

00:02:17.739 --> 00:02:21.150
el comandante que lo envió, 
el que lo manufacturó,

00:02:21.150 --> 00:02:24.139
o el programador que programó la misión. 

00:02:24.139 --> 00:02:28.099
El robot podría recibir un balazo en su
computadora y perder todo control. Asi que no

00:02:28.099 --> 00:02:31.529
hay manera de determinar quien es el responsable y eso
es muy importante en las leyes de 

00:02:31.529 --> 00:02:32.309
guerra. 

00:02:32.309 --> 00:02:35.249
Human Rights Watch está preocupada por

00:02:35.249 --> 00:02:41.600
los peligros de estos sistemas
completamente autónomos y creemos que una 

00:02:41.600 --> 00:02:43.059
prohibición preventiva y

00:02:43.059 --> 00:02:46.149
comprensiva del desarrollo 

00:02:46.149 --> 00:02:47.279
o producción de estos sistemas

00:02:47.279 --> 00:02:49.540
debe ser puesta en práctica

00:02:49.540 --> 00:02:50.799
inmediatamente. 

00:02:50.799 --> 00:02:54.869
Creo que la sociedad civil 
tiene el derecho y la obligación

00:02:54.869 --> 00:02:56.569
de tomar acciones cuando crean

00:02:56.569 --> 00:02:58.799
que un gobierno o ejército

00:02:58.799 --> 00:03:02.379
se están portando incorrectamente en su nombre. 

00:03:02.379 --> 00:03:04.459
Eso fue parte de lo que inspiró 

00:03:04.459 --> 00:03:09.549
la campaña para eliminar las minas anti-personales,
la coalición para detener el uso de bombas de racimo

00:03:09.549 --> 00:03:14.229
dos campañas que fueron exitosas en 
alcanzar los tratados que las regulan. 

00:03:14.229 --> 00:03:18.599
Se que podemos hacer lo mismo con
los robots asesinos

00:03:18.599 --> 00:03:22.000
antes de que entren al campo
de batalla.�

