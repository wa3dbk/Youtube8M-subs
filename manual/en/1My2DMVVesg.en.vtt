WEBVTT
Kind: captions
Language: en

00:00:01.121 --> 00:00:03.492
Follow us with InsideScience

00:00:03.492 --> 00:00:04.843
and take a peek over

00:00:04.843 --> 00:00:07.812
the shoulder of researchers.

00:00:07.812 --> 00:00:10.357
In this episode:

00:00:10.357 --> 00:00:14.090
"The analysis of human movement".

00:00:14.090 --> 00:00:16.617
Thorsten Stein and Andreas Fischer

00:00:16.617 --> 00:00:20.025
at the Karlsruher Institute of Technology

00:00:20.025 --> 00:00:21.914
analyse how humans move

00:00:21.914 --> 00:00:25.211
and transfer the results onto the robot.

00:00:25.211 --> 00:00:27.499
Welcome to the BioMotion Center,

00:00:27.499 --> 00:00:29.183
the biomechanics laboratory

00:00:29.183 --> 00:00:30.736
of the institute for sports and sports science.

00:00:30.736 --> 00:00:32.813
We are part of the

00:00:32.813 --> 00:00:35.221
"SFB 588: Humanoid Robots"

00:00:35.221 --> 00:00:35.791
and I will now

00:00:35.791 --> 00:00:36.660
explain to you

00:00:36.660 --> 00:00:37.373
what we do

00:00:37.373 --> 00:00:38.287
in this project.

00:00:38.287 --> 00:00:40.217
The goal of the SFB

00:00:40.217 --> 00:00:41.408
is to construct a machine,

00:00:41.408 --> 00:00:43.112
a humanoid robot

00:00:43.112 --> 00:00:44.662
that interacts with humans.

00:00:44.662 --> 00:00:46.505
We thought

00:00:46.505 --> 00:00:48.064
the first thing the machine

00:00:48.064 --> 00:00:48.892
has to know

00:00:48.892 --> 00:00:49.677
is which human

00:00:49.677 --> 00:00:52.623
the machine is dealing with.

00:00:52.623 --> 00:00:54.776
Movement research

00:00:54.776 --> 00:00:56.017
in sports shows us

00:00:56.017 --> 00:00:57.740
that every person

00:00:57.740 --> 00:00:59.514
has a very typical movement pattern,

00:00:59.514 --> 00:01:01.284
when he plays soccer

00:01:01.284 --> 00:01:03.021
or tennis for instance,

00:01:03.021 --> 00:01:04.929
and we want to use

00:01:04.929 --> 00:01:05.538
this knowledge

00:01:05.538 --> 00:01:07.892
to train algorithms,

00:01:07.892 --> 00:01:09.554
to develop methods

00:01:09.554 --> 00:01:10.835
of recognising humans

00:01:10.835 --> 00:01:12.428
on the basis

00:01:12.428 --> 00:01:13.588
of their movements.

00:01:13.588 --> 00:01:14.854
For this we have

00:01:14.854 --> 00:01:16.292
conducted an experiment.

00:01:16.292 --> 00:01:17.564
We had several test subjects

00:01:17.564 --> 00:01:18.796
run and walk

00:01:18.796 --> 00:01:19.906
on the treadmill

00:01:19.906 --> 00:01:20.966
with various speeds

00:01:20.966 --> 00:01:21.972
and inclinations.

00:01:21.972 --> 00:01:23.144
On the basis

00:01:23.144 --> 00:01:24.561
of this information

00:01:24.561 --> 00:01:26.048
we have developed models

00:01:26.048 --> 00:01:27.108
and we succeeded in recognising people

00:01:27.108 --> 00:01:28.770
on the basis of their

00:01:28.770 --> 00:01:31.772
walking and running patterns.

00:01:31.772 --> 00:01:32.796
Now we stick

00:01:32.796 --> 00:01:34.810
these reflective markers

00:01:34.810 --> 00:01:36.268
to the test subjects' joints

00:01:36.268 --> 00:01:39.140
and we will later try

00:01:39.140 --> 00:01:39.964
to reproduce the joint center

00:01:39.964 --> 00:01:41.132
with these markers.

00:01:41.132 --> 00:01:43.610
The markers are picked up

00:01:43.610 --> 00:01:44.964
by infrared videocameras

00:01:44.964 --> 00:01:46.474
that hang from the ceiling.

00:01:46.474 --> 00:01:48.956
The cameras emit infrared light

00:01:48.956 --> 00:01:49.754
and this light gets

00:01:49.754 --> 00:01:51.509
reflected by the markers.

00:01:51.509 --> 00:01:52.210
The markers are

00:01:52.210 --> 00:01:54.820
to predefined positions

00:01:54.820 --> 00:01:55.956
on the body.

00:01:55.956 --> 00:01:57.662
This is a predefined

00:01:57.662 --> 00:01:59.041
so-called marker set

00:01:59.041 --> 00:02:01.278
that was developed

00:02:01.278 --> 00:02:03.333
from past analyses.

00:02:03.333 --> 00:02:04.666
The markers are applied to each

00:02:04.666 --> 00:02:06.674
test subjects in the same way

00:02:06.674 --> 00:02:08.780
so that the system knows where

00:02:08.780 --> 00:02:12.642
the markers are on the person.

00:02:12.642 --> 00:02:13.980
Afterwards we can

00:02:13.980 --> 00:02:16.210
determine the joint center

00:02:16.210 --> 00:02:19.310
as well as the joint angles

00:02:19.310 --> 00:02:21.282
and speeds with the markers.

00:02:21.282 --> 00:02:25.482
Additionally to the camera system

00:02:25.482 --> 00:02:26.588
or the video data

00:02:26.588 --> 00:02:27.248
that we collect

00:02:27.248 --> 00:02:29.158
we are also able to

00:02:29.158 --> 00:02:30.712
capture muscle activity.

00:02:30.712 --> 00:02:33.332
To do this we attach electrodes to the muscles

00:02:33.332 --> 00:02:36.630
and derive the muscle activity

00:02:36.630 --> 00:02:38.530
over these electrodes and record it.

00:02:38.530 --> 00:02:39.838
The electrode is put

00:02:39.838 --> 00:02:41.496
over the highest point,

00:02:41.496 --> 00:02:43.247
the thickest part,

00:02:43.247 --> 00:02:45.252
the muscle belly,

00:02:45.252 --> 00:02:48.082
so that we can record many muscle fibres

00:02:48.082 --> 00:02:50.566
as possible with the electrode.

00:02:50.566 --> 00:02:56.514
Please contract again here.

00:02:56.514 --> 00:02:57.767
Because muscles can

00:02:57.767 --> 00:02:59.007
only contract

00:02:59.007 --> 00:03:01.381
and they expand on their own

00:03:01.381 --> 00:03:05.230
we always record

00:03:05.230 --> 00:03:06.649
agonist and antagonist,

00:03:06.649 --> 00:03:07.583
that means the muscle

00:03:07.583 --> 00:03:09.326
that does the bending

00:03:09.326 --> 00:03:10.151
and the muscle

00:03:10.151 --> 00:03:11.358
that does the stretching

00:03:11.358 --> 00:03:14.213
of the respective joint

00:03:14.213 --> 00:03:15.857
in order to be able to determine

00:03:15.857 --> 00:03:16.534
later if maybe muscles

00:03:16.534 --> 00:03:18.080
impeded one another,

00:03:18.080 --> 00:03:20.267
if the muscle activity when bending

00:03:20.267 --> 00:03:23.209
is also measurable in the stretcher

00:03:23.209 --> 00:03:25.519
and so to determine

00:03:25.519 --> 00:03:33.408
the interplay of the muscles.

00:03:33.408 --> 00:03:34.417
Here you can see the software

00:03:34.417 --> 00:03:35.143
that records

00:03:35.143 --> 00:03:36.520
the muscle activity.

00:03:36.520 --> 00:03:38.012
When the test subjects moves

00:03:38.012 --> 00:03:39.493
and the muscles contract,

00:03:39.493 --> 00:03:41.407
we can see here

00:03:41.407 --> 00:03:42.778
that the muscle of

00:03:42.778 --> 00:03:44.558
the gastrocnemius contracts.

00:03:44.558 --> 00:03:45.264
Here we see

00:03:45.264 --> 00:03:46.131
Bastian (Bastian Schittkowski)

00:03:46.131 --> 00:03:48.890
walking on the runway.

00:03:48.890 --> 00:03:50.480
We can clearly see

00:03:50.480 --> 00:03:51.262
how the marker

00:03:51.262 --> 00:03:52.360
reflects the infrared light,

00:03:52.360 --> 00:03:54.595
so that we can only see the markers.

00:03:54.595 --> 00:03:56.642
With these markers we then

00:03:56.642 --> 00:03:58.178
calculate the positions of the joints.

00:03:58.178 --> 00:04:00.379
If we now add the forces

00:04:00.379 --> 00:04:01.214
that are measured by

00:04:01.214 --> 00:04:02.932
these force measuring plates

00:04:02.932 --> 00:04:04.357
we can calculate

00:04:04.357 --> 00:04:05.432
the forces active

00:04:05.432 --> 00:04:06.981
in the joints.

00:04:06.981 --> 00:04:08.235
The study for person recognition

00:04:08.235 --> 00:04:09.847
was performed on a treadmill,

00:04:09.847 --> 00:04:10.683
as we see here,

00:04:10.683 --> 00:04:12.176
and the test subjects

00:04:12.176 --> 00:04:14.221
were equipped with several marker points

00:04:14.221 --> 00:04:15.845
and EMG electrodes

00:04:15.845 --> 00:04:17.446
and were recorded

00:04:17.446 --> 00:04:18.642
with cameras,

00:04:18.642 --> 00:04:20.425
as you can see up here.

00:04:20.425 --> 00:04:21.473
The study was performed

00:04:21.473 --> 00:04:23.156
in cooperation with the team of Professor Asfour,

00:04:23.156 --> 00:04:24.003
Professor Dillman

00:04:24.003 --> 00:04:25.074
and Professor Wank

00:04:25.074 --> 00:04:26.730
of the University TÃ¼bingen.

00:04:26.730 --> 00:04:28.916
Apart from the recognition of people

00:04:28.916 --> 00:04:30.488
on the basis of their movement patterns

00:04:30.488 --> 00:04:32.286
it is also important for

00:04:32.286 --> 00:04:33.119
human-machine interaction

00:04:33.119 --> 00:04:35.685
that the robot recognises

00:04:35.685 --> 00:04:36.688
the specific movement

00:04:36.688 --> 00:04:37.604
a human is making.

00:04:37.604 --> 00:04:38.561
This is prerequisite

00:04:38.561 --> 00:04:40.191
to adapting its movements

00:04:40.191 --> 00:04:41.288
to those of the human,

00:04:41.288 --> 00:04:43.411
to cooperate with the human.

00:04:43.411 --> 00:04:44.991
For this we have conducted

00:04:44.991 --> 00:04:46.058
an experiment with

00:04:46.058 --> 00:04:48.158
the team of Professor Schulz.

00:04:48.158 --> 00:04:50.638
In this we captured

00:04:50.638 --> 00:04:51.745
a variety of everyday movements

00:04:51.745 --> 00:04:53.707
with infrared cameras,

00:04:53.707 --> 00:04:54.684
different gripping movements,

00:04:54.684 --> 00:04:56.547
for instance gripping a bottle,

00:04:56.547 --> 00:04:57.917
or a glass, or different kitchen movements,

00:04:57.917 --> 00:05:00.400
like we would make when cooking.

00:05:00.400 --> 00:05:02.067
Mrs. Schultz has then

00:05:02.067 --> 00:05:03.489
developed algorithms on the basis

00:05:03.489 --> 00:05:05.765
of this movement analysis

00:05:05.765 --> 00:05:07.465
that recognise movements.

00:05:07.465 --> 00:05:08.811
Here we achieved

00:05:08.811 --> 00:05:10.567
very high recognition rates

00:05:10.567 --> 00:05:12.347
of over 90%,

00:05:12.347 --> 00:05:13.824
so we can recognise human movement

00:05:13.824 --> 00:05:15.639
with very high certainty.

00:05:15.639 --> 00:05:17.275
Apart from recognising people

00:05:17.275 --> 00:05:18.947
and movements the robot should

00:05:18.947 --> 00:05:21.409
also be able to move like a human.

00:05:21.409 --> 00:05:24.251
Understanding human movement

00:05:24.251 --> 00:05:25.956
is a subject for which

00:05:25.956 --> 00:05:28.998
we could probably request

00:05:28.998 --> 00:05:30.481
its own research center.

00:05:30.481 --> 00:05:32.311
We worked on the problem

00:05:32.311 --> 00:05:34.301
of how a human generates movement

00:05:34.301 --> 00:05:35.453
and tried to identify

00:05:35.453 --> 00:05:37.789
movement strategy with

00:05:37.789 --> 00:05:40.601
an analysis of movement

00:05:40.601 --> 00:05:41.841
This is necessary

00:05:41.841 --> 00:05:42.947
because a human can perform

00:05:42.947 --> 00:05:45.193
movements in many different ways.

00:05:45.193 --> 00:05:45.955
The question is

00:05:45.955 --> 00:05:47.505
how our brain chooses

00:05:47.505 --> 00:05:48.745
one of the possible movements.

00:05:48.745 --> 00:05:50.079
For instance,

00:05:50.079 --> 00:05:51.917
if we wanted to grip this can

00:05:51.917 --> 00:05:55.033
we can do that

00:05:55.033 --> 00:05:57.873
in very different ways

00:05:57.873 --> 00:06:01.126
and our brain chooses one movement

00:06:01.126 --> 00:06:02.515
on the basis of a mechanism

00:06:02.515 --> 00:06:03.689
and this mechanism is

00:06:03.689 --> 00:06:04.891
what we are trying to find.

00:06:04.891 --> 00:06:06.593
The new robot generation

00:06:06.593 --> 00:06:09.879
of the Collaborative Research Center AMAR IV

00:06:09.879 --> 00:06:10.564
has legs, that means

00:06:10.564 --> 00:06:12.382
that we gained bipedal walking and running

00:06:12.382 --> 00:06:14.306
as an additional subject.

00:06:14.306 --> 00:06:16.396
We study humans

00:06:16.396 --> 00:06:17.800
walking and running

00:06:17.800 --> 00:06:19.084
on different surfaces

00:06:19.084 --> 00:06:20.978
like the uneven surface

00:06:20.978 --> 00:06:21.858
we see here

00:06:21.858 --> 00:06:23.623
and on grass,

00:06:23.623 --> 00:06:24.848
like we see here

00:06:24.848 --> 00:06:26.190
and try to understand

00:06:26.190 --> 00:06:28.276
which strategies

00:06:28.276 --> 00:06:29.042
humans choose

00:06:29.042 --> 00:06:30.648
depending on the surface.

00:06:30.648 --> 00:06:33.426
Apart from that we conduct falling studies,

00:06:33.426 --> 00:06:35.018
that means we research

00:06:35.018 --> 00:06:36.462
which strategies are chosen by humans

00:06:36.462 --> 00:06:38.052
when they lose balance

00:06:38.052 --> 00:06:40.182
in order to regain it.

00:06:40.182 --> 00:06:44.012
The analysis of human movement

00:06:44.012 --> 00:06:46.074
is a builing block in

00:06:46.074 --> 00:06:47.710
the Collaborative Research Center "Humanoid Robots"

00:06:47.710 --> 00:06:49.404
and as we have just shown you

00:06:49.404 --> 00:06:51.876
it becomes important at a variety of points.

00:06:51.876 --> 00:06:53.653
I believe that in the future

00:06:53.653 --> 00:06:55.022
the information stream

00:06:55.022 --> 00:06:56.514
will go in the other direction,

00:06:56.514 --> 00:06:57.742
that through the construction

00:06:57.742 --> 00:07:00.135
of humanoid service robots we will

00:07:00.135 --> 00:07:02.020
be able to learn even more

00:07:02.020 --> 00:07:04.322
about human movement coordination.

00:07:04.322 --> 00:07:06.869
The KIT series InsideScience

00:07:06.869 --> 00:07:09.516
takes a peek over the shoulder

00:07:09.516 --> 00:07:10.395
of researchers of the Collaborative Research Center.

00:07:10.395 --> 00:07:12.691
Take a look at the other episodes

00:07:12.691 --> 00:07:14.607
and see how a robot is designed

00:07:14.607 --> 00:07:15.900
how it learns,

00:07:15.900 --> 00:07:17.473
how it interacts with humans

00:07:17.473 --> 00:07:20.784
and which social aspects have to be discussed.

