WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:01.436
Now the next question.

00:00:01.436 --> 00:00:02.901
When we build a high performance processor,

00:00:02.901 --> 00:00:06.406
which of course is going to be power-efficient, what are we optimizing for?

00:00:06.406 --> 00:00:08.808
One choice is minimizing latency.

00:00:08.808 --> 00:00:11.376
Latency is the amount of time to complete a task.

00:00:11.376 --> 00:00:14.312
We measure latency in units of time, like seconds.

00:00:14.312 --> 00:00:15.918
The other choice is throughput.

00:00:15.918 --> 00:00:19.030
Throughput is tasks completed per unit time.

00:00:19.030 --> 00:00:24.057
And we measure throughput in units as stuff per time, like jobs completed per hour.

00:00:24.057 --> 00:00:27.542
Unfortunately, these two goals are not necessarily aligned.

00:00:27.542 --> 00:00:30.163
In America, if you have a driver's license or a car,

00:00:30.163 --> 00:00:35.933
you've had the unfortunate opportunity to visit a government office called The Department of Motor Vehicles.

00:00:35.933 --> 00:00:38.972
If you're not from America, you've probably visited something like it.

00:00:38.972 --> 00:00:43.076
So in your head when when I say "DMV," substitute your favorite government office.

00:00:43.076 --> 00:00:46.046
When you visit the DMV, it's a very frustrating experience.

00:00:46.046 --> 00:00:50.883
You wait in lines a lot. This is not necessarily the fault of the DMC, though.

00:00:50.883 --> 00:00:55.589
The reason this happens is because your goals are not aligned with the DMV's goals.

00:00:55.589 --> 00:01:01.171
Your goal is to optimize for latency. You want to spend as little time in the DMV as possible.

00:01:01.171 --> 00:01:04.397
Instead, however, the DMV optimizes for throughput,

00:01:04.397 --> 00:01:07.432
specifically, the number of customers they serve per day.

00:01:07.432 --> 00:01:12.640
Consequently, these two people sitting behind the desk right here that work for DMV want long lines.

00:01:12.640 --> 00:01:15.678
Long lines mean their hard working employees are always busy

00:01:15.678 --> 00:01:19.036
because there's never a time they don't have a customer waiting.

00:01:19.036 --> 00:01:22.048
Traditional CPU's optimize for latency.

00:01:22.048 --> 00:01:26.018
They try to minimize the time elapsed of one particular task.

00:01:26.018 --> 00:01:28.822
GPUs instead chose to optimize for throughput.

00:01:28.822 --> 00:01:30.873
This is a fundamentally different approach

00:01:30.873 --> 00:01:33.673
and one that is aligned with technical trends in the computer industry.

00:01:33.673 --> 00:01:38.967
I'll refer you to a 2004 article by David Patterson called Latency Lags Bandwith.

00:01:38.967 --> 00:01:43.635
There are many, many applications where optimizing for throughput is the right approach.

00:01:43.635 --> 00:01:49.476
In computer graphics, for instance, we care more about pixels per second than the latency of any particular pixe l.

00:01:49.476 --> 00:01:52.931
We're willing to make the processing time of one pixel take twice as long

00:01:52.931 --> 00:01:55.114
if it means we get more pixel throughput.

00:01:55.114 --> 00:01:58.565
This class's homework focuses on image processing applications.

00:01:58.565 --> 00:02:00.815
Here, we also care more about throughput,

00:02:00.815 --> 00:02:05.824
which is more about pixels produced per second than the time for one individual pixel.

00:02:05.824 --> 00:02:08.993
Imaging processing applications are a perfect match for the GPU,

00:02:08.993 --> 00:02:12.897
which is why we're so excited about using them as a driving example in this course.

