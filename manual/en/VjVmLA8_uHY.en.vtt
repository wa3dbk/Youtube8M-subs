WEBVTT
Kind: captions
Language: en

00:00:00.058 --> 00:00:02.097
Gesture recognition is a novel approach to

00:00:02.097 --> 00:00:06.084
human-computer interaction that allows you to use your

00:00:06.084 --> 00:00:10.017
natural body movement to interact with computers.

00:00:10.017 --> 00:00:13.030
Because gestures are a form of human communication

00:00:13.030 --> 00:00:17.072
that is natural and expressive, they allow you to concentrate

00:00:17.072 --> 00:00:21.023
on the task itself, using what you already do, rather

00:00:21.023 --> 00:00:25.065
than having to learn new ways to interact. Our goal is to

00:00:25.065 --> 00:00:29.019
enable unmanned vehicles to recognize the aircraft

00:00:29.019 --> 00:00:33.011
handling gestures already made by deck crews. The

00:00:33.011 --> 00:00:37.037
aircraft handling gestures use both body posture and

00:00:37.037 --> 00:00:41.075
hand shapes; so it is important for our system to know

00:00:41.075 --> 00:00:46.021
both information. My research concentrates on developing

00:00:46.021 --> 00:00:49.067
a vision-based system that recognizes body and hand

00:00:49.067 --> 00:00:54.001
gestures from a continuous input stream. My system uses

00:00:54.001 --> 00:00:57.091
a single stereo camera to track body motion and hand

00:00:57.091 --> 00:01:01.060
shapes simultaneously and combines this information

00:01:01.060 --> 00:01:05.099
together to recognize body-and-hand gestures. We use

00:01:05.099 --> 00:01:10.026
machine learning to train the system with lots of examples

00:01:10.026 --> 00:01:15.041
allowing the system to learn how to recognize each gesture.

00:01:15.041 --> 00:01:19.087
There are four steps that our system takes to recognize

00:01:19.087 --> 00:01:22.087
gestures. First, from the input image obtained from a stereo

00:01:22.087 --> 00:01:26.016
camera, we calculate 3D images and remove the

00:01:26.016 --> 00:01:30.074
background. The second, our system estimates 3D body

00:01:30.074 --> 00:01:35.055
posture by fitting a skeletal body model to the input image.

00:01:35.055 --> 00:01:39.034
We extract various visual features, including 3D point cloud,

00:01:39.034 --> 00:01:42.068
contour lines and the history of motion. These features are

00:01:42.068 --> 00:01:47.048
computed both from the image and the skeletal model.

00:01:47.048 --> 00:01:50.034
Then, the two sets are features are compared allowing our

00:01:50.034 --> 00:01:54.019
program to come up with the most probable posture.

00:01:54.019 --> 00:01:57.061
The third [step], once we know the body posture, we know

00:01:57.061 --> 00:02:01.092
approximately where the hands are located. We search

00:02:01.092 --> 00:02:05.070
around each of the estimated wrist positions, compute

00:02:05.070 --> 00:02:09.096
visual features in that region and estimate the probability

00:02:09.096 --> 00:02:13.067
that what we see there is one of the known hand shapes

00:02:13.067 --> 00:02:18.026
used in aircraft handling. For example: palm open, closed,

00:02:18.026 --> 00:02:22.085
and thumb up and thumb down. As the last step, we

00:02:22.085 --> 00:02:26.047
combine the estimated body posture and hand shape to

00:02:26.047 --> 00:02:32.031
determine gestures. We collected twenty-four aircraft

00:02:32.031 --> 00:02:34.090
handling gestures from twenty people, giving us four

00:02:34.090 --> 00:02:38.036
hundred sample gestures to use to teach the system to

00:02:38.036 --> 00:02:42.051
recognize the gestures. We use a probabilistic graphical

00:02:42.051 --> 00:02:49.001
model called a Latent Dynamic Conditional Random Field.

00:02:49.001 --> 00:02:52.071
This model learns the distribution of the patterns of each

00:02:52.071 --> 00:02:55.003
gesture as well as the transition between gestures. We use

00:02:55.003 --> 00:02:59.022
this with a sliding window to recognize gestures continously

00:02:59.022 --> 00:03:04.001
and apply the multi-layered filtering technique we developed

00:03:04.001 --> 00:03:09.040
to make the recognition more robust. There is still a

00:03:09.040 --> 00:03:12.086
considerable amount of work to be done in the field of

00:03:12.086 --> 00:03:15.048
gesture recognition. Things we continue to work on include

00:03:15.048 --> 00:03:19.069
improving the reliability, adaptability to new gestures and

00:03:19.069 --> 00:03:23.095
developing appropriate feedback mechanisms; for example

00:03:23.095 --> 00:03:27.078
the system can say, "I get it" or, "I don't get it."

