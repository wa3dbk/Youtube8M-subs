WEBVTT
Kind: captions
Language: en

00:00:03.080 --> 00:00:07.100
One of the specific projects our lab is
working on is in the area of

00:00:07.100 --> 00:00:09.059
augmented reality visualization

00:00:09.059 --> 00:00:13.369
In the context of construction,
specifically we use augmented reality to 

00:00:13.369 --> 00:00:17.949
project on a plain construction site
what might it look like when

00:00:17.949 --> 00:00:22.070
actual resources or construction
machines come into the environment and

00:00:22.070 --> 00:00:24.910
start doing work that will occur in the future

00:00:24.910 --> 00:00:29.959
So this way by planning in the virtual environment,
we can learn from our mistakes

00:00:29.959 --> 00:00:34.239
and afford to make mistakes
without encumbering real resources

00:00:34.239 --> 00:00:38.000
or incurring actual costs, 
or endangering anybody's safety

00:00:38.000 --> 00:00:44.110
What augmented reality visualization implies
is the creation of a computer-generated world

00:00:44.110 --> 00:00:46.159
that blends together

00:00:46.159 --> 00:00:51.579
the real world and computer-generated images 
so that the composite image

00:00:51.579 --> 00:00:56.299
creates a persistent illusion that
real and virtual objects co-exist

00:00:56.299 --> 00:01:02.160
There are two possible ways to achieve this
One is called optical see-through augmented reality

00:01:02.160 --> 00:01:06.230
and the second is called 
video see-through augmented reality

00:01:06.230 --> 00:01:10.300
Video see-through augmented reality display
has taken a forecourt in the research community

00:01:10.300 --> 00:01:12.760
and that's what we have been pursuing

00:01:12.760 --> 00:01:16.790
So the main idea behind 
video see-through augmented reality is that

00:01:16.790 --> 00:01:22.000
a video camera, which is aligned with 
a user's physical line of sight, 

00:01:22.000 --> 00:01:23.980
it captures the view of the real world

00:01:23.980 --> 00:01:27.900
This video is then fed to a computer 
which is typically carried by the user

00:01:27.900 --> 00:01:30.280
It's a mobile computer

00:01:30.280 --> 00:01:34.910
The computer is told what virtual objects
are to be placed in the real environment,

00:01:34.910 --> 00:01:38.100
what is their location, and what is their behavior 

00:01:38.100 --> 00:01:43.420
The reason the computer knows is because 
we treat both the real and the virtual objects

00:01:43.420 --> 00:01:48.890
using the same coordinate frame 
used by the global positioning system, or GPS

00:01:48.890 --> 00:01:52.290
Then, with the algorithms that 
we have developed, the computer

00:01:52.290 --> 00:01:56.680
generates a composite image and that
image travels to head monitor display,

00:01:56.680 --> 00:02:01.760
which the user wears, to create a
augmented reality visualization

00:02:01.760 --> 00:02:08.689
So all this planning can be done ahead of time 
in the physical space of the job site using cam-models 

00:02:08.689 --> 00:02:14.529
The other aspect also is that using augmented reality, 
things that cannot be seen in the real world

00:02:14.529 --> 00:02:18.879
can be shown in an augmented world
And the example for that is the location of

00:02:18.879 --> 00:02:21.239
buried utilities

00:02:21.239 --> 00:02:26.130
In both these cases, the central idea 
is that cam-models of those 

00:02:26.130 --> 00:02:29.559
elements or those objects that are not

00:02:29.559 --> 00:02:32.149
physically present in the real world

00:02:32.149 --> 00:02:36.379
but you would like to create an illusion
that they are present in the real world,

00:02:36.379 --> 00:02:37.769
we need to have 3-D models of

