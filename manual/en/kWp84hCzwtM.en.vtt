WEBVTT
Kind: captions
Language: en

00:00:00.320 --> 00:00:01.470
Welcome to Zoho Sites

00:00:01.470 --> 00:00:06.800
Your Zoho Sites website can be optimized for
search engines

00:00:06.800 --> 00:00:11.490
I'll show you how, Go to Manage -- Settings

00:00:11.490 --> 00:00:15.969
Find SEO on the left hand side. Click.

00:00:15.969 --> 00:00:21.619
Here's where you give the inputs for optimization,
which could have a notable impact on how your

00:00:21.619 --> 00:00:24.380
website is treated by search engines

00:00:24.380 --> 00:00:29.570
You have to enter the title, the keywords
and the description

00:00:29.570 --> 00:00:33.180
Let's take a look at an example of a search
result

00:00:33.180 --> 00:00:36.800
Here's how a Google Search result appears
to users

00:00:36.800 --> 00:00:43.520
The three main areas of importance are the
title, the URL and the description

00:00:43.520 --> 00:00:45.820
Getting back to filling in the details..

00:00:45.820 --> 00:00:51.160
Against page you can choose whether you want
to optimize the entire site or a page on

00:00:51.160 --> 00:00:52.469
your website

00:00:52.469 --> 00:00:56.070
I'm going to select a page, Salads

00:00:56.070 --> 00:01:00.260
The title of your page is enclosed in title
tags

00:01:00.260 --> 00:01:06.619
A good title is one that is unique, readable
and the keyword should preferably appear within

00:01:06.619 --> 00:01:09.220
the first half of your title

00:01:09.220 --> 00:01:13.570
So once that is done, you move onto keywords

00:01:13.570 --> 00:01:19.600
A keyword is the term that people search for,
in order to arrive at a website.

00:01:19.600 --> 00:01:26.600
Each page has its own focus terms and the
title, description and URL of that page depend

00:01:26.650 --> 00:01:29.710
on, and contain keywords.

00:01:29.710 --> 00:01:36.140
The more specific your keywords are, the better.
So if my page is about Salads, here are the

00:01:36.140 --> 00:01:43.140
keywords I would use.. salads, salad recipes,
healthy salads

00:01:43.439 --> 00:01:50.439
Include variations of your keywords, avoid
wrong keywords, definitely avoid spam

00:01:52.579 --> 00:01:57.899
The next thing is description

00:01:57.899 --> 00:02:03.979
Description appears below the title on search
results, it should be short and should support

00:02:03.979 --> 00:02:05.640
the claim you've made in your title.

00:02:05.640 --> 00:02:11.840
A description should generally be about a
160 characters long

00:02:11.840 --> 00:02:16.050
Users are more likely to click on a search
result that contains the term they just searched

00:02:16.050 --> 00:02:17.690
for.

00:02:17.690 --> 00:02:24.690
That is why the title and description draw
attention if and when they contain keywords.

00:02:26.160 --> 00:02:33.160
Once you've given the title, the keywords
and the description, just hit save.

00:02:33.270 --> 00:02:34.940
The next thing we look at is crawlers

00:02:34.940 --> 00:02:41.050
Crawlers are the bots that crawl your website
and in Zoho Sites you have the option of giving

00:02:41.050 --> 00:02:43.000
robots.txt for crawlers

00:02:43.000 --> 00:02:49.220
So what is robots.txt or what exactly is the
role of a robots.txt

00:02:49.220 --> 00:02:52.620
Your robots.txt will contain two important
sections

00:02:52.620 --> 00:02:58.120
One is which bots are allowed to crawl the
website and the second is, which pages on

00:02:58.120 --> 00:03:01.070
the site should not be crawled

00:03:01.070 --> 00:03:03.250
It has two commands.

00:03:03.250 --> 00:03:06.400
One is user agent

00:03:06.400 --> 00:03:09.920
and the other is disallow

00:03:09.920 --> 00:03:15.040
User agent is to specify the bot to which
the instructions apply

00:03:15.040 --> 00:03:20.280
And Disallow is to specify the pages that
are restricted

00:03:20.280 --> 00:03:25.650
I'll show you a simple example

00:03:25.650 --> 00:03:31.280
The star that you see here against User Agent
implies that the following commands apply

00:03:31.280 --> 00:03:35.180
to every kind of bot that crawls the site

00:03:35.180 --> 00:03:41.400
And the slash against Disallow implies that
all sub-directories in the root folder are

00:03:41.400 --> 00:03:43.590
restricted to bots.

00:03:43.590 --> 00:03:49.730
That means, that no page in the root folder
should be crawled by any bot.

00:03:49.730 --> 00:03:51.090
To show you an example

00:03:51.090 --> 00:03:58.090
I'm on the home page of my website and the
URL reads cookingdelight.zohosites.com/Home.html

00:03:59.220 --> 00:04:06.220
Now, if I click on the salads page you'll
find that Home.html has been replaced by Salads.html

00:04:08.730 --> 00:04:15.730
The slash here that you see follows the dot
com and anything that follows the slash is

00:04:15.840 --> 00:04:18.090
the page or the page name

00:04:18.090 --> 00:04:23.070
If I want to Disallow any bot from crawling
the Salads page all I need to do is take it

00:04:23.070 --> 00:04:26.730
from here slash salads dot html(/salads.html)

00:04:26.730 --> 00:04:32.930
and type it or paste it against Disallow

00:04:32.930 --> 00:04:38.720
Here it reads now User Agent Star, Disallow
slash salads dot html

00:04:38.720 --> 00:04:45.220
and this means that no bot can crawl the salads
page on my website

00:04:45.220 --> 00:04:47.750
You can give multiple robots.txt entries

00:04:47.750 --> 00:04:52.630
So here's another example

00:04:52.630 --> 00:04:59.630
Here it means that I have disallowed the Google
bot from crawling my Contact page on my website

00:05:00.630 --> 00:05:02.230
Then you hit save

00:05:02.230 --> 00:05:04.410
That's all we have for elementary SEO

00:05:04.410 --> 00:05:05.230
Thanks for watching

