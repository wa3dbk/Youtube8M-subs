WEBVTT
Kind: captions
Language: en

00:00:02.940 --> 00:00:05.450 

my<00:00:03.660> name<00:00:03.840> is<00:00:03.990> jeff<00:00:04.170> cocina<00:00:04.590> pal<00:00:04.770> and<00:00:05.069> this

00:00:05.450 --> 00:00:05.460 
my name is jeff cocina pal and this

00:00:05.460 --> 00:00:07.010 
my name is jeff cocina pal and this
summer<00:00:05.700> I<00:00:05.790> was<00:00:06.029> an<00:00:06.210> Internet<00:00:06.630> Willow<00:00:06.870> Garage

00:00:07.010 --> 00:00:07.020 
summer I was an Internet Willow Garage

00:00:07.020 --> 00:00:10.430 
summer I was an Internet Willow Garage
and<00:00:07.529> in<00:00:08.340> my<00:00:08.460> project<00:00:09.000> I<00:00:09.180> explored<00:00:09.690> how<00:00:09.930> the<00:00:09.990> pr2

00:00:10.430 --> 00:00:10.440 
and in my project I explored how the pr2

00:00:10.440 --> 00:00:12.529 
and in my project I explored how the pr2
can<00:00:10.830> recognize<00:00:11.280> whether<00:00:11.580> an<00:00:11.760> object<00:00:11.910> is<00:00:12.270> full

00:00:12.529 --> 00:00:12.539 
can recognize whether an object is full

00:00:12.539 --> 00:00:14.390 
can recognize whether an object is full
or<00:00:12.719> not<00:00:12.930> and<00:00:13.230> this<00:00:13.920> is<00:00:14.039> particularly

00:00:14.390 --> 00:00:14.400 
or not and this is particularly

00:00:14.400 --> 00:00:17.930 
or not and this is particularly
important<00:00:15.389> because<00:00:16.100> vision<00:00:17.100> and<00:00:17.280> 3d<00:00:17.760> laser

00:00:17.930 --> 00:00:17.940 
important because vision and 3d laser

00:00:17.940 --> 00:00:19.850 
important because vision and 3d laser
scan<00:00:18.300> data<00:00:18.480> cannot<00:00:18.840> tell<00:00:19.080> whether<00:00:19.260> about<00:00:19.620> o<00:00:19.650> is

00:00:19.850 --> 00:00:19.860 
scan data cannot tell whether about o is

00:00:19.860 --> 00:00:21.770 
scan data cannot tell whether about o is
for<00:00:19.890> empty<00:00:20.550> in<00:00:20.730> the<00:00:20.820> robot<00:00:21.060> sometimes<00:00:21.570> needs

00:00:21.770 --> 00:00:21.780 
for empty in the robot sometimes needs

00:00:21.780 --> 00:00:26.030 
for empty in the robot sometimes needs
to<00:00:21.930> know<00:00:22.050> that<00:00:22.970> to<00:00:23.970> solve<00:00:24.210> the<00:00:24.300> problem<00:00:24.750> I<00:00:25.040> use

00:00:26.030 --> 00:00:26.040 
to know that to solve the problem I use

00:00:26.040 --> 00:00:27.830 
to know that to solve the problem I use
the<00:00:26.220> proprioceptive<00:00:26.820> sensory<00:00:27.330> modality

00:00:27.830 --> 00:00:27.840 
the proprioceptive sensory modality

00:00:27.840 --> 00:00:30.140 
the proprioceptive sensory modality
which<00:00:28.080> can<00:00:28.320> inform<00:00:28.710> the<00:00:28.830> robot<00:00:29.190> of<00:00:29.460> the<00:00:29.880> joint

00:00:30.140 --> 00:00:30.150 
which can inform the robot of the joint

00:00:30.150 --> 00:00:31.910 
which can inform the robot of the joint
efforts<00:00:30.539> that<00:00:30.660> it<00:00:30.750> feels<00:00:31.050> as<00:00:31.320> it<00:00:31.440> manipulates

00:00:31.910 --> 00:00:31.920 
efforts that it feels as it manipulates

00:00:31.920 --> 00:00:34.040 
efforts that it feels as it manipulates
an<00:00:32.070> object<00:00:32.460> the<00:00:32.940> approach<00:00:33.149> that<00:00:33.180> I<00:00:33.420> chose<00:00:33.690> was

00:00:34.040 --> 00:00:34.050 
an object the approach that I chose was

00:00:34.050 --> 00:00:35.989 
an object the approach that I chose was
a<00:00:34.079> data-driven<00:00:34.379> approach<00:00:34.710> in<00:00:35.190> which<00:00:35.219> I<00:00:35.640> led

00:00:35.989 --> 00:00:35.999 
a data-driven approach in which I led

00:00:35.999 --> 00:00:38.419 
a data-driven approach in which I led
the<00:00:36.149> robot<00:00:36.480> experience<00:00:37.199> for<00:00:37.440> a<00:00:37.469> foo<00:00:38.070> and<00:00:38.280> what

00:00:38.419 --> 00:00:38.429 
the robot experience for a foo and what

00:00:38.429 --> 00:00:40.700 
the robot experience for a foo and what
an<00:00:38.519> empty<00:00:38.670> objects<00:00:39.269> feel<00:00:39.449> like<00:00:39.690> and<00:00:40.350> monster

00:00:40.700 --> 00:00:40.710 
an empty objects feel like and monster

00:00:40.710 --> 00:00:42.410 
an empty objects feel like and monster
robot<00:00:40.859> had<00:00:41.100> that<00:00:41.249> experience<00:00:41.489> it<00:00:42.059> could<00:00:42.239> use

00:00:42.410 --> 00:00:42.420 
robot had that experience it could use

00:00:42.420 --> 00:00:44.209 
robot had that experience it could use
it<00:00:42.569> to<00:00:42.600> classify<00:00:43.109> novel<00:00:43.469> bottles<00:00:43.859> it's<00:00:44.069> either

00:00:44.209 --> 00:00:44.219 
it to classify novel bottles it's either

00:00:44.219 --> 00:00:46.970 
it to classify novel bottles it's either
for<00:00:44.579> auntie<00:00:45.230> after<00:00:46.230> the<00:00:46.350> robot<00:00:46.620> learned<00:00:46.890> the

00:00:46.970 --> 00:00:46.980 
for auntie after the robot learned the

00:00:46.980 --> 00:00:50.059 
for auntie after the robot learned the
motto<00:00:47.190> I<00:00:47.899> developed<00:00:48.899> a<00:00:49.050> sorting<00:00:49.499> application

00:00:50.059 --> 00:00:50.069 
motto I developed a sorting application

00:00:50.069 --> 00:00:52.389 
motto I developed a sorting application
task<00:00:50.309> in<00:00:50.699> which<00:00:50.760> the<00:00:51.359> robot<00:00:51.659> was<00:00:51.870> tasked<00:00:52.109> to

00:00:52.389 --> 00:00:52.399 
task in which the robot was tasked to

00:00:52.399 --> 00:00:54.950 
task in which the robot was tasked to
sort<00:00:53.399> bottles<00:00:53.789> based<00:00:54.089> on<00:00:54.269> whether<00:00:54.449> they<00:00:54.659> for

00:00:54.950 --> 00:00:54.960 
sort bottles based on whether they for

00:00:54.960 --> 00:00:57.649 
sort bottles based on whether they for
empty<00:00:55.440> the<00:00:56.280> robot<00:00:56.550> picks<00:00:56.789> objects<00:00:57.359> from<00:00:57.449> one

00:00:57.649 --> 00:00:57.659 
empty the robot picks objects from one

00:00:57.659 --> 00:00:59.209 
empty the robot picks objects from one
side<00:00:57.870> of<00:00:57.899> the<00:00:58.079> table<00:00:58.289> and<00:00:58.620> moves<00:00:58.859> him<00:00:58.979> to<00:00:59.010> the

00:00:59.209 --> 00:00:59.219 
side of the table and moves him to the

00:00:59.219 --> 00:01:00.829 
side of the table and moves him to the
other<00:00:59.339> if<00:00:59.579> they're<00:00:59.729> fool<00:00:59.999> or<00:01:00.269> puts<00:01:00.600> him<00:01:00.719> in<00:01:00.809> the

00:01:00.829 --> 00:01:00.839 
other if they're fool or puts him in the

00:01:00.839 --> 00:01:04.070 
other if they're fool or puts him in the
trash<00:01:01.109> can<00:01:01.139> either<00:01:01.559> empty<00:01:02.389> in<00:01:03.389> this<00:01:03.569> demo<00:01:03.870> the

00:01:04.070 --> 00:01:04.080 
trash can either empty in this demo the

00:01:04.080 --> 00:01:05.750 
trash can either empty in this demo the
robot<00:01:04.379> used<00:01:04.710> the<00:01:04.890> currently<00:01:05.280> existing

00:01:05.750 --> 00:01:05.760 
robot used the currently existing

00:01:05.760 --> 00:01:07.940 
robot used the currently existing
grasping<00:01:06.240> pipeline<00:01:06.720> to<00:01:07.020> grasp<00:01:07.260> the<00:01:07.500> object

00:01:07.940 --> 00:01:07.950 
grasping pipeline to grasp the object

00:01:07.950 --> 00:01:10.520 
grasping pipeline to grasp the object
and<00:01:08.100> lift<00:01:08.670> it<00:01:08.820> in<00:01:08.910> space<00:01:09.210> and<00:01:09.930> once<00:01:10.140> the<00:01:10.260> robot

00:01:10.520 --> 00:01:10.530 
and lift it in space and once the robot

00:01:10.530 --> 00:01:12.140 
and lift it in space and once the robot
had<00:01:10.680> done<00:01:10.860> that<00:01:11.040> it<00:01:11.250> could<00:01:11.490> measure<00:01:11.880> the

00:01:12.140 --> 00:01:12.150 
had done that it could measure the

00:01:12.150 --> 00:01:14.000 
had done that it could measure the
effort<00:01:12.510> it<00:01:12.720> was<00:01:12.870> experiencing<00:01:13.560> and<00:01:13.770> used

00:01:14.000 --> 00:01:14.010 
effort it was experiencing and used

00:01:14.010 --> 00:01:15.800 
effort it was experiencing and used
those<00:01:14.190> efforts<00:01:14.640> to<00:01:14.940> decide<00:01:15.450> whether<00:01:15.660> the

00:01:15.800 --> 00:01:15.810 
those efforts to decide whether the

00:01:15.810 --> 00:01:18.440 
those efforts to decide whether the
object<00:01:15.840> is<00:01:16.290> for<00:01:16.560> auntie<00:01:17.010> if<00:01:17.910> the<00:01:18.030> object<00:01:18.360> was

00:01:18.440 --> 00:01:18.450 
object is for auntie if the object was

00:01:18.450 --> 00:01:20.030 
object is for auntie if the object was
empty<00:01:18.840> the<00:01:18.960> robot<00:01:19.200> place<00:01:19.410> it<00:01:19.590> in<00:01:19.710> the<00:01:19.740> trash

00:01:20.030 --> 00:01:20.040 
empty the robot place it in the trash

00:01:20.040 --> 00:01:21.710 
empty the robot place it in the trash
can<00:01:20.070> and<00:01:20.550> if<00:01:20.670> it<00:01:20.760> moves<00:01:20.940> forward<00:01:21.180> moved<00:01:21.540> it<00:01:21.630> to

00:01:21.710 --> 00:01:21.720 
can and if it moves forward moved it to

00:01:21.720 --> 00:01:23.960 
can and if it moves forward moved it to
the<00:01:21.750> other<00:01:21.930> side<00:01:21.990> of<00:01:22.200> the<00:01:22.320> table<00:01:22.560> and<00:01:22.940> after<00:01:23.940> a

00:01:23.960 --> 00:01:23.970 
the other side of the table and after a

00:01:23.970 --> 00:01:25.880 
the other side of the table and after a
series<00:01:24.330> of<00:01:24.480> tests<00:01:24.780> we<00:01:25.080> found<00:01:25.320> that<00:01:25.440> the<00:01:25.590> robot

00:01:25.880 --> 00:01:25.890 
series of tests we found that the robot

00:01:25.890 --> 00:01:27.590 
series of tests we found that the robot
was<00:01:26.070> able<00:01:26.370> to<00:01:26.520> solve<00:01:26.940> the<00:01:27.090> problem<00:01:27.480> with<00:01:27.570> a

00:01:27.590 --> 00:01:27.600 
was able to solve the problem with a

00:01:27.600 --> 00:01:29.360 
was able to solve the problem with a
hundred<00:01:27.900> percent<00:01:28.020> success<00:01:28.380> rate<00:01:28.710> so<00:01:29.040> it<00:01:29.130> shows

00:01:29.360 --> 00:01:29.370 
hundred percent success rate so it shows

00:01:29.370 --> 00:01:31.250 
hundred percent success rate so it shows
that<00:01:29.580> proprioceptive<00:01:30.030> input<00:01:30.570> can<00:01:30.960> be<00:01:30.990> very

00:01:31.250 --> 00:01:31.260 
that proprioceptive input can be very

00:01:31.260 --> 00:01:32.720 
that proprioceptive input can be very
important<00:01:31.740> in<00:01:31.860> terms<00:01:31.980> of<00:01:32.220> detecting

00:01:32.720 --> 00:01:32.730 
important in terms of detecting

00:01:32.730 --> 00:01:34.400 
important in terms of detecting
properties<00:01:33.180> of<00:01:33.270> objects<00:01:33.660> which<00:01:33.840> cannot<00:01:34.140> be<00:01:34.350> in

00:01:34.400 --> 00:01:34.410 
properties of objects which cannot be in

00:01:34.410 --> 00:01:36.650 
properties of objects which cannot be in
first<00:01:34.650> revision<00:01:35.040> for<00:01:35.640> future<00:01:35.970> work<00:01:36.150> a<00:01:36.330> plan<00:01:36.540> to

00:01:36.650 --> 00:01:36.660 
first revision for future work a plan to

00:01:36.660 --> 00:01:38.180 
first revision for future work a plan to
extend<00:01:36.840> this<00:01:37.080> model<00:01:37.470> to<00:01:37.590> other<00:01:37.770> types<00:01:38.070> of

00:01:38.180 --> 00:01:38.190 
extend this model to other types of

00:01:38.190 --> 00:01:40.160 
extend this model to other types of
tasks<00:01:38.430> for<00:01:38.880> example<00:01:39.330> if<00:01:39.420> there's<00:01:39.600> a<00:01:39.690> box<00:01:39.960> that

00:01:40.160 --> 00:01:40.170 
tasks for example if there's a box that

00:01:40.170 --> 00:01:42.380 
tasks for example if there's a box that
may<00:01:40.470> be<00:01:40.530> for<00:01:40.860> maybe<00:01:41.130> empty<00:01:41.580> the<00:01:41.760> robot<00:01:42.060> can

00:01:42.380 --> 00:01:42.390 
may be for maybe empty the robot can

00:01:42.390 --> 00:01:44.090 
may be for maybe empty the robot can
perhaps<00:01:42.600> push<00:01:42.990> it<00:01:43.170> or<00:01:43.290> slider<00:01:43.470> on<00:01:43.590> the<00:01:43.740> table

00:01:44.090 --> 00:01:44.100 
perhaps push it or slider on the table

00:01:44.100 --> 00:01:46.190 
perhaps push it or slider on the table
very<00:01:44.280> gently<00:01:44.610> to<00:01:44.790> find<00:01:45.000> out<00:01:45.180> if<00:01:45.330> it's<00:01:45.450> what<00:01:46.080> its

00:01:46.190 --> 00:01:46.200 
very gently to find out if it's what its

00:01:46.200 --> 00:01:48.800 
very gently to find out if it's what its
internal<00:01:46.620> state<00:01:46.830> is<00:01:47.040> also<00:01:47.910> I've<00:01:48.360> been<00:01:48.510> working

00:01:48.800 --> 00:01:48.810 
internal state is also I've been working

00:01:48.810 --> 00:01:50.840 
internal state is also I've been working
with<00:01:48.840> auditory<00:01:49.620> picture<00:01:50.190> processing<00:01:50.400> to

00:01:50.840 --> 00:01:50.850 
with auditory picture processing to

00:01:50.850 --> 00:01:52.880 
with auditory picture processing to
detect<00:01:51.210> whether<00:01:51.660> an<00:01:51.840> object<00:01:51.960> is<00:01:52.260> for<00:01:52.500> energy

00:01:52.880 --> 00:01:52.890 
detect whether an object is for energy

00:01:52.890 --> 00:01:54.500 
detect whether an object is for energy
based<00:01:53.100> on<00:01:53.280> how<00:01:53.400> it<00:01:53.550> sounds<00:01:53.910> like<00:01:53.970> when<00:01:54.390> its

00:01:54.500 --> 00:01:54.510 
based on how it sounds like when its

00:01:54.510 --> 00:01:56.660 
based on how it sounds like when its
grasper<00:01:55.470> when<00:01:55.590> it's<00:01:55.740> hit<00:01:55.950> when<00:01:56.310> it<00:01:56.400> hits<00:01:56.550> the

00:01:56.660 --> 00:01:56.670 
grasper when it's hit when it hits the

00:01:56.670 --> 00:01:59.360 
grasper when it's hit when it hits the
table<00:01:56.820> and<00:01:57.860> finally<00:01:58.860> I<00:01:58.890> want<00:01:59.040> to<00:01:59.159> integrate

00:01:59.360 --> 00:01:59.370 
table and finally I want to integrate

00:01:59.370 --> 00:02:01.280 
table and finally I want to integrate
those<00:01:59.730> two<00:01:59.970> sensory<00:02:00.330> modalities<00:02:00.870> so<00:02:01.050> that<00:02:01.200> the

00:02:01.280 --> 00:02:01.290 
those two sensory modalities so that the

00:02:01.290 --> 00:02:03.230 
those two sensory modalities so that the
robot<00:02:01.560> has<00:02:01.710> a<00:02:01.770> motor<00:02:02.310> model<00:02:02.520> representation

00:02:03.230 --> 00:02:03.240 
robot has a motor model representation

00:02:03.240 --> 00:02:05.000 
robot has a motor model representation
of<00:02:03.360> the<00:02:03.450> objects<00:02:03.990> rather<00:02:04.170> than<00:02:04.290> just<00:02:04.590> rely<00:02:04.890> on

00:02:05.000 --> 00:02:05.010 
of the objects rather than just rely on

00:02:05.010 --> 00:02:13.740 
of the objects rather than just rely on
a<00:02:05.070> single<00:02:05.100> sensory<00:02:05.820> modality

00:02:13.740 --> 00:02:13.750 

00:02:13.750 --> 00:02:15.810 

you

