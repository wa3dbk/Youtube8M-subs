WEBVTT
Kind: captions
Language: en

00:00:00.030 --> 00:00:02.240 

augmented<00:00:00.690> reality<00:00:00.719> is<00:00:01.380> the<00:00:01.589> enhancement<00:00:02.010> of

00:00:02.240 --> 00:00:02.250 
augmented reality is the enhancement of

00:00:02.250 --> 00:00:03.830 
augmented reality is the enhancement of
a<00:00:02.370> view<00:00:02.580> of<00:00:02.669> the<00:00:02.790> real<00:00:03.000> world<00:00:03.300> using

00:00:03.830 --> 00:00:03.840 
a view of the real world using

00:00:03.840 --> 00:00:06.230 
a view of the real world using
computer-generated<00:00:04.560> overlays<00:00:05.310> of<00:00:05.520> graphics

00:00:06.230 --> 00:00:06.240 
computer-generated overlays of graphics

00:00:06.240 --> 00:00:11.270 
computer-generated overlays of graphics
text<00:00:07.220> videos<00:00:08.220> or<00:00:08.550> sounds<00:00:09.360> in<00:00:09.950> this<00:00:10.950> video

00:00:11.270 --> 00:00:11.280 
text videos or sounds in this video

00:00:11.280 --> 00:00:13.310 
text videos or sounds in this video
we'll<00:00:11.670> take<00:00:11.849> a<00:00:11.910> webcam<00:00:12.420> and<00:00:12.690> use<00:00:12.870> object

00:00:13.310 --> 00:00:13.320 
we'll take a webcam and use object

00:00:13.320 --> 00:00:15.259 
we'll take a webcam and use object
recognition<00:00:13.469> and<00:00:14.009> tracking<00:00:14.429> to<00:00:14.820> develop<00:00:15.179> a

00:00:15.259 --> 00:00:15.269 
recognition and tracking to develop a

00:00:15.269 --> 00:00:17.650 
recognition and tracking to develop a
simple<00:00:15.480> augmented<00:00:16.020> reality<00:00:16.049> application

00:00:17.650 --> 00:00:17.660 
simple augmented reality application

00:00:17.660 --> 00:00:20.450 
simple augmented reality application
here<00:00:18.660> the<00:00:18.930> webcam<00:00:19.320> stream<00:00:19.590> is<00:00:19.740> augmented<00:00:20.279> by

00:00:20.450 --> 00:00:20.460 
here the webcam stream is augmented by

00:00:20.460 --> 00:00:22.340 
here the webcam stream is augmented by
recognizing<00:00:21.270> the<00:00:21.300> mathworks<00:00:21.779> magnet<00:00:22.199> on<00:00:22.320> the

00:00:22.340 --> 00:00:22.350 
recognizing the mathworks magnet on the

00:00:22.350 --> 00:00:24.800 
recognizing the mathworks magnet on the
desk<00:00:22.680> and<00:00:22.920> replacing<00:00:23.910> it<00:00:24.000> with<00:00:24.060> a<00:00:24.240> video<00:00:24.539> about

00:00:24.800 --> 00:00:24.810 
desk and replacing it with a video about

00:00:24.810 --> 00:00:26.050 
desk and replacing it with a video about
life<00:00:24.990> at<00:00:25.140> MathWorks

00:00:26.050 --> 00:00:26.060 
life at MathWorks

00:00:26.060 --> 00:00:28.820 
life at MathWorks
augmented<00:00:27.060> reality<00:00:27.140> applications<00:00:28.140> often<00:00:28.439> use

00:00:28.820 --> 00:00:28.830 
augmented reality applications often use

00:00:28.830 --> 00:00:30.830 
augmented reality applications often use
object<00:00:29.310> detection<00:00:29.609> and<00:00:29.970> recognition<00:00:30.240> to

00:00:30.830 --> 00:00:30.840 
object detection and recognition to

00:00:30.840 --> 00:00:32.900 
object detection and recognition to
determine<00:00:31.710> what<00:00:31.890> relevant<00:00:32.309> information

00:00:32.900 --> 00:00:32.910 
determine what relevant information

00:00:32.910 --> 00:00:35.750 
determine what relevant information
needs<00:00:33.480> to<00:00:33.660> be<00:00:33.750> added<00:00:33.989> to<00:00:34.020> the<00:00:34.170> display<00:00:34.730> here

00:00:35.750 --> 00:00:35.760 
needs to be added to the display here

00:00:35.760 --> 00:00:37.700 
needs to be added to the display here
recognizing<00:00:36.570> the<00:00:36.690> MathWorks<00:00:37.079> magnet<00:00:37.500> also

00:00:37.700 --> 00:00:37.710 
recognizing the MathWorks magnet also

00:00:37.710 --> 00:00:39.350 
recognizing the MathWorks magnet also
locates<00:00:38.309> the<00:00:38.460> correct<00:00:38.790> position<00:00:39.210> on<00:00:39.300> the

00:00:39.350 --> 00:00:39.360 
locates the correct position on the

00:00:39.360 --> 00:00:41.560 
locates the correct position on the
screen<00:00:39.719> for<00:00:40.050> playing<00:00:40.290> a<00:00:40.379> matching<00:00:40.710> video

00:00:41.560 --> 00:00:41.570 
screen for playing a matching video

00:00:41.570 --> 00:00:44.090 
screen for playing a matching video
object<00:00:42.570> tracking<00:00:43.020> is<00:00:43.260> also<00:00:43.590> an<00:00:43.710> important

00:00:44.090 --> 00:00:44.100 
object tracking is also an important

00:00:44.100 --> 00:00:46.100 
object tracking is also an important
part<00:00:44.280> of<00:00:44.340> augmented<00:00:44.789> reality<00:00:44.840> since<00:00:45.840> it<00:00:45.989> can

00:00:46.100 --> 00:00:46.110 
part of augmented reality since it can

00:00:46.110 --> 00:00:47.840 
part of augmented reality since it can
be<00:00:46.230> faster<00:00:46.590> to<00:00:46.620> track<00:00:46.920> an<00:00:47.039> object's<00:00:47.430> movement

00:00:47.840 --> 00:00:47.850 
be faster to track an object's movement

00:00:47.850 --> 00:00:50.299 
be faster to track an object's movement
than<00:00:48.120> to<00:00:48.270> keep<00:00:48.420> reading<00:00:48.570> it<00:00:49.079> you<00:00:49.860> can<00:00:50.010> see<00:00:50.160> that

00:00:50.299 --> 00:00:50.309 
than to keep reading it you can see that

00:00:50.309 --> 00:00:52.010 
than to keep reading it you can see that
object<00:00:50.489> tracking<00:00:50.910> helps<00:00:51.360> keep<00:00:51.510> the<00:00:51.629> video<00:00:51.870> in

00:00:52.010 --> 00:00:52.020 
object tracking helps keep the video in

00:00:52.020 --> 00:00:54.139 
object tracking helps keep the video in
the<00:00:52.079> magnets<00:00:52.410> location<00:00:52.920> even<00:00:53.610> as<00:00:53.730> the<00:00:53.820> webcam

00:00:54.139 --> 00:00:54.149 
the magnets location even as the webcam

00:00:54.149 --> 00:00:57.170 
the magnets location even as the webcam
is<00:00:54.270> moved<00:00:54.449> around<00:00:55.399> this<00:00:56.399> application<00:00:57.090> of

00:00:57.170 --> 00:00:57.180 
is moved around this application of

00:00:57.180 --> 00:00:58.880 
is moved around this application of
augmented<00:00:57.660> reality<00:00:57.690> is<00:00:58.289> useful<00:00:58.800> for

00:00:58.880 --> 00:00:58.890 
augmented reality is useful for

00:00:58.890 --> 00:01:01.369 
augmented reality is useful for
advertising<00:00:59.430> and<00:00:59.760> video<00:01:00.329> editing<00:01:00.719> effects<00:01:01.050> in

00:01:01.369 --> 00:01:01.379 
advertising and video editing effects in

00:01:01.379 --> 00:01:04.399 
advertising and video editing effects in
entertainment<00:01:01.949> industries<00:01:03.110> now<00:01:04.110> we'll<00:01:04.290> take

00:01:04.399 --> 00:01:04.409 
entertainment industries now we'll take

00:01:04.409 --> 00:01:06.260 
entertainment industries now we'll take
a<00:01:04.470> look<00:01:04.589> at<00:01:04.979> how<00:01:05.159> this<00:01:05.280> particular<00:01:05.610> augmented

00:01:06.260 --> 00:01:06.270 
a look at how this particular augmented

00:01:06.270 --> 00:01:08.300 
a look at how this particular augmented
reality<00:01:06.320> application<00:01:07.320> uses<00:01:07.920> object

00:01:08.300 --> 00:01:08.310 
reality application uses object

00:01:08.310 --> 00:01:11.630 
reality application uses object
recognition<00:01:08.460> and<00:01:09.030> tracking<00:01:10.010> first<00:01:11.010> we<00:01:11.460> need

00:01:11.630 --> 00:01:11.640 
recognition and tracking first we need

00:01:11.640 --> 00:01:13.100 
recognition and tracking first we need
to<00:01:11.729> read<00:01:11.909> in<00:01:12.060> images<00:01:12.450> of<00:01:12.600> our<00:01:12.720> reference

00:01:13.100 --> 00:01:13.110 
to read in images of our reference

00:01:13.110 --> 00:01:14.800 
to read in images of our reference
objects<00:01:13.650> and<00:01:13.799> store<00:01:14.189> their<00:01:14.369> features

00:01:14.800 --> 00:01:14.810 
objects and store their features

00:01:14.810 --> 00:01:17.330 
objects and store their features
features<00:01:15.810> are<00:01:15.960> areas<00:01:16.380> or<00:01:16.619> structures<00:01:17.100> within

00:01:17.330 --> 00:01:17.340 
features are areas or structures within

00:01:17.340 --> 00:01:18.890 
features are areas or structures within
images<00:01:17.670> that<00:01:18.299> provide<00:01:18.630> key<00:01:18.869> information

00:01:18.890 --> 00:01:18.900 
images that provide key information

00:01:18.900 --> 00:01:22.130 
images that provide key information
about<00:01:19.650> the<00:01:19.890> underlying<00:01:20.250> object<00:01:20.930> these<00:01:21.930> are

00:01:22.130 --> 00:01:22.140 
about the underlying object these are

00:01:22.140 --> 00:01:25.700 
about the underlying object these are
often<00:01:22.320> corners<00:01:22.979> regions<00:01:23.880> or<00:01:24.119> blobs<00:01:24.840> that<00:01:25.439> vary

00:01:25.700 --> 00:01:25.710 
often corners regions or blobs that vary

00:01:25.710 --> 00:01:27.140 
often corners regions or blobs that vary
in<00:01:25.799> intensity<00:01:26.310> compared<00:01:26.880> to<00:01:27.000> their

00:01:27.140 --> 00:01:27.150 
in intensity compared to their

00:01:27.150 --> 00:01:30.950 
in intensity compared to their
surroundings<00:01:28.820> the<00:01:29.820> detect<00:01:30.210> surf<00:01:30.479> features

00:01:30.950 --> 00:01:30.960 
surroundings the detect surf features

00:01:30.960 --> 00:01:33.319 
surroundings the detect surf features
and<00:01:31.200> extract<00:01:31.619> features<00:01:31.829> functions<00:01:32.549> help<00:01:33.150> us

00:01:33.319 --> 00:01:33.329 
and extract features functions help us

00:01:33.329 --> 00:01:35.149 
and extract features functions help us
obtain<00:01:33.509> the<00:01:33.750> surf<00:01:33.960> feature<00:01:34.259> descriptors<00:01:34.890> of

00:01:35.149 --> 00:01:35.159 
obtain the surf feature descriptors of

00:01:35.159 --> 00:01:37.580 
obtain the surf feature descriptors of
the<00:01:35.310> reference<00:01:35.670> images<00:01:36.030> these<00:01:36.810> are<00:01:37.020> 64

00:01:37.580 --> 00:01:37.590 
the reference images these are 64

00:01:37.590 --> 00:01:39.410 
the reference images these are 64
element<00:01:37.950> vectors<00:01:38.310> that<00:01:38.850> provide<00:01:39.180> information

00:01:39.410 --> 00:01:39.420 
element vectors that provide information

00:01:39.420 --> 00:01:42.289 
element vectors that provide information
about<00:01:39.810> blobs<00:01:40.259> in<00:01:40.470> an<00:01:40.590> image<00:01:40.829> the<00:01:41.790> descriptors

00:01:42.289 --> 00:01:42.299 
about blobs in an image the descriptors

00:01:42.299 --> 00:01:43.789 
about blobs in an image the descriptors
provide<00:01:42.540> a<00:01:42.600> basis<00:01:42.960> for<00:01:42.990> comparing<00:01:43.649> and

00:01:43.789 --> 00:01:43.799 
provide a basis for comparing and

00:01:43.799 --> 00:01:45.560 
provide a basis for comparing and
matching<00:01:44.159> features<00:01:44.549> which<00:01:45.119> is<00:01:45.270> how<00:01:45.390> will

00:01:45.560 --> 00:01:45.570 
matching features which is how will

00:01:45.570 --> 00:01:48.050 
matching features which is how will
recognize<00:01:45.990> our<00:01:46.170> object<00:01:46.670> here<00:01:47.670> are<00:01:47.790> some<00:01:47.939> of

00:01:48.050 --> 00:01:48.060 
recognize our object here are some of

00:01:48.060 --> 00:01:49.639 
recognize our object here are some of
the<00:01:48.180> surf<00:01:48.420> features<00:01:48.869> from<00:01:49.200> our<00:01:49.320> reference

00:01:49.639 --> 00:01:49.649 
the surf features from our reference

00:01:49.649 --> 00:01:53.210 
the surf features from our reference
image<00:01:51.170> next<00:01:52.170> we'll<00:01:52.530> need<00:01:52.560> to<00:01:52.770> prepare<00:01:53.070> the

00:01:53.210 --> 00:01:53.220 
image next we'll need to prepare the

00:01:53.220 --> 00:01:54.560 
image next we'll need to prepare the
videos<00:01:53.520> that<00:01:53.549> we'll<00:01:53.909> be<00:01:53.939> replacing<00:01:54.240> the

00:01:54.560 --> 00:01:54.570 
videos that we'll be replacing the

00:01:54.570 --> 00:01:58.010 
videos that we'll be replacing the
objects<00:01:55.969> to<00:01:56.969> complete<00:01:57.299> our<00:01:57.420> initial<00:01:57.780> setup

00:01:58.010 --> 00:01:58.020 
objects to complete our initial setup

00:01:58.020 --> 00:02:00.139 
objects to complete our initial setup
we'll<00:01:58.560> create<00:01:58.740> a<00:01:58.860> web<00:01:59.070> cam<00:01:59.310> object<00:01:59.790> which

00:02:00.139 --> 00:02:00.149 
we'll create a web cam object which

00:02:00.149 --> 00:02:02.560 
we'll create a web cam object which
we'll<00:02:00.360> use<00:02:00.390> to<00:02:00.659> get<00:02:00.810> frames<00:02:01.200> from<00:02:01.439> our<00:02:01.590> webcam

00:02:02.560 --> 00:02:02.570 
we'll use to get frames from our webcam

00:02:02.570 --> 00:02:04.999 
we'll use to get frames from our webcam
now<00:02:03.570> we<00:02:03.630> can<00:02:03.869> look<00:02:03.990> at<00:02:04.110> the<00:02:04.200> processing<00:02:04.799> that

00:02:04.999 --> 00:02:05.009 
now we can look at the processing that

00:02:05.009 --> 00:02:07.370 
now we can look at the processing that
happens<00:02:05.219> with<00:02:05.579> each<00:02:05.759> webcam<00:02:06.240> frame<00:02:06.570> there

00:02:07.370 --> 00:02:07.380 
happens with each webcam frame there

00:02:07.380 --> 00:02:09.440 
happens with each webcam frame there
will<00:02:07.500> be<00:02:07.530> two<00:02:07.740> possible<00:02:08.129> paths<00:02:08.340> to<00:02:08.580> take<00:02:08.789> one

00:02:09.440 --> 00:02:09.450 
will be two possible paths to take one

00:02:09.450 --> 00:02:11.330 
will be two possible paths to take one
for<00:02:09.629> recognition<00:02:10.080> and<00:02:10.470> the<00:02:11.009> other<00:02:11.129> for

00:02:11.330 --> 00:02:11.340 
for recognition and the other for

00:02:11.340 --> 00:02:12.270 
for recognition and the other for
tracking

00:02:12.270 --> 00:02:12.280 
tracking

00:02:12.280 --> 00:02:15.210 
tracking
first<00:02:13.270> we<00:02:13.780> need<00:02:13.870> to<00:02:13.930> take<00:02:14.170> a<00:02:14.200> snapshot<00:02:14.560> of<00:02:14.980> the

00:02:15.210 --> 00:02:15.220 
first we need to take a snapshot of the

00:02:15.220 --> 00:02:17.699 
first we need to take a snapshot of the
webcam<00:02:15.580> stream<00:02:15.910> to<00:02:16.660> recognize<00:02:17.080> an<00:02:17.230> object<00:02:17.350> in

00:02:17.699 --> 00:02:17.709 
webcam stream to recognize an object in

00:02:17.709 --> 00:02:20.040 
webcam stream to recognize an object in
our<00:02:17.830> webcam<00:02:18.190> video<00:02:18.490> we<00:02:19.180> need<00:02:19.330> to<00:02:19.420> obtain<00:02:19.569> surf

00:02:20.040 --> 00:02:20.050 
our webcam video we need to obtain surf

00:02:20.050 --> 00:02:23.100 
our webcam video we need to obtain surf
features<00:02:20.470> from<00:02:20.620> the<00:02:20.680> frame<00:02:21.600> we<00:02:22.600> already<00:02:22.959> have

00:02:23.100 --> 00:02:23.110 
features from the frame we already have

00:02:23.110 --> 00:02:24.870 
features from the frame we already have
the<00:02:23.230> extracted<00:02:23.770> surf<00:02:24.010> descriptors<00:02:24.610> for<00:02:24.790> the

00:02:24.870 --> 00:02:24.880 
the extracted surf descriptors for the

00:02:24.880 --> 00:02:26.690 
the extracted surf descriptors for the
magnet<00:02:25.270> from<00:02:25.510> the<00:02:25.600> preparation<00:02:26.020> step<00:02:26.440> earlier

00:02:26.690 --> 00:02:26.700 
magnet from the preparation step earlier

00:02:26.700 --> 00:02:29.100 
magnet from the preparation step earlier
we<00:02:27.700> can<00:02:27.880> use<00:02:28.060> these<00:02:28.240> to<00:02:28.450> find<00:02:28.660> the<00:02:28.750> matches

00:02:29.100 --> 00:02:29.110 
we can use these to find the matches

00:02:29.110 --> 00:02:30.979 
we can use these to find the matches
between<00:02:29.260> the<00:02:29.620> reference<00:02:30.010> and<00:02:30.250> frame<00:02:30.550> images

00:02:30.979 --> 00:02:30.989 
between the reference and frame images

00:02:30.989 --> 00:02:33.090 
between the reference and frame images
here's<00:02:31.989> an<00:02:32.140> example<00:02:32.500> of<00:02:32.560> what<00:02:32.709> the<00:02:32.800> matches

00:02:33.090 --> 00:02:33.100 
here's an example of what the matches

00:02:33.100 --> 00:02:37.530 
here's an example of what the matches
look<00:02:33.250> like<00:02:35.430> from<00:02:36.430> the<00:02:36.489> matches<00:02:37.030> we<00:02:37.390> can

00:02:37.530 --> 00:02:37.540 
look like from the matches we can

00:02:37.540 --> 00:02:39.300 
look like from the matches we can
estimate<00:02:37.780> the<00:02:38.050> geometric<00:02:38.560> transformation

00:02:39.300 --> 00:02:39.310 
estimate the geometric transformation

00:02:39.310 --> 00:02:41.370 
estimate the geometric transformation
that<00:02:39.880> positions<00:02:40.330> our<00:02:40.480> reference<00:02:40.870> image<00:02:41.020> in

00:02:41.370 --> 00:02:41.380 
that positions our reference image in

00:02:41.380 --> 00:02:44.430 
that positions our reference image in
its<00:02:41.800> location<00:02:42.130> in<00:02:42.400> the<00:02:42.489> webcam<00:02:42.819> frame<00:02:43.440> this

00:02:44.430 --> 00:02:44.440 
its location in the webcam frame this

00:02:44.440 --> 00:02:46.380 
its location in the webcam frame this
uses<00:02:44.739> the<00:02:44.769> ransac<00:02:45.280> algorithm<00:02:45.610> which<00:02:46.180> also

00:02:46.380 --> 00:02:46.390 
uses the ransac algorithm which also

00:02:46.390 --> 00:02:49.400 
uses the ransac algorithm which also
removes<00:02:46.810> possible<00:02:47.320> outliers<00:02:47.680> in<00:02:47.980> the<00:02:48.010> matches

00:02:49.400 --> 00:02:49.410 
removes possible outliers in the matches

00:02:49.410 --> 00:02:51.660 
removes possible outliers in the matches
we<00:02:50.410> want<00:02:50.590> to<00:02:50.709> use<00:02:50.800> the<00:02:51.010> same<00:02:51.280> transformation

00:02:51.660 --> 00:02:51.670 
we want to use the same transformation

00:02:51.670 --> 00:02:54.300 
we want to use the same transformation
on<00:02:52.330> a<00:02:52.390> replacement<00:02:52.810> video<00:02:53.320> to<00:02:53.739> insert<00:02:54.040> it<00:02:54.190> in

00:02:54.300 --> 00:02:54.310 
on a replacement video to insert it in

00:02:54.310 --> 00:02:56.880 
on a replacement video to insert it in
the<00:02:54.340> right<00:02:54.580> place<00:02:54.930> to<00:02:55.930> do<00:02:56.050> this<00:02:56.230> we<00:02:56.560> first<00:02:56.590> need

00:02:56.880 --> 00:02:56.890 
the right place to do this we first need

00:02:56.890 --> 00:02:59.309 
the right place to do this we first need
to<00:02:57.069> resize<00:02:57.459> the<00:02:57.700> replacement<00:02:58.239> video<00:02:58.480> frame<00:02:58.870> to

00:02:59.309 --> 00:02:59.319 
to resize the replacement video frame to

00:02:59.319 --> 00:03:01.890 
to resize the replacement video frame to
the<00:02:59.440> reference<00:02:59.800> image<00:03:00.130> size<00:03:00.780> here's<00:03:01.780> the

00:03:01.890 --> 00:03:01.900 
the reference image size here's the

00:03:01.900 --> 00:03:03.840 
the reference image size here's the
resized<00:03:02.290> frame<00:03:02.650> next<00:03:02.950> to<00:03:03.100> the<00:03:03.220> original<00:03:03.700> image

00:03:03.840 --> 00:03:03.850 
resized frame next to the original image

00:03:03.850 --> 00:03:07.770 
resized frame next to the original image
of<00:03:04.150> a<00:03:04.209> magnet<00:03:05.880> now<00:03:06.880> that<00:03:07.090> the<00:03:07.209> dimensions<00:03:07.660> are

00:03:07.770 --> 00:03:07.780 
of a magnet now that the dimensions are

00:03:07.780 --> 00:03:09.300 
of a magnet now that the dimensions are
matched<00:03:07.989> we<00:03:08.410> can<00:03:08.560> work<00:03:08.709> on<00:03:08.830> creating<00:03:09.040> the

00:03:09.300 --> 00:03:09.310 
matched we can work on creating the

00:03:09.310 --> 00:03:11.759 
matched we can work on creating the
display<00:03:09.840> will<00:03:10.840> apply<00:03:11.080> the<00:03:11.140> geometric

00:03:11.759 --> 00:03:11.769 
display will apply the geometric

00:03:11.769 --> 00:03:13.920 
display will apply the geometric
transformation<00:03:12.459> that<00:03:12.640> we<00:03:12.730> found<00:03:12.910> before<00:03:13.360> to

00:03:13.920 --> 00:03:13.930 
transformation that we found before to

00:03:13.930 --> 00:03:16.050 
transformation that we found before to
position<00:03:14.350> the<00:03:14.500> resize<00:03:14.890> video<00:03:15.250> frame<00:03:15.580> into<00:03:15.940> the

00:03:16.050 --> 00:03:16.060 
position the resize video frame into the

00:03:16.060 --> 00:03:18.180 
position the resize video frame into the
right<00:03:16.180> place<00:03:16.620> here's<00:03:17.620> what<00:03:17.799> it<00:03:17.890> looks<00:03:18.070> like

00:03:18.180 --> 00:03:18.190 
right place here's what it looks like

00:03:18.190 --> 00:03:23.580 
right place here's what it looks like
afterwards<00:03:21.660> finally<00:03:22.660> we'll<00:03:22.959> composite<00:03:23.440> this

00:03:23.580 --> 00:03:23.590 
afterwards finally we'll composite this

00:03:23.590 --> 00:03:26.310 
afterwards finally we'll composite this
into<00:03:23.950> the<00:03:24.070> original<00:03:24.280> webcam<00:03:24.880> frame<00:03:25.320> this

00:03:26.310 --> 00:03:26.320 
into the original webcam frame this

00:03:26.320 --> 00:03:27.930 
into the original webcam frame this
resulting<00:03:26.829> image<00:03:27.070> is<00:03:27.280> what<00:03:27.430> we<00:03:27.519> display<00:03:27.820> to

00:03:27.930 --> 00:03:27.940 
resulting image is what we display to

00:03:27.940 --> 00:03:31.740 
resulting image is what we display to
create<00:03:28.299> the<00:03:28.390> augmented<00:03:28.810> reality<00:03:30.600> now<00:03:31.600> that

00:03:31.740 --> 00:03:31.750 
create the augmented reality now that

00:03:31.750 --> 00:03:33.600 
create the augmented reality now that
we've<00:03:31.900> successfully<00:03:32.079> recognized<00:03:33.010> the<00:03:33.190> object

00:03:33.600 --> 00:03:33.610 
we've successfully recognized the object

00:03:33.610 --> 00:03:37.080 
we've successfully recognized the object
we<00:03:34.120> can<00:03:34.269> also<00:03:34.420> handle<00:03:34.690> tracking<00:03:35.820> the<00:03:36.820> point

00:03:37.080 --> 00:03:37.090 
we can also handle tracking the point

00:03:37.090 --> 00:03:39.030 
we can also handle tracking the point
tracker<00:03:37.390> provides<00:03:37.959> an<00:03:38.110> easy<00:03:38.350> way<00:03:38.560> to<00:03:38.590> track

00:03:39.030 --> 00:03:39.040 
tracker provides an easy way to track

00:03:39.040 --> 00:03:41.789 
tracker provides an easy way to track
our<00:03:39.220> object<00:03:39.610> between<00:03:39.760> frames<00:03:40.329> it<00:03:40.630> keeps<00:03:41.470> a<00:03:41.590> set

00:03:41.789 --> 00:03:41.799 
our object between frames it keeps a set

00:03:41.799 --> 00:03:43.710 
our object between frames it keeps a set
of<00:03:41.890> point<00:03:42.190> locations<00:03:42.730> in<00:03:42.880> an<00:03:43.000> image<00:03:43.269> to

00:03:43.710 --> 00:03:43.720 
of point locations in an image to

00:03:43.720 --> 00:03:45.930 
of point locations in an image to
represent<00:03:43.810> an<00:03:44.260> object<00:03:44.380> and<00:03:44.890> uses<00:03:45.489> the<00:03:45.609> KLT

00:03:45.930 --> 00:03:45.940 
represent an object and uses the KLT

00:03:45.940 --> 00:03:48.750 
represent an object and uses the KLT
algorithm<00:03:46.630> to<00:03:46.810> track<00:03:47.049> the<00:03:47.200> points<00:03:47.530> we<00:03:48.459> already

00:03:48.750 --> 00:03:48.760 
algorithm to track the points we already

00:03:48.760 --> 00:03:50.490 
algorithm to track the points we already
have<00:03:49.000> in<00:03:49.150> lyer<00:03:49.329> feature<00:03:49.690> matches<00:03:50.200> for<00:03:50.410> our

00:03:50.490 --> 00:03:50.500 
have in lyer feature matches for our

00:03:50.500 --> 00:03:53.069 
have in lyer feature matches for our
object<00:03:51.010> from<00:03:51.220> the<00:03:51.340> recognition<00:03:51.609> step<00:03:52.180> we'll

00:03:53.069 --> 00:03:53.079 
object from the recognition step we'll

00:03:53.079 --> 00:03:55.199 
object from the recognition step we'll
use<00:03:53.350> their<00:03:53.560> locations<00:03:54.100> to<00:03:54.430> initialize<00:03:54.910> a<00:03:54.940> set

00:03:55.199 --> 00:03:55.209 
use their locations to initialize a set

00:03:55.209 --> 00:03:59.009 
use their locations to initialize a set
of<00:03:55.329> points<00:03:55.540> for<00:03:55.930> the<00:03:55.989> point<00:03:56.200> tracker<00:03:57.930> when<00:03:58.930> we

00:03:59.009 --> 00:03:59.019 
of points for the point tracker when we

00:03:59.019 --> 00:04:00.599 
of points for the point tracker when we
provide<00:03:59.380> the<00:03:59.560> next<00:03:59.829> frame<00:04:00.010> of<00:04:00.160> the<00:04:00.280> webcam

00:04:00.599 --> 00:04:00.609 
provide the next frame of the webcam

00:04:00.609 --> 00:04:02.849 
provide the next frame of the webcam
stream<00:04:01.000> the<00:04:01.510> point<00:04:01.750> tracker<00:04:02.019> automatically

00:04:02.849 --> 00:04:02.859 
stream the point tracker automatically

00:04:02.859 --> 00:04:04.620 
stream the point tracker automatically
finds<00:04:03.280> the<00:04:03.370> new<00:04:03.519> point<00:04:03.790> locations<00:04:04.359> for

00:04:04.620 --> 00:04:04.630 
finds the new point locations for

00:04:04.630 --> 00:04:08.699 
finds the new point locations for
objects<00:04:05.170> features<00:04:06.780> we<00:04:07.780> can<00:04:07.959> use<00:04:08.170> these<00:04:08.410> to

00:04:08.699 --> 00:04:08.709 
objects features we can use these to

00:04:08.709 --> 00:04:10.470 
objects features we can use these to
find<00:04:08.739> the<00:04:09.040> geometric<00:04:09.519> transformation<00:04:10.209> that

00:04:10.470 --> 00:04:10.480 
find the geometric transformation that

00:04:10.480 --> 00:04:12.900 
find the geometric transformation that
just<00:04:10.720> happened<00:04:11.079> between<00:04:11.200> frames<00:04:11.760> we'll<00:04:12.760> also

00:04:12.900 --> 00:04:12.910 
just happened between frames we'll also

00:04:12.910 --> 00:04:14.789 
just happened between frames we'll also
update<00:04:13.239> the<00:04:13.450> point<00:04:13.780> tracker<00:04:14.049> with<00:04:14.440> these<00:04:14.590> new

00:04:14.789 --> 00:04:14.799 
update the point tracker with these new

00:04:14.799 --> 00:04:18.659 
update the point tracker with these new
point<00:04:15.040> locations<00:04:16.890> to<00:04:17.890> keep<00:04:18.070> inserting<00:04:18.400> the

00:04:18.659 --> 00:04:18.669 
point locations to keep inserting the

00:04:18.669 --> 00:04:20.880 
point locations to keep inserting the
replacement<00:04:19.239> video<00:04:19.329> in<00:04:19.660> the<00:04:19.750> right<00:04:19.930> place<00:04:20.229> we

00:04:20.880 --> 00:04:20.890 
replacement video in the right place we

00:04:20.890 --> 00:04:22.020 
replacement video in the right place we
combined<00:04:21.250> the<00:04:21.400> current<00:04:21.729> tracking

00:04:22.020 --> 00:04:22.030 
combined the current tracking

00:04:22.030 --> 00:04:24.000 
combined the current tracking
transformation<00:04:22.930> with<00:04:23.530> any<00:04:23.710> previous

00:04:24.000 --> 00:04:24.010 
transformation with any previous

00:04:24.010 --> 00:04:25.470 
transformation with any previous
transformation

00:04:25.470 --> 00:04:25.480 
transformation

00:04:25.480 --> 00:04:28.150 
transformation
from<00:04:26.480> here<00:04:26.840> we<00:04:27.290> just<00:04:27.440> need<00:04:27.560> to<00:04:27.740> repeat<00:04:28.010> the

00:04:28.150 --> 00:04:28.160 
from here we just need to repeat the

00:04:28.160 --> 00:04:31.200 
from here we just need to repeat the
process<00:04:28.340> of<00:04:28.850> resizing<00:04:29.540> the<00:04:29.630> new<00:04:29.810> video<00:04:30.050> frame

00:04:31.200 --> 00:04:31.210 
process of resizing the new video frame

00:04:31.210 --> 00:04:34.590 
process of resizing the new video frame
applying<00:04:32.210> the<00:04:32.360> updated<00:04:32.780> transformation<00:04:33.500> and

00:04:34.590 --> 00:04:34.600 
applying the updated transformation and

00:04:34.600 --> 00:04:39.120 
applying the updated transformation and
compositing<00:04:37.060> once<00:04:38.060> we<00:04:38.210> repeat<00:04:38.510> the<00:04:38.660> reading

00:04:39.120 --> 00:04:39.130 
compositing once we repeat the reading

00:04:39.130 --> 00:04:41.470 
compositing once we repeat the reading
recognition<00:04:40.130> or<00:04:40.250> tracking<00:04:40.520> and<00:04:40.910> display

00:04:41.470 --> 00:04:41.480 
recognition or tracking and display

00:04:41.480 --> 00:04:42.970 
recognition or tracking and display
steps<00:04:41.840> frame<00:04:42.320> by<00:04:42.470> frame

00:04:42.970 --> 00:04:42.980 
steps frame by frame

00:04:42.980 --> 00:04:45.190 
steps frame by frame
we<00:04:43.430> get<00:04:43.610> the<00:04:43.730> video<00:04:44.000> and<00:04:44.180> video<00:04:44.300> augmented

00:04:45.190 --> 00:04:45.200 
we get the video and video augmented

00:04:45.200 --> 00:04:47.950 
we get the video and video augmented
reality<00:04:45.230> effect<00:04:45.980> with<00:04:46.250> our<00:04:46.280> webcam<00:04:46.960> we've

00:04:47.950 --> 00:04:47.960 
reality effect with our webcam we've

00:04:47.960 --> 00:04:49.600 
reality effect with our webcam we've
developed<00:04:48.350> a<00:04:48.440> basic<00:04:48.770> application<00:04:49.400> for

00:04:49.600 --> 00:04:49.610 
developed a basic application for

00:04:49.610 --> 00:04:51.430 
developed a basic application for
augmented<00:04:49.670> reality<00:04:50.000> using<00:04:50.930> object

00:04:51.430 --> 00:04:51.440 
augmented reality using object

00:04:51.440 --> 00:04:53.620 
augmented reality using object
recognition<00:04:51.590> and<00:04:52.130> tracking<00:04:52.330> you<00:04:53.330> can<00:04:53.360> also

00:04:53.620 --> 00:04:53.630 
recognition and tracking you can also

00:04:53.630 --> 00:04:55.360 
recognition and tracking you can also
explore<00:04:54.080> other<00:04:54.110> types<00:04:54.530> of<00:04:54.650> recognition<00:04:55.070> and

00:04:55.360 --> 00:04:55.370 
explore other types of recognition and

00:04:55.370 --> 00:04:57.040 
explore other types of recognition and
tracking<00:04:55.520> to<00:04:56.150> create<00:04:56.420> your<00:04:56.540> own<00:04:56.570> augmented

00:04:57.040 --> 00:04:57.050 
tracking to create your own augmented

00:04:57.050 --> 00:05:00.040 
tracking to create your own augmented
reality<00:04:57.080> applications

