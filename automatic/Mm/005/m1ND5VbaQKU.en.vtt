WEBVTT
Kind: captions
Language: en

00:00:07.490 --> 00:00:10.160 

the<00:00:08.490> motivation<00:00:08.910> of<00:00:09.240> this<00:00:09.480> work<00:00:09.719> is<00:00:09.900> to

00:00:10.160 --> 00:00:10.170 
the motivation of this work is to

00:00:10.170 --> 00:00:12.110 
the motivation of this work is to
develop<00:00:10.349> a<00:00:10.650> complete<00:00:11.070> framework<00:00:11.580> that<00:00:11.880> will

00:00:12.110 --> 00:00:12.120 
develop a complete framework that will

00:00:12.120 --> 00:00:14.030 
develop a complete framework that will
enable<00:00:12.360> humanoid<00:00:12.929> robots<00:00:13.380> to<00:00:13.620> perform

00:00:14.030 --> 00:00:14.040 
enable humanoid robots to perform

00:00:14.040 --> 00:00:15.980 
enable humanoid robots to perform
collaborative<00:00:14.730> manipulation<00:00:15.360> tasks<00:00:15.809> with

00:00:15.980 --> 00:00:15.990 
collaborative manipulation tasks with

00:00:15.990 --> 00:00:18.950 
collaborative manipulation tasks with
humans<00:00:16.460> the<00:00:17.460> figure<00:00:17.789> shows<00:00:18.029> the<00:00:18.270> experimental

00:00:18.950 --> 00:00:18.960 
humans the figure shows the experimental

00:00:18.960 --> 00:00:21.080 
humans the figure shows the experimental
setup<00:00:19.350> which<00:00:19.710> consists<00:00:20.189> mainly<00:00:20.430> of<00:00:20.670> the<00:00:20.939> nao

00:00:21.080 --> 00:00:21.090 
setup which consists mainly of the nao

00:00:21.090 --> 00:00:23.300 
setup which consists mainly of the nao
humanoid<00:00:21.330> robot<00:00:22.020> and<00:00:22.170> the<00:00:22.560> y<00:00:22.710> con<00:00:22.920> motion

00:00:23.300 --> 00:00:23.310 
humanoid robot and the y con motion

00:00:23.310 --> 00:00:26.710 
humanoid robot and the y con motion
capture<00:00:23.640> system

00:00:26.710 --> 00:00:26.720 

00:00:26.720 --> 00:00:28.820 

initially<00:00:27.720> calibration<00:00:28.410> has<00:00:28.439> to<00:00:28.710> be

00:00:28.820 --> 00:00:28.830 
initially calibration has to be

00:00:28.830 --> 00:00:30.679 
initially calibration has to be
performed<00:00:29.279> to<00:00:29.400> find<00:00:29.640> out<00:00:29.820> the<00:00:30.000> correspondence

00:00:30.679 --> 00:00:30.689 
performed to find out the correspondence

00:00:30.689 --> 00:00:32.749 
performed to find out the correspondence
between<00:00:30.990> the<00:00:31.380> frame<00:00:31.650> defined<00:00:32.070> by<00:00:32.220> the<00:00:32.279> markers

00:00:32.749 --> 00:00:32.759 
between the frame defined by the markers

00:00:32.759 --> 00:00:34.819 
between the frame defined by the markers
on<00:00:32.910> the<00:00:33.030> robot's<00:00:33.360> body<00:00:33.450> with<00:00:34.260> the<00:00:34.470> robots

00:00:34.819 --> 00:00:34.829 
on the robot's body with the robots

00:00:34.829 --> 00:00:37.549 
on the robot's body with the robots
internal<00:00:35.370> control<00:00:35.730> frame<00:00:36.260> figure<00:00:37.260> shows<00:00:37.530> the

00:00:37.549 --> 00:00:37.559 
internal control frame figure shows the

00:00:37.559 --> 00:00:39.740 
internal control frame figure shows the
markers<00:00:38.250> placed<00:00:38.520> on<00:00:38.790> the<00:00:38.879> robots<00:00:39.239> arm<00:00:39.480> and

00:00:39.740 --> 00:00:39.750 
markers placed on the robots arm and

00:00:39.750 --> 00:00:41.729 
markers placed on the robots arm and
torso

00:00:41.729 --> 00:00:41.739 
torso

00:00:41.739 --> 00:00:44.169 
torso
calibration<00:00:42.739> involves<00:00:43.280> moving<00:00:43.550> the<00:00:43.820> robots

00:00:44.169 --> 00:00:44.179 
calibration involves moving the robots

00:00:44.179 --> 00:00:46.270 
calibration involves moving the robots
arm<00:00:44.420> randomly<00:00:45.019> while<00:00:45.409> collecting<00:00:45.829> the

00:00:46.270 --> 00:00:46.280 
arm randomly while collecting the

00:00:46.280 --> 00:00:47.829 
arm randomly while collecting the
encoder<00:00:46.670> and<00:00:46.789> motion<00:00:47.300> capture<00:00:47.659> data

00:00:47.829 --> 00:00:47.839 
encoder and motion capture data

00:00:47.839 --> 00:00:52.819 
encoder and motion capture data
simultaneously

00:00:52.819 --> 00:00:52.829 

00:00:52.829 --> 00:00:54.799 

the<00:00:53.670> figure<00:00:53.969> shows<00:00:54.239> that<00:00:54.510> a<00:00:54.570> good

00:00:54.799 --> 00:00:54.809 
the figure shows that a good

00:00:54.809 --> 00:00:56.299 
the figure shows that a good
correspondence<00:00:55.230> has<00:00:55.679> been<00:00:55.920> found<00:00:56.190> out

00:00:56.299 --> 00:00:56.309 
correspondence has been found out

00:00:56.309 --> 00:00:58.130 
correspondence has been found out
between<00:00:56.550> the<00:00:56.820> motion<00:00:57.000> capture<00:00:57.510> data<00:00:57.659> and<00:00:57.989> the

00:00:58.130 --> 00:00:58.140 
between the motion capture data and the

00:00:58.140 --> 00:01:01.130 
between the motion capture data and the
encoder<00:00:58.500> data<00:00:58.800> in<00:00:59.269> the<00:01:00.269> first<00:01:00.479> phase<00:01:00.629> the

00:01:01.130 --> 00:01:01.140 
encoder data in the first phase the

00:01:01.140 --> 00:01:03.049 
encoder data in the first phase the
robot<00:01:01.440> learns<00:01:01.710> to<00:01:01.800> grasp<00:01:02.159> the<00:01:02.339> table<00:01:02.729> by

00:01:03.049 --> 00:01:03.059 
robot learns to grasp the table by

00:01:03.059 --> 00:01:05.359 
robot learns to grasp the table by
imitating<00:01:03.510> human<00:01:03.780> demonstrations<00:01:04.710> each

00:01:05.359 --> 00:01:05.369 
imitating human demonstrations each

00:01:05.369 --> 00:01:06.980 
imitating human demonstrations each
human<00:01:05.670> demonstration<00:01:06.509> has<00:01:06.720> slight

00:01:06.980 --> 00:01:06.990 
human demonstration has slight

00:01:06.990 --> 00:01:09.100 
human demonstration has slight
variations

00:01:09.100 --> 00:01:09.110 
variations

00:01:09.110 --> 00:01:10.850 
variations
here<00:01:10.110> we<00:01:10.290> see<00:01:10.470> four<00:01:10.829> different

00:01:10.850 --> 00:01:10.860 
here we see four different

00:01:10.860 --> 00:01:16.110 
here we see four different
demonstrations

00:01:16.110 --> 00:01:16.120 

00:01:16.120 --> 00:01:18.450 

the<00:01:16.930> figure<00:01:17.230> shows<00:01:17.470> task<00:01:17.830> constraints

00:01:18.450 --> 00:01:18.460 
the figure shows task constraints

00:01:18.460 --> 00:01:22.170 
the figure shows task constraints
extracted<00:01:19.030> using<00:01:19.150> GM<00:01:19.630> m<00:01:19.810> and<00:01:20.020> GM<00:01:20.350> are<00:01:21.180> human

00:01:22.170 --> 00:01:22.180 
extracted using GM m and GM are human

00:01:22.180 --> 00:01:23.760 
extracted using GM m and GM are human
demonstrations<00:01:22.870> are<00:01:23.050> mapped<00:01:23.290> to<00:01:23.440> the<00:01:23.590> robot

00:01:23.760 --> 00:01:23.770 
demonstrations are mapped to the robot

00:01:23.770 --> 00:01:25.890 
demonstrations are mapped to the robot
by<00:01:24.280> adding<00:01:24.640> a<00:01:24.730> bias<00:01:24.970> that<00:01:25.090> is<00:01:25.360> equal<00:01:25.690> to<00:01:25.780> the

00:01:25.890 --> 00:01:25.900 
by adding a bias that is equal to the

00:01:25.900 --> 00:01:28.860 
by adding a bias that is equal to the
hand<00:01:26.110> size<00:01:26.320> difference<00:01:27.330> once<00:01:28.330> the<00:01:28.540> mapping

00:01:28.860 --> 00:01:28.870 
hand size difference once the mapping

00:01:28.870 --> 00:01:30.750 
hand size difference once the mapping
has<00:01:29.050> been<00:01:29.260> done<00:01:29.500> the<00:01:29.860> robot<00:01:30.160> can<00:01:30.340> grasp<00:01:30.580> the

00:01:30.750 --> 00:01:30.760 
has been done the robot can grasp the

00:01:30.760 --> 00:01:33.360 
has been done the robot can grasp the
table<00:01:31.090> in<00:01:31.210> any<00:01:31.390> given<00:01:31.570> situation<00:01:32.070> the<00:01:33.070> video

00:01:33.360 --> 00:01:33.370 
table in any given situation the video

00:01:33.370 --> 00:01:41.020 
table in any given situation the video
shows<00:01:33.640> one<00:01:33.940> such<00:01:34.210> trial

00:01:41.020 --> 00:01:41.030 

00:01:41.030 --> 00:01:43.480 

now<00:01:41.659> for<00:01:41.930> a<00:01:41.960> different<00:01:42.350> situation<00:01:42.560> notice

00:01:43.480 --> 00:01:43.490 
now for a different situation notice

00:01:43.490 --> 00:01:45.520 
now for a different situation notice
that<00:01:43.520> the<00:01:43.729> table<00:01:44.150> is<00:01:44.299> now<00:01:44.479> kept<00:01:44.840> higher<00:01:45.080> but

00:01:45.520 --> 00:01:45.530 
that the table is now kept higher but

00:01:45.530 --> 00:01:46.899 
that the table is now kept higher but
the<00:01:45.650> robot<00:01:45.950> can<00:01:46.100> still<00:01:46.369> grasped<00:01:46.700> it

00:01:46.899 --> 00:01:46.909 
the robot can still grasped it

00:01:46.909 --> 00:01:48.790 
the robot can still grasped it
successfully

00:01:48.790 --> 00:01:48.800 
successfully

00:01:48.800 --> 00:01:51.250 
successfully
in<00:01:49.520> the<00:01:49.790> second<00:01:50.120> learning<00:01:50.450> phase<00:01:50.630> the<00:01:50.990> robot

00:01:51.250 --> 00:01:51.260 
in the second learning phase the robot

00:01:51.260 --> 00:01:52.930 
in the second learning phase the robot
launched<00:01:51.530> the<00:01:51.710> cooperative<00:01:52.340> manipulation

00:01:52.930 --> 00:01:52.940 
launched the cooperative manipulation

00:01:52.940 --> 00:01:55.570 
launched the cooperative manipulation
task<00:01:53.210> by<00:01:53.540> reinforcement<00:01:54.230> learning<00:01:54.580> this

00:01:55.570 --> 00:01:55.580 
task by reinforcement learning this

00:01:55.580 --> 00:01:57.160 
task by reinforcement learning this
video<00:01:55.880> shows<00:01:56.090> the<00:01:56.120> robot<00:01:56.660> learning<00:01:57.050> to

00:01:57.160 --> 00:01:57.170 
video shows the robot learning to

00:01:57.170 --> 00:01:58.810 
video shows the robot learning to
manipulate<00:01:57.290> the<00:01:57.800> table<00:01:58.130> by<00:01:58.280> trial<00:01:58.550> and<00:01:58.670> error

00:01:58.810 --> 00:01:58.820 
manipulate the table by trial and error

00:01:58.820 --> 00:02:01.120 
manipulate the table by trial and error
while<00:01:59.510> the<00:01:59.690> human<00:02:00.050> is<00:02:00.170> holding<00:02:00.590> his<00:02:00.830> end<00:02:01.040> of

00:02:01.120 --> 00:02:01.130 
while the human is holding his end of

00:02:01.130 --> 00:02:05.080 
while the human is holding his end of
the<00:02:01.250> table<00:02:01.430> still<00:02:03.160> the<00:02:04.160> robot<00:02:04.490> can<00:02:04.700> learn<00:02:04.910> the

00:02:05.080 --> 00:02:05.090 
the table still the robot can learn the

00:02:05.090 --> 00:02:10.620 
the table still the robot can learn the
manipulation<00:02:05.750> skill<00:02:06.050> within<00:02:06.410> 40<00:02:06.680> trials

00:02:10.620 --> 00:02:10.630 

00:02:10.630 --> 00:02:12.310 

objective<00:02:11.630> of<00:02:11.780> the<00:02:11.960> cooperative

00:02:12.310 --> 00:02:12.320 
objective of the cooperative

00:02:12.320 --> 00:02:14.470 
objective of the cooperative
manipulation<00:02:13.160> task<00:02:13.400> is<00:02:13.670> to<00:02:13.850> keep<00:02:13.970> the<00:02:14.150> table

00:02:14.470 --> 00:02:14.480 
manipulation task is to keep the table

00:02:14.480 --> 00:02:16.570 
manipulation task is to keep the table
as<00:02:14.630> horizontal<00:02:15.110> as<00:02:15.380> possible<00:02:16.040> throughout<00:02:16.400> the

00:02:16.570 --> 00:02:16.580 
as horizontal as possible throughout the

00:02:16.580 --> 00:02:20.110 
as horizontal as possible throughout the
table<00:02:16.880> lifting<00:02:17.210> task<00:02:18.700> based<00:02:19.700> on<00:02:20.000> the

00:02:20.110 --> 00:02:20.120 
table lifting task based on the

00:02:20.120 --> 00:02:22.060 
table lifting task based on the
manipulation<00:02:20.750> scale<00:02:21.050> acquired<00:02:21.470> by<00:02:21.620> the<00:02:21.650> robot

00:02:22.060 --> 00:02:22.070 
manipulation scale acquired by the robot

00:02:22.070 --> 00:02:23.560 
manipulation scale acquired by the robot
in<00:02:22.220> the<00:02:22.250> last<00:02:22.520> step<00:02:22.790> this<00:02:23.300> can<00:02:23.540> be

00:02:23.560 --> 00:02:23.570 
in the last step this can be

00:02:23.570 --> 00:02:26.680 
in the last step this can be
successfully<00:02:24.260> achieved

