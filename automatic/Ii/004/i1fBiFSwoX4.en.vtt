WEBVTT
Kind: captions
Language: en

00:00:02.210 --> 00:00:04.940 

one<00:00:03.210> of<00:00:03.330> the<00:00:03.449> specific<00:00:03.659> projects<00:00:04.319> our<00:00:04.500> lab<00:00:04.799> is

00:00:04.940 --> 00:00:04.950 
one of the specific projects our lab is

00:00:04.950 --> 00:00:07.579 
one of the specific projects our lab is
working<00:00:05.130> on<00:00:05.520> is<00:00:05.850> in<00:00:06.120> the<00:00:06.210> area<00:00:06.540> of<00:00:06.600> augmented

00:00:07.579 --> 00:00:07.589 
working on is in the area of augmented

00:00:07.589 --> 00:00:09.770 
working on is in the area of augmented
reality<00:00:07.910> visualization<00:00:08.910> in<00:00:09.090> the<00:00:09.300> context<00:00:09.690> of

00:00:09.770 --> 00:00:09.780 
reality visualization in the context of

00:00:09.780 --> 00:00:11.330 
reality visualization in the context of
construction<00:00:10.440> specifically<00:00:11.099> we<00:00:11.309> use

00:00:11.330 --> 00:00:11.340 
construction specifically we use

00:00:11.340 --> 00:00:14.629 
construction specifically we use
augmented<00:00:12.120> reality<00:00:12.259> to<00:00:13.340> project<00:00:14.340> on<00:00:14.580> a

00:00:14.629 --> 00:00:14.639 
augmented reality to project on a

00:00:14.639 --> 00:00:17.240 
augmented reality to project on a
planned<00:00:15.269> construction<00:00:15.960> site<00:00:16.260> what<00:00:16.859> might<00:00:17.070> it

00:00:17.240 --> 00:00:17.250 
planned construction site what might it

00:00:17.250 --> 00:00:19.340 
planned construction site what might it
look<00:00:17.279> like<00:00:17.730> when<00:00:18.029> actual<00:00:18.390> resources<00:00:18.869> or

00:00:19.340 --> 00:00:19.350 
look like when actual resources or

00:00:19.350 --> 00:00:20.900 
look like when actual resources or
construction<00:00:19.710> machines<00:00:20.250> come<00:00:20.580> into<00:00:20.789> the

00:00:20.900 --> 00:00:20.910 
construction machines come into the

00:00:20.910 --> 00:00:23.300 
construction machines come into the
environment<00:00:21.180> and<00:00:21.840> start<00:00:22.350> doing<00:00:22.650> work<00:00:23.070> that

00:00:23.300 --> 00:00:23.310 
environment and start doing work that

00:00:23.310 --> 00:00:25.730 
environment and start doing work that
will<00:00:23.760> occur<00:00:24.029> in<00:00:24.180> the<00:00:24.210> future<00:00:24.480> so<00:00:25.080> this<00:00:25.260> way<00:00:25.500> by

00:00:25.730 --> 00:00:25.740 
will occur in the future so this way by

00:00:25.740 --> 00:00:28.310 
will occur in the future so this way by
planning<00:00:26.279> in<00:00:26.580> the<00:00:26.760> virtual<00:00:27.269> environment<00:00:27.599> we

00:00:28.310 --> 00:00:28.320 
planning in the virtual environment we

00:00:28.320 --> 00:00:30.859 
planning in the virtual environment we
can<00:00:28.890> learn<00:00:29.550> from<00:00:29.609> our<00:00:29.910> mistakes<00:00:30.390> and<00:00:30.599> afford

00:00:30.859 --> 00:00:30.869 
can learn from our mistakes and afford

00:00:30.869 --> 00:00:32.600 
can learn from our mistakes and afford
to<00:00:30.990> make<00:00:31.170> mistakes<00:00:31.199> without<00:00:31.890> encumbering

00:00:32.600 --> 00:00:32.610 
to make mistakes without encumbering

00:00:32.610 --> 00:00:35.540 
to make mistakes without encumbering
real<00:00:32.969> resources<00:00:33.690> or<00:00:33.870> incurring<00:00:34.590> actual<00:00:35.040> costs

00:00:35.540 --> 00:00:35.550 
real resources or incurring actual costs

00:00:35.550 --> 00:00:37.490 
real resources or incurring actual costs
or<00:00:35.730> endangering<00:00:36.420> anybody's<00:00:36.930> safety

00:00:37.490 --> 00:00:37.500 
or endangering anybody's safety

00:00:37.500 --> 00:00:39.860 
or endangering anybody's safety
what<00:00:38.370> augmented<00:00:38.820> reality<00:00:38.870> visualization

00:00:39.860 --> 00:00:39.870 
what augmented reality visualization

00:00:39.870 --> 00:00:42.470 
what augmented reality visualization
implies<00:00:40.230> is<00:00:40.500> the<00:00:41.250> creation<00:00:41.610> of<00:00:41.940> a

00:00:42.470 --> 00:00:42.480 
implies is the creation of a

00:00:42.480 --> 00:00:45.200 
implies is the creation of a
computer-generated<00:00:43.379> world<00:00:44.040> that<00:00:44.730> blends

00:00:45.200 --> 00:00:45.210 
computer-generated world that blends

00:00:45.210 --> 00:00:47.200 
computer-generated world that blends
together<00:00:45.420> the<00:00:46.350> real<00:00:46.530> world<00:00:46.920> and

00:00:47.200 --> 00:00:47.210 
together the real world and

00:00:47.210 --> 00:00:50.180 
together the real world and
computer-generated<00:00:48.210> images<00:00:48.840> so<00:00:49.590> that<00:00:49.620> the

00:00:50.180 --> 00:00:50.190 
computer-generated images so that the

00:00:50.190 --> 00:00:52.610 
computer-generated images so that the
composite<00:00:50.640> image<00:00:51.000> creates<00:00:51.870> a<00:00:52.020> persistent

00:00:52.610 --> 00:00:52.620 
composite image creates a persistent

00:00:52.620 --> 00:00:54.920 
composite image creates a persistent
illusion<00:00:53.190> that<00:00:53.460> real<00:00:53.760> and<00:00:54.000> virtual<00:00:54.149> objects

00:00:54.920 --> 00:00:54.930 
illusion that real and virtual objects

00:00:54.930 --> 00:00:57.590 
illusion that real and virtual objects
coexist<00:00:55.590> there<00:00:56.430> are<00:00:56.550> two<00:00:56.910> possible<00:00:57.329> ways<00:00:57.390> to

00:00:57.590 --> 00:00:57.600 
coexist there are two possible ways to

00:00:57.600 --> 00:01:00.200 
coexist there are two possible ways to
achieve<00:00:57.899> this<00:00:58.320> one<00:00:58.710> is<00:00:58.890> called<00:00:59.210> optical

00:01:00.200 --> 00:01:00.210 
achieve this one is called optical

00:01:00.210 --> 00:01:02.389 
achieve this one is called optical
see-through<00:01:00.449> augmented<00:01:01.199> reality<00:01:01.230> and<00:01:01.890> the

00:01:02.389 --> 00:01:02.399 
see-through augmented reality and the

00:01:02.399 --> 00:01:04.670 
see-through augmented reality and the
second<00:01:02.760> is<00:01:02.879> called<00:01:03.210> video<00:01:04.049> see-through

00:01:04.670 --> 00:01:04.680 
second is called video see-through

00:01:04.680 --> 00:01:06.800 
second is called video see-through
augmented<00:01:05.189> reality<00:01:05.220> video<00:01:06.180> see-through

00:01:06.800 --> 00:01:06.810 
augmented reality video see-through

00:01:06.810 --> 00:01:08.690 
augmented reality video see-through
augmented<00:01:07.290> reality<00:01:07.320> display<00:01:08.070> has<00:01:08.280> taken<00:01:08.640> a

00:01:08.690 --> 00:01:08.700 
augmented reality display has taken a

00:01:08.700 --> 00:01:10.670 
augmented reality display has taken a
foothold<00:01:08.939> in<00:01:09.299> the<00:01:09.479> research<00:01:09.960> community<00:01:10.530> and

00:01:10.670 --> 00:01:10.680 
foothold in the research community and

00:01:10.680 --> 00:01:13.219 
foothold in the research community and
that's<00:01:10.830> what<00:01:10.979> we<00:01:11.460> have<00:01:11.580> been<00:01:11.850> pursuing<00:01:12.119> so<00:01:12.900> the

00:01:13.219 --> 00:01:13.229 
that's what we have been pursuing so the

00:01:13.229 --> 00:01:14.750 
that's what we have been pursuing so the
main<00:01:13.409> idea<00:01:13.710> behind<00:01:13.740> video<00:01:14.369> see-through

00:01:14.750 --> 00:01:14.760 
main idea behind video see-through

00:01:14.760 --> 00:01:17.300 
main idea behind video see-through
augmented<00:01:15.180> reality<00:01:15.210> is<00:01:15.869> that<00:01:16.500> a<00:01:16.560> video<00:01:16.890> camera

00:01:17.300 --> 00:01:17.310 
augmented reality is that a video camera

00:01:17.310 --> 00:01:20.450 
augmented reality is that a video camera
which<00:01:17.880> is<00:01:18.119> aligned<00:01:18.600> with<00:01:18.900> a<00:01:19.170> user's<00:01:19.740> physical

00:01:20.450 --> 00:01:20.460 
which is aligned with a user's physical

00:01:20.460 --> 00:01:22.550 
which is aligned with a user's physical
line-of-sight<00:01:21.090> it<00:01:21.360> captures<00:01:21.990> the<00:01:22.020> view<00:01:22.439> of

00:01:22.550 --> 00:01:22.560 
line-of-sight it captures the view of

00:01:22.560 --> 00:01:25.460 
line-of-sight it captures the view of
the<00:01:22.740> real<00:01:22.920> world<00:01:23.280> this<00:01:24.060> video<00:01:24.330> is<00:01:24.780> then<00:01:25.140> fed<00:01:25.439> to

00:01:25.460 --> 00:01:25.470 
the real world this video is then fed to

00:01:25.470 --> 00:01:27.710 
the real world this video is then fed to
a<00:01:25.680> computer<00:01:26.400> which<00:01:26.580> is<00:01:26.729> typically<00:01:27.180> carried<00:01:27.540> by

00:01:27.710 --> 00:01:27.720 
a computer which is typically carried by

00:01:27.720 --> 00:01:30.380 
a computer which is typically carried by
the<00:01:27.780> user<00:01:28.110> it's<00:01:28.500> a<00:01:28.619> mobile<00:01:29.369> computer<00:01:29.939> the

00:01:30.380 --> 00:01:30.390 
the user it's a mobile computer the

00:01:30.390 --> 00:01:33.109 
the user it's a mobile computer the
computer<00:01:30.540> is<00:01:31.140> told<00:01:31.470> what<00:01:31.979> virtual<00:01:32.549> objects

00:01:33.109 --> 00:01:33.119 
computer is told what virtual objects

00:01:33.119 --> 00:01:35.420 
computer is told what virtual objects
are<00:01:33.299> to<00:01:33.450> be<00:01:33.570> placed<00:01:33.900> in<00:01:34.229> the<00:01:34.259> real<00:01:34.740> environment

00:01:35.420 --> 00:01:35.430 
are to be placed in the real environment

00:01:35.430 --> 00:01:37.490 
are to be placed in the real environment
what<00:01:35.610> is<00:01:35.640> their<00:01:35.880> location<00:01:36.270> and<00:01:36.750> what<00:01:37.200> is<00:01:37.320> their

00:01:37.490 --> 00:01:37.500 
what is their location and what is their

00:01:37.500 --> 00:01:39.679 
what is their location and what is their
behavior<00:01:38.130> the<00:01:38.579> reason<00:01:38.909> the<00:01:39.000> computer<00:01:39.420> knows

00:01:39.679 --> 00:01:39.689 
behavior the reason the computer knows

00:01:39.689 --> 00:01:42.410 
behavior the reason the computer knows
is<00:01:40.020> because<00:01:40.530> we<00:01:41.310> treat<00:01:41.579> both<00:01:41.820> the<00:01:41.850> real<00:01:42.180> and

00:01:42.410 --> 00:01:42.420 
is because we treat both the real and

00:01:42.420 --> 00:01:44.060 
is because we treat both the real and
the<00:01:42.450> virtual<00:01:42.540> objects<00:01:43.439> using<00:01:43.619> the<00:01:43.829> same

00:01:44.060 --> 00:01:44.070 
the virtual objects using the same

00:01:44.070 --> 00:01:46.550 
the virtual objects using the same
coordinate<00:01:44.729> frame<00:01:45.119> used<00:01:45.600> by<00:01:45.869> the<00:01:45.930> global

00:01:46.550 --> 00:01:46.560 
coordinate frame used by the global

00:01:46.560 --> 00:01:49.700 
coordinate frame used by the global
positioning<00:01:47.070> system<00:01:47.520> or<00:01:47.729> GPS<00:01:48.200> then<00:01:49.200> with<00:01:49.530> the

00:01:49.700 --> 00:01:49.710 
positioning system or GPS then with the

00:01:49.710 --> 00:01:51.649 
positioning system or GPS then with the
algorithms<00:01:50.280> that<00:01:50.610> we<00:01:50.759> have<00:01:50.790> developed<00:01:51.180> the

00:01:51.649 --> 00:01:51.659 
algorithms that we have developed the

00:01:51.659 --> 00:01:53.840 
algorithms that we have developed the
computer<00:01:52.079> generates<00:01:52.680> a<00:01:52.799> composite<00:01:53.310> image<00:01:53.640> and

00:01:53.840 --> 00:01:53.850 
computer generates a composite image and

00:01:53.850 --> 00:01:56.660 
computer generates a composite image and
that<00:01:53.880> image<00:01:54.570> travels<00:01:55.530> to<00:01:55.829> head<00:01:56.250> mounted

00:01:56.660 --> 00:01:56.670 
that image travels to head mounted

00:01:56.670 --> 00:01:59.359 
that image travels to head mounted
display<00:01:57.119> which<00:01:57.420> the<00:01:57.600> user<00:01:57.840> wears<00:01:58.619> to<00:01:59.040> create<00:01:59.340> a

00:01:59.359 --> 00:01:59.369 
display which the user wears to create a

00:01:59.369 --> 00:02:02.179 
display which the user wears to create a
augmented<00:01:59.579> reality<00:02:00.049> visualization<00:02:01.049> so<00:02:01.950> all

00:02:02.179 --> 00:02:02.189 
augmented reality visualization so all

00:02:02.189 --> 00:02:04.520 
augmented reality visualization so all
this<00:02:02.369> planning<00:02:02.880> can<00:02:03.180> be<00:02:03.210> done<00:02:03.719> ahead<00:02:03.930> of<00:02:04.229> time

00:02:04.520 --> 00:02:04.530 
this planning can be done ahead of time

00:02:04.530 --> 00:02:06.560 
this planning can be done ahead of time
in<00:02:04.799> the<00:02:04.979> physical<00:02:05.430> space<00:02:05.729> of<00:02:05.759> the<00:02:06.090> jobsite

00:02:06.560 --> 00:02:06.570 
in the physical space of the jobsite

00:02:06.570 --> 00:02:09.680 
in the physical space of the jobsite
using<00:02:07.380> CAD<00:02:07.649> models<00:02:08.099> the<00:02:08.759> other<00:02:08.879> aspect<00:02:09.420> also

00:02:09.680 --> 00:02:09.690 
using CAD models the other aspect also

00:02:09.690 --> 00:02:12.199 
using CAD models the other aspect also
is<00:02:10.140> that<00:02:10.470> using<00:02:10.950> augmented<00:02:11.220> reality<00:02:11.520> thinks

00:02:12.199 --> 00:02:12.209 
is that using augmented reality thinks

00:02:12.209 --> 00:02:13.670 
is that using augmented reality thinks
that<00:02:12.390> cannot<00:02:12.840> be<00:02:13.050> seen<00:02:13.290> in<00:02:13.440> the

00:02:13.670 --> 00:02:13.680 
that cannot be seen in the

00:02:13.680 --> 00:02:16.339 
that cannot be seen in the
real<00:02:13.769> world<00:02:14.099> can<00:02:14.670> be<00:02:14.909> shown<00:02:15.510> in<00:02:15.750> an<00:02:15.870> augmented

00:02:16.339 --> 00:02:16.349 
real world can be shown in an augmented

00:02:16.349 --> 00:02:18.229 
real world can be shown in an augmented
world<00:02:16.620> and<00:02:16.799> the<00:02:16.859> example<00:02:17.280> for<00:02:17.459> that<00:02:17.640> is<00:02:17.849> the

00:02:18.229 --> 00:02:18.239 
world and the example for that is the

00:02:18.239 --> 00:02:21.500 
world and the example for that is the
location<00:02:18.540> of<00:02:18.780> buried<00:02:19.260> utilities<00:02:20.269> in<00:02:21.269> both

00:02:21.500 --> 00:02:21.510 
location of buried utilities in both

00:02:21.510 --> 00:02:24.170 
location of buried utilities in both
these<00:02:21.659> cases<00:02:21.900> the<00:02:22.890> central<00:02:23.670> idea<00:02:23.909> is<00:02:24.030> that

00:02:24.170 --> 00:02:24.180 
these cases the central idea is that

00:02:24.180 --> 00:02:27.020 
these cases the central idea is that
care<00:02:24.510> models<00:02:25.019> of<00:02:25.290> those<00:02:25.640> elements<00:02:26.640> or<00:02:26.790> those

00:02:27.020 --> 00:02:27.030 
care models of those elements or those

00:02:27.030 --> 00:02:30.170 
care models of those elements or those
objects<00:02:27.659> that<00:02:28.109> are<00:02:28.260> not<00:02:29.000> physically<00:02:30.000> present

00:02:30.170 --> 00:02:30.180 
objects that are not physically present

00:02:30.180 --> 00:02:32.780 
objects that are not physically present
in<00:02:30.510> the<00:02:30.569> real<00:02:30.840> world<00:02:31.200> but<00:02:31.799> you<00:02:32.310> would<00:02:32.459> like<00:02:32.670> to

00:02:32.780 --> 00:02:32.790 
in the real world but you would like to

00:02:32.790 --> 00:02:35.030 
in the real world but you would like to
create<00:02:33.030> an<00:02:33.329> illusion<00:02:33.599> that<00:02:34.079> they<00:02:34.620> are<00:02:34.739> present

00:02:35.030 --> 00:02:35.040 
create an illusion that they are present

00:02:35.040 --> 00:02:37.220 
create an illusion that they are present
in<00:02:35.280> the<00:02:35.430> real<00:02:35.549> world<00:02:35.939> we<00:02:36.389> need<00:02:36.540> to<00:02:36.689> have<00:02:36.870> 3d

00:02:37.220 --> 00:02:37.230 
in the real world we need to have 3d

00:02:37.230 --> 00:02:39.590 
in the real world we need to have 3d
models

