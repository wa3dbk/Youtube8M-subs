WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:02.600 

in<00:00:00.089> this<00:00:00.900> work<00:00:01.199> we<00:00:01.469> address<00:00:01.860> the<00:00:02.040> problem<00:00:02.490> of

00:00:02.600 --> 00:00:02.610 
in this work we address the problem of

00:00:02.610 --> 00:00:04.789 
in this work we address the problem of
person<00:00:03.120> detection<00:00:03.720> and<00:00:03.899> tracking<00:00:04.110> in<00:00:04.500> crowded

00:00:04.789 --> 00:00:04.799 
person detection and tracking in crowded

00:00:04.799 --> 00:00:07.369 
person detection and tracking in crowded
video<00:00:05.220> scenes<00:00:05.609> although<00:00:06.299> the<00:00:06.660> detection<00:00:07.080> of

00:00:07.369 --> 00:00:07.379 
video scenes although the detection of

00:00:07.379 --> 00:00:09.200 
video scenes although the detection of
individual<00:00:07.950> objects<00:00:08.400> has<00:00:08.670> been<00:00:08.849> improved

00:00:09.200 --> 00:00:09.210 
individual objects has been improved

00:00:09.210 --> 00:00:11.270 
individual objects has been improved
significantly<00:00:09.420> over<00:00:10.200> the<00:00:10.230> years<00:00:10.320> crowd

00:00:11.270 --> 00:00:11.280 
significantly over the years crowd

00:00:11.280 --> 00:00:13.310 
significantly over the years crowd
scenes<00:00:11.610> such<00:00:11.820> as<00:00:12.000> these<00:00:12.179> remain<00:00:12.570> particularly

00:00:13.310 --> 00:00:13.320 
scenes such as these remain particularly

00:00:13.320 --> 00:00:14.810 
scenes such as these remain particularly
challenging<00:00:13.889> for<00:00:13.950> the<00:00:14.190> detection<00:00:14.549> and

00:00:14.810 --> 00:00:14.820 
challenging for the detection and

00:00:14.820 --> 00:00:17.390 
challenging for the detection and
tracking<00:00:15.059> tasks<00:00:15.839> due<00:00:16.410> to<00:00:16.590> heavy<00:00:16.770> occlusions

00:00:17.390 --> 00:00:17.400 
tracking tasks due to heavy occlusions

00:00:17.400 --> 00:00:20.000 
tracking tasks due to heavy occlusions
high<00:00:17.970> person<00:00:18.420> densities<00:00:18.900> and<00:00:19.140> significant

00:00:20.000 --> 00:00:20.010 
high person densities and significant

00:00:20.010 --> 00:00:22.700 
high person densities and significant
variation<00:00:20.550> in<00:00:20.640> people's<00:00:21.000> appearance<00:00:21.710> an

00:00:22.700 --> 00:00:22.710 
variation in people's appearance an

00:00:22.710 --> 00:00:24.859 
variation in people's appearance an
example<00:00:23.670> of<00:00:23.760> the<00:00:23.880> challenges<00:00:24.449> posed<00:00:24.750> by

00:00:24.859 --> 00:00:24.869 
example of the challenges posed by

00:00:24.869 --> 00:00:27.230 
example of the challenges posed by
crowds<00:00:25.289> can<00:00:25.560> be<00:00:25.710> seen<00:00:25.949> here<00:00:26.279> where<00:00:26.760> we<00:00:26.880> observe

00:00:27.230 --> 00:00:27.240 
crowds can be seen here where we observe

00:00:27.240 --> 00:00:28.880 
crowds can be seen here where we observe
head<00:00:27.480> detection<00:00:27.990> and<00:00:28.109> tracking<00:00:28.289> results

00:00:28.880 --> 00:00:28.890 
head detection and tracking results

00:00:28.890 --> 00:00:30.560 
head detection and tracking results
obtained<00:00:29.279> using<00:00:29.490> the<00:00:29.760> current<00:00:30.090> state<00:00:30.359> of<00:00:30.390> the

00:00:30.560 --> 00:00:30.570 
obtained using the current state of the

00:00:30.570 --> 00:00:34.370 
obtained using the current state of the
art<00:00:30.599> part<00:00:31.050> based<00:00:31.349> object<00:00:31.949> detector<00:00:33.380> the

00:00:34.370 --> 00:00:34.380 
art part based object detector the

00:00:34.380 --> 00:00:36.319 
art part based object detector the
density<00:00:34.920> of<00:00:35.010> a<00:00:35.100> crowd<00:00:35.370> provides<00:00:35.850> us<00:00:36.030> with<00:00:36.090> an

00:00:36.319 --> 00:00:36.329 
density of a crowd provides us with an

00:00:36.329 --> 00:00:38.180 
density of a crowd provides us with an
additional<00:00:36.870> source<00:00:37.050> of<00:00:37.290> information<00:00:38.010> which

00:00:38.180 --> 00:00:38.190 
additional source of information which

00:00:38.190 --> 00:00:39.979 
additional source of information which
can<00:00:38.370> be<00:00:38.430> used<00:00:38.730> to<00:00:38.850> constrain<00:00:39.329> the<00:00:39.510> difficult

00:00:39.979 --> 00:00:39.989 
can be used to constrain the difficult

00:00:39.989 --> 00:00:41.990 
can be used to constrain the difficult
problem<00:00:40.410> of<00:00:40.530> detecting<00:00:41.129> and<00:00:41.250> tracking<00:00:41.460> people

00:00:41.990 --> 00:00:42.000 
problem of detecting and tracking people

00:00:42.000 --> 00:00:44.660 
problem of detecting and tracking people
in<00:00:42.090> crowded<00:00:42.360> scenes<00:00:43.129> here<00:00:44.129> we<00:00:44.280> see<00:00:44.460> how<00:00:44.610> the

00:00:44.660 --> 00:00:44.670 
in crowded scenes here we see how the

00:00:44.670 --> 00:00:46.850 
in crowded scenes here we see how the
results<00:00:45.120> of<00:00:45.210> crowd<00:00:45.480> density<00:00:45.989> estimation<00:00:46.469> can

00:00:46.850 --> 00:00:46.860 
results of crowd density estimation can

00:00:46.860 --> 00:00:48.560 
results of crowd density estimation can
provide<00:00:47.160> us<00:00:47.340> with<00:00:47.370> global<00:00:48.000> scene<00:00:48.210> level

00:00:48.560 --> 00:00:48.570 
provide us with global scene level

00:00:48.570 --> 00:00:50.330 
provide us with global scene level
information<00:00:48.870> which<00:00:49.800> we<00:00:49.950> use<00:00:50.070> to<00:00:50.100> improve

00:00:50.330 --> 00:00:50.340 
information which we use to improve

00:00:50.340 --> 00:00:52.160 
information which we use to improve
detection<00:00:51.090> and<00:00:51.239> tracking<00:00:51.420> and<00:00:51.750> crowded

00:00:52.160 --> 00:00:52.170 
detection and tracking and crowded

00:00:52.170 --> 00:00:54.319 
detection and tracking and crowded
scenes

00:00:54.319 --> 00:00:54.329 
scenes

00:00:54.329 --> 00:00:56.479 
scenes
we<00:00:54.570> formulate<00:00:55.140> our<00:00:55.170> method<00:00:55.710> in<00:00:55.890> an<00:00:56.070> energy

00:00:56.479 --> 00:00:56.489 
we formulate our method in an energy

00:00:56.489 --> 00:00:58.369 
we formulate our method in an energy
minimization<00:00:56.879> framework<00:00:57.719> which<00:00:57.930> combines

00:00:58.369 --> 00:00:58.379 
minimization framework which combines

00:00:58.379 --> 00:01:00.350 
minimization framework which combines
crowd<00:00:58.739> density<00:00:59.220> estimates<00:00:59.760> with<00:01:00.239> the

00:01:00.350 --> 00:01:00.360 
crowd density estimates with the

00:01:00.360 --> 00:01:02.229 
crowd density estimates with the
strength<00:01:00.660> of<00:01:00.870> individual<00:01:01.410> person<00:01:01.860> detections

00:01:02.229 --> 00:01:02.239 
strength of individual person detections

00:01:02.239 --> 00:01:04.850 
strength of individual person detections
we<00:01:03.239> minimize<00:01:03.629> this<00:01:03.840> energy<00:01:04.290> by<00:01:04.440> jointly

00:01:04.850 --> 00:01:04.860 
we minimize this energy by jointly

00:01:04.860 --> 00:01:07.010 
we minimize this energy by jointly
optimizing<00:01:05.580> the<00:01:05.670> density<00:01:06.180> and<00:01:06.360> the<00:01:06.479> location

00:01:07.010 --> 00:01:07.020 
optimizing the density and the location

00:01:07.020 --> 00:01:09.649 
optimizing the density and the location
of<00:01:07.140> individual<00:01:07.770> people<00:01:07.979> in<00:01:08.220> the<00:01:08.340> crowd<00:01:08.659> the

00:01:09.649 --> 00:01:09.659 
of individual people in the crowd the

00:01:09.659 --> 00:01:11.719 
of individual people in the crowd the
energy<00:01:09.690> function<00:01:10.590> is<00:01:10.740> made<00:01:10.920> up<00:01:11.070> of<00:01:11.190> three<00:01:11.520> main

00:01:11.719 --> 00:01:11.729 
energy function is made up of three main

00:01:11.729 --> 00:01:14.749 
energy function is made up of three main
terms<00:01:12.060> the<00:01:13.050> scores<00:01:13.409> of<00:01:13.590> an<00:01:13.710> object<00:01:14.070> detector<00:01:14.580> a

00:01:14.749 --> 00:01:14.759 
terms the scores of an object detector a

00:01:14.759 --> 00:01:16.609 
terms the scores of an object detector a
pairwise<00:01:15.390> term<00:01:15.840> that<00:01:16.020> penalized<00:01:16.470> is

00:01:16.609 --> 00:01:16.619 
pairwise term that penalized is

00:01:16.619 --> 00:01:18.950 
pairwise term that penalized is
overlapping<00:01:17.070> windows<00:01:17.610> and<00:01:17.850> an<00:01:18.390> in<00:01:18.540> term<00:01:18.750> that

00:01:18.950 --> 00:01:18.960 
overlapping windows and an in term that

00:01:18.960 --> 00:01:22.550 
overlapping windows and an in term that
incorporates<00:01:19.229> crowd<00:01:19.770> density<00:01:21.170> given<00:01:22.170> a<00:01:22.320> crowd

00:01:22.550 --> 00:01:22.560 
incorporates crowd density given a crowd

00:01:22.560 --> 00:01:24.649 
incorporates crowd density given a crowd
density<00:01:23.100> estimate<00:01:23.580> seen<00:01:23.850> on<00:01:24.000> the<00:01:24.119> left<00:01:24.300> and

00:01:24.649 --> 00:01:24.659 
density estimate seen on the left and

00:01:24.659 --> 00:01:26.930 
density estimate seen on the left and
color<00:01:24.869> coded<00:01:25.259> blue<00:01:25.430> detections<00:01:26.430> which<00:01:26.789> are

00:01:26.930 --> 00:01:26.940 
color coded blue detections which are

00:01:26.940 --> 00:01:28.460 
color coded blue detections which are
consistent<00:01:27.300> with<00:01:27.570> the<00:01:27.750> overall<00:01:27.780> scene

00:01:28.460 --> 00:01:28.470 
consistent with the overall scene

00:01:28.470 --> 00:01:30.770 
consistent with the overall scene
density<00:01:29.009> are<00:01:29.160> selected<00:01:29.729> seen<00:01:30.390> here<00:01:30.600> in<00:01:30.690> the

00:01:30.770 --> 00:01:30.780 
density are selected seen here in the

00:01:30.780 --> 00:01:32.990 
density are selected seen here in the
middle<00:01:31.020> the<00:01:31.860> crowd<00:01:32.100> density<00:01:32.310> that<00:01:32.670> arises

00:01:32.990 --> 00:01:33.000 
middle the crowd density that arises

00:01:33.000 --> 00:01:35.060 
middle the crowd density that arises
from<00:01:33.179> the<00:01:33.450> selected<00:01:33.929> detections<00:01:34.289> can<00:01:34.740> be<00:01:34.860> seen

00:01:35.060 --> 00:01:35.070 
from the selected detections can be seen

00:01:35.070 --> 00:01:37.630 
from the selected detections can be seen
on<00:01:35.190> the<00:01:35.310> right<00:01:35.520> and<00:01:35.820> it's<00:01:36.000> color<00:01:36.210> coded<00:01:36.600> red

00:01:37.630 --> 00:01:37.640 
on the right and it's color coded red

00:01:37.640 --> 00:01:40.100 
on the right and it's color coded red
minimizing<00:01:38.640> this<00:01:38.759> energy<00:01:39.240> function<00:01:39.750> implies

00:01:40.100 --> 00:01:40.110 
minimizing this energy function implies

00:01:40.110 --> 00:01:41.779 
minimizing this energy function implies
reducing<00:01:40.710> the<00:01:40.800> difference<00:01:41.220> in<00:01:41.369> person

00:01:41.779 --> 00:01:41.789 
reducing the difference in person

00:01:41.789 --> 00:01:43.430 
reducing the difference in person
density<00:01:42.210> estimates<00:01:42.690> obtained<00:01:43.200> by<00:01:43.380> the

00:01:43.430 --> 00:01:43.440 
density estimates obtained by the

00:01:43.440 --> 00:01:45.830 
density estimates obtained by the
estimator<00:01:44.009> and<00:01:44.280> by<00:01:44.670> local<00:01:44.880> counting<00:01:45.450> person

00:01:45.830 --> 00:01:45.840 
estimator and by local counting person

00:01:45.840 --> 00:01:50.960 
estimator and by local counting person
detections

00:01:50.960 --> 00:01:50.970 

00:01:50.970 --> 00:01:53.370 

here<00:01:51.970> we<00:01:52.120> see<00:01:52.330> the<00:01:52.480> detection<00:01:53.020> and<00:01:53.200> tracking

00:01:53.370 --> 00:01:53.380 
here we see the detection and tracking

00:01:53.380 --> 00:01:55.410 
here we see the detection and tracking
results<00:01:53.740> obtained<00:01:54.670> by<00:01:54.790> using<00:01:55.060> geometric

00:01:55.410 --> 00:01:55.420 
results obtained by using geometric

00:01:55.420 --> 00:01:57.330 
results obtained by using geometric
filtering<00:01:56.260> and<00:01:56.380> agglomerative<00:01:57.160> clustering

00:01:57.330 --> 00:01:57.340 
filtering and agglomerative clustering

00:01:57.340 --> 00:02:00.060 
filtering and agglomerative clustering
on<00:01:58.000> the<00:01:58.120> left<00:01:58.360> and<00:01:58.660> using<00:01:59.350> the<00:01:59.440> proposed<00:01:59.800> joint

00:02:00.060 --> 00:02:00.070 
on the left and using the proposed joint

00:02:00.070 --> 00:02:01.770 
on the left and using the proposed joint
density<00:02:00.610> and<00:02:00.730> detection<00:02:01.030> framework<00:02:01.600> on<00:02:01.750> the

00:02:01.770 --> 00:02:01.780 
density and detection framework on the

00:02:01.780 --> 00:02:02.990 
density and detection framework on the
right

00:02:02.990 --> 00:02:03.000 
right

00:02:03.000 --> 00:02:06.090 
right
yellow<00:02:04.000> bounding<00:02:04.480> boxes<00:02:04.930> indicate<00:02:05.530> incorrect

00:02:06.090 --> 00:02:06.100 
yellow bounding boxes indicate incorrect

00:02:06.100 --> 00:02:11.010 
yellow bounding boxes indicate incorrect
tracks

00:02:11.010 --> 00:02:11.020 

00:02:11.020 --> 00:02:13.450 

these<00:02:12.020> results<00:02:12.260> demonstrate<00:02:13.160> how<00:02:13.400> the

00:02:13.450 --> 00:02:13.460 
these results demonstrate how the

00:02:13.460 --> 00:02:15.480 
these results demonstrate how the
optimization<00:02:13.700> of<00:02:14.450> such<00:02:14.660> an<00:02:14.810> energy<00:02:15.230> function

00:02:15.480 --> 00:02:15.490 
optimization of such an energy function

00:02:15.490 --> 00:02:17.890 
optimization of such an energy function
significantly<00:02:16.490> improves<00:02:16.940> person<00:02:17.390> detection

00:02:17.890 --> 00:02:17.900 
significantly improves person detection

00:02:17.900 --> 00:02:21.670 
significantly improves person detection
and<00:02:18.080> tracking<00:02:18.350> in<00:02:18.710> crowds<00:02:20.350> here<00:02:21.350> we<00:02:21.500> see

00:02:21.670 --> 00:02:21.680 
and tracking in crowds here we see

00:02:21.680 --> 00:02:23.860 
and tracking in crowds here we see
results<00:02:21.860> for<00:02:22.310> a<00:02:22.370> wide<00:02:22.610> field-of-view<00:02:23.210> crowded

00:02:23.860 --> 00:02:23.870 
results for a wide field-of-view crowded

00:02:23.870 --> 00:02:28.060 
results for a wide field-of-view crowded
sequence<00:02:26.020> we<00:02:27.020> have<00:02:27.050> shown<00:02:27.440> that<00:02:27.590> density

00:02:28.060 --> 00:02:28.070 
sequence we have shown that density

00:02:28.070 --> 00:02:29.530 
sequence we have shown that density
estimation<00:02:28.550> can<00:02:28.940> be<00:02:29.060> used<00:02:29.240> to<00:02:29.450> improve

00:02:29.530 --> 00:02:29.540 
estimation can be used to improve

00:02:29.540 --> 00:02:31.300 
estimation can be used to improve
detection<00:02:30.260> and<00:02:30.410> tracking<00:02:30.560> and<00:02:30.890> crowded

00:02:31.300 --> 00:02:31.310 
detection and tracking and crowded

00:02:31.310 --> 00:02:33.880 
detection and tracking and crowded
scenes<00:02:31.610> our<00:02:32.060> our<00:02:32.450> energy<00:02:32.990> formulation<00:02:33.530> is

00:02:33.880 --> 00:02:33.890 
scenes our our energy formulation is

00:02:33.890 --> 00:02:35.380 
scenes our our energy formulation is
general<00:02:34.310> enough<00:02:34.550> to<00:02:34.610> allow<00:02:35.090> for<00:02:35.120> the

00:02:35.380 --> 00:02:35.390 
general enough to allow for the

00:02:35.390 --> 00:02:37.270 
general enough to allow for the
incorporation<00:02:35.930> of<00:02:36.200> additional<00:02:36.680> constraints

00:02:37.270 --> 00:02:37.280 
incorporation of additional constraints

00:02:37.280 --> 00:02:39.400 
incorporation of additional constraints
please<00:02:38.150> see<00:02:38.360> the<00:02:38.480> paper<00:02:38.690> for<00:02:38.930> quantitative

00:02:39.400 --> 00:02:39.410 
please see the paper for quantitative

00:02:39.410 --> 00:02:42.130 
please see the paper for quantitative
analysis

