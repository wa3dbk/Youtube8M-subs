WEBVTT
Kind: captions
Language: en

00:00:03.260 --> 00:00:06.230 

we<00:00:04.260> present<00:00:04.440> an<00:00:04.800> augmented<00:00:05.340> reality<00:00:05.790> x-ray

00:00:06.230 --> 00:00:06.240 
we present an augmented reality x-ray

00:00:06.240 --> 00:00:09.370 
we present an augmented reality x-ray
system<00:00:06.660> based<00:00:07.290> on<00:00:07.529> visual<00:00:07.710> say<00:00:08.100> Lancet

00:00:09.370 --> 00:00:09.380 
system based on visual say Lancet

00:00:09.380 --> 00:00:12.590 
system based on visual say Lancet
augmented<00:00:10.380> reality<00:00:10.800> x-ray<00:00:11.220> and<00:00:11.600> visualizing

00:00:12.590 --> 00:00:12.600 
augmented reality x-ray and visualizing

00:00:12.600 --> 00:00:15.050 
augmented reality x-ray and visualizing
occluded<00:00:13.080> points<00:00:13.380> of<00:00:13.500> interest<00:00:13.820> when<00:00:14.820> a<00:00:14.850> user

00:00:15.050 --> 00:00:15.060 
occluded points of interest when a user

00:00:15.060 --> 00:00:17.330 
occluded points of interest when a user
looks<00:00:15.360> at<00:00:15.480> a<00:00:15.540> wall<00:00:15.780> and<00:00:15.810> the<00:00:16.590> area<00:00:16.920> behind<00:00:17.100> the

00:00:17.330 --> 00:00:17.340 
looks at a wall and the area behind the

00:00:17.340 --> 00:00:19.880 
looks at a wall and the area behind the
wall<00:00:17.580> has<00:00:17.820> been<00:00:17.850> modeled<00:00:18.330> in<00:00:18.480> advance<00:00:18.810> we<00:00:19.710> can

00:00:19.880 --> 00:00:19.890 
wall has been modeled in advance we can

00:00:19.890 --> 00:00:21.800 
wall has been modeled in advance we can
combine<00:00:20.070> the<00:00:20.369> users<00:00:20.699> view<00:00:20.939> with<00:00:21.300> the<00:00:21.330> occluded

00:00:21.800 --> 00:00:21.810 
combine the users view with the occluded

00:00:21.810 --> 00:00:24.950 
combine the users view with the occluded
area<00:00:22.169> in<00:00:22.640> our<00:00:23.640> previous<00:00:23.849> augmented<00:00:24.570> reality

00:00:24.950 --> 00:00:24.960 
area in our previous augmented reality

00:00:24.960 --> 00:00:26.839 
area in our previous augmented reality
x-ray<00:00:25.320> system<00:00:25.679> we<00:00:26.189> have<00:00:26.279> highlighted<00:00:26.490> the

00:00:26.839 --> 00:00:26.849 
x-ray system we have highlighted the

00:00:26.849 --> 00:00:29.029 
x-ray system we have highlighted the
edges<00:00:27.210> of<00:00:27.240> the<00:00:27.419> foreground<00:00:27.839> area<00:00:28.199> in<00:00:28.409> order<00:00:28.919> to

00:00:29.029 --> 00:00:29.039 
edges of the foreground area in order to

00:00:29.039 --> 00:00:30.859 
edges of the foreground area in order to
support<00:00:29.159> correct<00:00:29.759> depth<00:00:30.150> perception<00:00:30.749> of

00:00:30.859 --> 00:00:30.869 
support correct depth perception of

00:00:30.869 --> 00:00:34.340 
support correct depth perception of
these<00:00:31.289> two<00:00:31.439> layers<00:00:32.480> while<00:00:33.480> depth<00:00:33.810> perception

00:00:34.340 --> 00:00:34.350 
these two layers while depth perception

00:00:34.350 --> 00:00:36.410 
these two layers while depth perception
was<00:00:34.470> improved<00:00:34.829> significantly<00:00:35.420> information

00:00:36.410 --> 00:00:36.420 
was improved significantly information

00:00:36.420 --> 00:00:38.660 
was improved significantly information
about<00:00:36.570> landmarks<00:00:37.140> could<00:00:37.350> get<00:00:37.500> lost<00:00:37.739> for

00:00:38.660 --> 00:00:38.670 
about landmarks could get lost for

00:00:38.670 --> 00:00:40.160 
about landmarks could get lost for
example<00:00:39.059> the<00:00:39.180> color<00:00:39.329> information<00:00:39.690> of<00:00:40.079> the

00:00:40.160 --> 00:00:40.170 
example the color information of the

00:00:40.170 --> 00:00:44.060 
example the color information of the
permit<00:00:40.530> side<00:00:40.739> side<00:00:41.039> has<00:00:41.519> been<00:00:41.760> lost<00:00:42.559> our<00:00:43.559> novel

00:00:44.060 --> 00:00:44.070 
permit side side has been lost our novel

00:00:44.070 --> 00:00:45.529 
permit side side has been lost our novel
system<00:00:44.430> preserves<00:00:44.879> the<00:00:45.059> color<00:00:45.239> information

00:00:45.529 --> 00:00:45.539 
system preserves the color information

00:00:45.539 --> 00:00:50.180 
system preserves the color information
of<00:00:45.960> important<00:00:46.440> foreground<00:00:46.829> objects<00:00:48.679> here<00:00:49.679> we

00:00:50.180 --> 00:00:50.190 
of important foreground objects here we

00:00:50.190 --> 00:00:52.040 
of important foreground objects here we
show<00:00:50.370> a<00:00:50.399> user<00:00:50.760> employing<00:00:51.239> our<00:00:51.449> system<00:00:51.840> on<00:00:51.989> a

00:00:52.040 --> 00:00:52.050 
show a user employing our system on a

00:00:52.050 --> 00:00:55.009 
show a user employing our system on a
handheld<00:00:52.469> screen<00:00:52.859> we<00:00:53.730> employ<00:00:54.030> PTM<00:00:54.539> for

00:00:55.009 --> 00:00:55.019 
handheld screen we employ PTM for

00:00:55.019 --> 00:00:56.660 
handheld screen we employ PTM for
tracking<00:00:55.230> the<00:00:55.469> screen<00:00:55.739> in<00:00:55.920> six<00:00:56.219> degrees<00:00:56.370> of

00:00:56.660 --> 00:00:56.670 
tracking the screen in six degrees of

00:00:56.670 --> 00:01:04.680 
tracking the screen in six degrees of
freedom

00:01:04.680 --> 00:01:04.690 

00:01:04.690 --> 00:01:11.279 

you

00:01:11.279 --> 00:01:11.289 

00:01:11.289 --> 00:01:13.719 

naively<00:01:12.289> rendering<00:01:12.829> the<00:01:12.979> occluded<00:01:13.399> region

00:01:13.719 --> 00:01:13.729 
naively rendering the occluded region

00:01:13.729 --> 00:01:15.639 
naively rendering the occluded region
fails<00:01:14.359> to<00:01:14.509> convey<00:01:14.780> the<00:01:14.990> correct<00:01:15.320> depth

00:01:15.639 --> 00:01:15.649 
fails to convey the correct depth

00:01:15.649 --> 00:01:17.889 
fails to convey the correct depth
relation<00:01:16.359> making<00:01:17.359> the<00:01:17.479> foreground

00:01:17.889 --> 00:01:17.899 
relation making the foreground

00:01:17.899 --> 00:01:19.899 
relation making the foreground
semi-transparent<00:01:18.530> only<00:01:19.280> confounds<00:01:19.789> the

00:01:19.899 --> 00:01:19.909 
semi-transparent only confounds the

00:01:19.909 --> 00:01:22.690 
semi-transparent only confounds the
image<00:01:20.560> our<00:01:21.560> previous<00:01:22.039> system<00:01:22.369> which

00:01:22.690 --> 00:01:22.700 
image our previous system which

00:01:22.700 --> 00:01:25.209 
image our previous system which
highlights<00:01:23.119> edges<00:01:23.539> foreground<00:01:24.140> objects<00:01:24.619> can

00:01:25.209 --> 00:01:25.219 
highlights edges foreground objects can

00:01:25.219 --> 00:01:27.370 
highlights edges foreground objects can
lose<00:01:25.429> foreground<00:01:25.939> information<00:01:26.509> and<00:01:26.750> increase

00:01:27.370 --> 00:01:27.380 
lose foreground information and increase

00:01:27.380 --> 00:01:29.810 
lose foreground information and increase
visual<00:01:27.709> noise

00:01:29.810 --> 00:01:29.820 
visual noise

00:01:29.820 --> 00:01:32.130 
visual noise
our<00:01:30.820> novel<00:01:31.270> approach<00:01:31.570> selectively

00:01:32.130 --> 00:01:32.140 
our novel approach selectively

00:01:32.140 --> 00:01:34.080 
our novel approach selectively
emphasizes<00:01:32.950> important<00:01:33.430> features<00:01:33.790> in<00:01:34.000> the

00:01:34.080 --> 00:01:34.090 
emphasizes important features in the

00:01:34.090 --> 00:01:36.030 
emphasizes important features in the
foreground<00:01:34.480> for<00:01:35.290> example<00:01:35.710> the<00:01:35.830> bright

00:01:36.030 --> 00:01:36.040 
foreground for example the bright

00:01:36.040 --> 00:01:38.760 
foreground for example the bright
umbrellas<00:01:36.720> notice<00:01:37.720> how<00:01:37.870> important<00:01:38.380> features

00:01:38.760 --> 00:01:38.770 
umbrellas notice how important features

00:01:38.770 --> 00:01:40.800 
umbrellas notice how important features
are<00:01:38.980> preserved<00:01:39.370> and<00:01:39.610> visual<00:01:40.060> complexity<00:01:40.510> is

00:01:40.800 --> 00:01:40.810 
are preserved and visual complexity is

00:01:40.810 --> 00:01:43.410 
are preserved and visual complexity is
reduced<00:01:41.200> we<00:01:42.190> now<00:01:42.370> present<00:01:42.610> the<00:01:42.880> underlying

00:01:43.410 --> 00:01:43.420 
reduced we now present the underlying

00:01:43.420 --> 00:01:46.410 
reduced we now present the underlying
method<00:01:43.840> of<00:01:43.960> our<00:01:44.170> novel<00:01:44.470> x-ray<00:01:44.860> system<00:01:45.250> this<00:01:46.150> is

00:01:46.410 --> 00:01:46.420 
method of our novel x-ray system this is

00:01:46.420 --> 00:01:48.840 
method of our novel x-ray system this is
the<00:01:46.570> raw<00:01:46.720> video<00:01:47.130> next<00:01:48.130> we<00:01:48.430> show<00:01:48.670> the

00:01:48.840 --> 00:01:48.850 
the raw video next we show the

00:01:48.850 --> 00:01:51.090 
the raw video next we show the
individual<00:01:49.420> saliency<00:01:50.050> maps<00:01:50.290> that<00:01:50.590> we<00:01:50.770> extract

00:01:51.090 --> 00:01:51.100 
individual saliency maps that we extract

00:01:51.100 --> 00:01:54.720 
individual saliency maps that we extract
from<00:01:51.370> it<00:01:52.650> first<00:01:53.650> we<00:01:53.920> compute<00:01:54.250> the<00:01:54.370> luminance

00:01:54.720 --> 00:01:54.730 
from it first we compute the luminance

00:01:54.730 --> 00:01:56.910 
from it first we compute the luminance
map<00:01:54.970> which<00:01:55.570> indicates<00:01:56.140> objects<00:01:56.560> with<00:01:56.740> high

00:01:56.910 --> 00:01:56.920 
map which indicates objects with high

00:01:56.920 --> 00:02:04.969 
map which indicates objects with high
brightness

00:02:04.969 --> 00:02:04.979 

00:02:04.979 --> 00:02:07.560 

then<00:02:05.979> we<00:02:06.549> compute<00:02:06.850> maps<00:02:07.149> for<00:02:07.390> color

00:02:07.560 --> 00:02:07.570 
then we compute maps for color

00:02:07.570 --> 00:02:10.139 
then we compute maps for color
apprentices<00:02:08.200> this<00:02:09.009> example<00:02:09.399> shows<00:02:09.610> the

00:02:10.139 --> 00:02:10.149 
apprentices this example shows the

00:02:10.149 --> 00:02:15.330 
apprentices this example shows the
red-green<00:02:10.629> Epona<00:02:11.019> see<00:02:11.230> map<00:02:13.830> similarly<00:02:14.830> we

00:02:15.330 --> 00:02:15.340 
red-green Epona see map similarly we

00:02:15.340 --> 00:02:17.369 
red-green Epona see map similarly we
identify<00:02:15.819> moving<00:02:16.180> objects<00:02:16.629> through<00:02:16.900> a<00:02:16.930> motion

00:02:17.369 --> 00:02:17.379 
identify moving objects through a motion

00:02:17.379 --> 00:02:20.670 
identify moving objects through a motion
map

00:02:20.670 --> 00:02:20.680 

00:02:20.680 --> 00:02:23.950 

we<00:02:21.680> then<00:02:21.890> combine<00:02:22.310> all<00:02:22.580> saline<00:02:23.030> see<00:02:23.210> maps<00:02:23.450> to

00:02:23.950 --> 00:02:23.960 
we then combine all saline see maps to

00:02:23.960 --> 00:02:25.570 
we then combine all saline see maps to
compute<00:02:24.290> the<00:02:24.320> overall<00:02:24.860> salience<00:02:25.310> II<00:02:25.400> of<00:02:25.550> the

00:02:25.570 --> 00:02:25.580 
compute the overall salience II of the

00:02:25.580 --> 00:02:31.470 
compute the overall salience II of the
image

00:02:31.470 --> 00:02:31.480 

00:02:31.480 --> 00:02:34.120 

finally<00:02:32.480> foreground<00:02:33.170> and<00:02:33.440> background<00:02:33.530> are

00:02:34.120 --> 00:02:34.130 
finally foreground and background are

00:02:34.130 --> 00:02:35.590 
finally foreground and background are
blended<00:02:34.520> according<00:02:35.030> to<00:02:35.180> the<00:02:35.300> overall

00:02:35.590 --> 00:02:35.600 
blended according to the overall

00:02:35.600 --> 00:02:38.080 
blended according to the overall
saliency<00:02:36.170> map<00:02:36.380> the<00:02:37.160> inset<00:02:37.580> shows<00:02:37.640> our

00:02:38.080 --> 00:02:38.090 
saliency map the inset shows our

00:02:38.090 --> 00:02:47.430 
saliency map the inset shows our
previous<00:02:38.510> system<00:02:38.840> for<00:02:39.050> comparison

00:02:47.430 --> 00:02:47.440 

00:02:47.440 --> 00:02:51.410 

you

00:02:51.410 --> 00:02:51.420 

00:02:51.420 --> 00:02:53.660 

to<00:02:52.200> further<00:02:52.410> illustrate<00:02:52.650> the<00:02:53.040> capabilities

00:02:53.660 --> 00:02:53.670 
to further illustrate the capabilities

00:02:53.670 --> 00:02:55.910 
to further illustrate the capabilities
of<00:02:53.700> our<00:02:53.910> novel<00:02:54.240> x-ray<00:02:54.599> method<00:02:54.959> we<00:02:55.470> now<00:02:55.680> show

00:02:55.910 --> 00:02:55.920 
of our novel x-ray method we now show

00:02:55.920 --> 00:02:58.010 
of our novel x-ray method we now show
three<00:02:56.280> test<00:02:56.580> cases<00:02:56.819> to<00:02:57.120> highlight<00:02:57.450> how<00:02:57.599> motion

00:02:58.010 --> 00:02:58.020 
three test cases to highlight how motion

00:02:58.020 --> 00:02:59.870 
three test cases to highlight how motion
color<00:02:58.349> and<00:02:58.620> brightness<00:02:58.800> of<00:02:59.400> foreground

00:02:59.870 --> 00:02:59.880 
color and brightness of foreground

00:02:59.880 --> 00:03:01.809 
color and brightness of foreground
objects<00:03:00.330> affect<00:03:00.660> the<00:03:00.750> final<00:03:00.930> composition

00:03:01.809 --> 00:03:01.819 
objects affect the final composition

00:03:01.819 --> 00:03:05.510 
objects affect the final composition
first<00:03:02.819> motion<00:03:03.500> note<00:03:04.500> how<00:03:04.709> a<00:03:04.739> walking<00:03:05.130> person

00:03:05.510 --> 00:03:05.520 
first motion note how a walking person

00:03:05.520 --> 00:03:11.699 
first motion note how a walking person
disappears<00:03:06.060> when<00:03:06.330> stopping

00:03:11.699 --> 00:03:11.709 

00:03:11.709 --> 00:03:14.860 

4-color<00:03:12.730> notice<00:03:13.730> how<00:03:13.850> strong<00:03:14.240> foreground

00:03:14.860 --> 00:03:14.870 
4-color notice how strong foreground

00:03:14.870 --> 00:03:16.990 
4-color notice how strong foreground
colors<00:03:15.260> such<00:03:15.830> as<00:03:15.860> yellow<00:03:16.280> and<00:03:16.550> red<00:03:16.730> are

00:03:16.990 --> 00:03:17.000 
colors such as yellow and red are

00:03:17.000 --> 00:03:19.570 
colors such as yellow and red are
preserved<00:03:17.569> weak<00:03:18.440> colors<00:03:18.830> such<00:03:19.010> as<00:03:19.040> green<00:03:19.400> and

00:03:19.570 --> 00:03:19.580 
preserved weak colors such as green and

00:03:19.580 --> 00:03:26.080 
preserved weak colors such as green and
blue<00:03:19.730> are<00:03:20.060> suppressed

00:03:26.080 --> 00:03:26.090 

00:03:26.090 --> 00:03:28.970 

brightness<00:03:27.349> notice<00:03:28.349> how<00:03:28.499> changes<00:03:28.950> in

00:03:28.970 --> 00:03:28.980 
brightness notice how changes in

00:03:28.980 --> 00:03:31.190 
brightness notice how changes in
illumination<00:03:29.609> affect<00:03:30.299> the<00:03:30.450> visibility<00:03:30.959> of

00:03:31.190 --> 00:03:31.200 
illumination affect the visibility of

00:03:31.200 --> 00:03:32.869 
illumination affect the visibility of
yellow<00:03:31.469> and<00:03:31.739> red<00:03:31.950> services<00:03:32.549> in<00:03:32.790> the

00:03:32.869 --> 00:03:32.879 
yellow and red services in the

00:03:32.879 --> 00:03:37.009 
yellow and red services in the
foreground<00:03:34.939> we<00:03:35.939> have<00:03:36.120> compared<00:03:36.510> our<00:03:36.659> novel

00:03:37.009 --> 00:03:37.019 
foreground we have compared our novel

00:03:37.019 --> 00:03:39.199 
foreground we have compared our novel
salen<00:03:37.590> sea<00:03:37.709> based<00:03:37.950> system<00:03:38.430> with<00:03:38.849> our<00:03:38.969> previous

00:03:39.199 --> 00:03:39.209 
salen sea based system with our previous

00:03:39.209 --> 00:03:41.059 
salen sea based system with our previous
edge<00:03:39.569> overlay<00:03:40.079> system<00:03:40.139> through<00:03:40.769> empirical

00:03:41.059 --> 00:03:41.069 
edge overlay system through empirical

00:03:41.069 --> 00:03:43.670 
edge overlay system through empirical
user<00:03:41.459> studies<00:03:41.849> our<00:03:42.750> first<00:03:43.109> study<00:03:43.379> was<00:03:43.650> a

00:03:43.670 --> 00:03:43.680 
user studies our first study was a

00:03:43.680 --> 00:03:46.309 
user studies our first study was a
target<00:03:44.099> acquisition<00:03:44.280> task<00:03:45.200> participants<00:03:46.200> had

00:03:46.309 --> 00:03:46.319 
target acquisition task participants had

00:03:46.319 --> 00:03:47.809 
target acquisition task participants had
to<00:03:46.439> click<00:03:46.650> on<00:03:46.829> a<00:03:46.859> red<00:03:47.099> circle<00:03:47.340> in<00:03:47.700> the

00:03:47.809 --> 00:03:47.819 
to click on a red circle in the

00:03:47.819 --> 00:03:50.000 
to click on a red circle in the
background<00:03:48.269> of<00:03:48.359> the<00:03:48.510> scene<00:03:48.750> for<00:03:49.349> a<00:03:49.379> variety<00:03:49.650> of

00:03:50.000 --> 00:03:50.010 
background of the scene for a variety of

00:03:50.010 --> 00:03:53.119 
background of the scene for a variety of
selected<00:03:50.459> for<00:03:50.669> grounds<00:03:51.019> in<00:03:52.019> the<00:03:52.290> following<00:03:52.500> we

00:03:53.119 --> 00:03:53.129 
selected for grounds in the following we

00:03:53.129 --> 00:03:55.159 
selected for grounds in the following we
show<00:03:53.340> a<00:03:53.370> reenactment<00:03:54.060> of<00:03:54.239> a<00:03:54.299> participant<00:03:54.900> with

00:03:55.159 --> 00:03:55.169 
show a reenactment of a participant with

00:03:55.169 --> 00:04:03.880 
show a reenactment of a participant with
falling<00:03:55.469> the<00:03:55.590> experimental<00:03:56.189> task

00:04:03.880 --> 00:04:03.890 

00:04:03.890 --> 00:04:35.119 

you

00:04:35.119 --> 00:04:35.129 

00:04:35.129 --> 00:04:37.369 

the<00:04:35.669> first<00:04:35.969> study<00:04:36.239> showed<00:04:36.749> that<00:04:36.779> although<00:04:37.199> our

00:04:37.369 --> 00:04:37.379 
the first study showed that although our

00:04:37.379 --> 00:04:39.469 
the first study showed that although our
model<00:04:37.709> system<00:04:38.039> provides<00:04:38.429> a<00:04:38.580> richer<00:04:38.909> context

00:04:39.469 --> 00:04:39.479 
model system provides a richer context

00:04:39.479 --> 00:04:41.540 
model system provides a richer context
of<00:04:39.599> the<00:04:39.749> occluder<00:04:40.139> object<00:04:40.559> it<00:04:40.709> does<00:04:41.369> not

00:04:41.540 --> 00:04:41.550 
of the occluder object it does not

00:04:41.550 --> 00:04:43.549 
of the occluder object it does not
impede<00:04:41.909> users<00:04:42.360> to<00:04:42.509> select<00:04:42.719> objects<00:04:43.349> in<00:04:43.469> the

00:04:43.549 --> 00:04:43.559 
impede users to select objects in the

00:04:43.559 --> 00:04:46.489 
impede users to select objects in the
occluded<00:04:43.979> area<00:04:44.309> we<00:04:45.269> can<00:04:45.449> identify<00:04:45.569> a<00:04:45.929> problem

00:04:46.489 --> 00:04:46.499 
occluded area we can identify a problem

00:04:46.499 --> 00:04:48.979 
occluded area we can identify a problem
in<00:04:46.619> our<00:04:46.709> prototype<00:04:47.330> the<00:04:48.330> high<00:04:48.509> levels<00:04:48.929> of

00:04:48.979 --> 00:04:48.989 
in our prototype the high levels of

00:04:48.989 --> 00:04:51.079 
in our prototype the high levels of
brightness<00:04:49.169> had<00:04:49.709> an<00:04:49.860> adverse<00:04:50.069> effect<00:04:50.639> on<00:04:50.789> sale

00:04:51.079 --> 00:04:51.089 
brightness had an adverse effect on sale

00:04:51.089 --> 00:04:53.989 
brightness had an adverse effect on sale
nc-based<00:04:51.389> x-ray<00:04:52.019> in<00:04:52.289> the<00:04:53.279> bright<00:04:53.489> portion<00:04:53.909> of

00:04:53.989 --> 00:04:53.999 
nc-based x-ray in the bright portion of

00:04:53.999 --> 00:04:56.029 
nc-based x-ray in the bright portion of
the<00:04:54.119> x-rayed<00:04:54.539> region<00:04:54.929> target<00:04:55.469> objects<00:04:55.919> were

00:04:56.029 --> 00:04:56.039 
the x-rayed region target objects were

00:04:56.039 --> 00:04:58.639 
the x-rayed region target objects were
hard<00:04:56.279> to<00:04:56.399> locate<00:04:56.659> however<00:04:57.659> in<00:04:57.959> the<00:04:58.289> darker

00:04:58.639 --> 00:04:58.649 
hard to locate however in the darker

00:04:58.649 --> 00:05:03.009 
hard to locate however in the darker
x-rayed<00:04:59.099> region<00:04:59.489> it<00:05:00.089> was<00:05:00.300> clearly<00:05:00.569> visible

00:05:03.009 --> 00:05:03.019 

00:05:03.019 --> 00:05:05.809 

next<00:05:04.019> we<00:05:04.379> show<00:05:04.589> a<00:05:04.619> reenacted<00:05:05.159> version<00:05:05.519> of<00:05:05.699> our

00:05:05.809 --> 00:05:05.819 
next we show a reenacted version of our

00:05:05.819 --> 00:05:08.779 
next we show a reenacted version of our
second<00:05:06.149> study<00:05:06.330> an<00:05:06.539> online<00:05:07.349> survey<00:05:07.789> we

00:05:08.779 --> 00:05:08.789 
second study an online survey we

00:05:08.789 --> 00:05:10.999 
second study an online survey we
instructed<00:05:09.209> respondents<00:05:09.749> to<00:05:09.779> do<00:05:09.929> AC<00:05:10.110> perceive

00:05:10.999 --> 00:05:11.009 
instructed respondents to do AC perceive

00:05:11.009 --> 00:05:14.059 
instructed respondents to do AC perceive
mark<00:05:11.610> task<00:05:12.059> the<00:05:13.019> images<00:05:13.379> were<00:05:13.559> presented<00:05:14.039> to

00:05:14.059 --> 00:05:14.069 
mark task the images were presented to

00:05:14.069 --> 00:05:16.429 
mark task the images were presented to
respondents<00:05:14.669> one<00:05:14.819> at<00:05:14.909> a<00:05:14.969> time<00:05:15.439> after

00:05:16.429 --> 00:05:16.439 
respondents one at a time after

00:05:16.439 --> 00:05:17.409 
respondents one at a time after
observing<00:05:16.649> the<00:05:16.889> image<00:05:17.099> carefully

00:05:17.409 --> 00:05:17.419 
observing the image carefully

00:05:17.419 --> 00:05:19.820 
observing the image carefully
respondents<00:05:18.419> had<00:05:18.569> to<00:05:18.719> score<00:05:18.959> on<00:05:19.169> a<00:05:19.199> scale<00:05:19.499> of<00:05:19.529> 1

00:05:19.820 --> 00:05:19.830 
respondents had to score on a scale of 1

00:05:19.830 --> 00:05:21.619 
respondents had to score on a scale of 1
to<00:05:19.949> 10<00:05:20.009> how<00:05:20.399> well<00:05:20.819> the<00:05:21.029> image<00:05:21.269> conveyed

00:05:21.619 --> 00:05:21.629 
to 10 how well the image conveyed

00:05:21.629 --> 00:05:23.209 
to 10 how well the image conveyed
information<00:05:21.929> for<00:05:22.589> foreground<00:05:23.039> and

00:05:23.209 --> 00:05:23.219 
information for foreground and

00:05:23.219 --> 00:05:25.879 
information for foreground and
background<00:05:23.959> after<00:05:24.959> marking<00:05:25.229> both<00:05:25.589> of<00:05:25.800> the

00:05:25.879 --> 00:05:25.889 
background after marking both of the

00:05:25.889 --> 00:05:28.129 
background after marking both of the
questions<00:05:26.329> respondents<00:05:27.329> had<00:05:27.479> to<00:05:27.599> click<00:05:27.809> Next

00:05:28.129 --> 00:05:28.139 
questions respondents had to click Next

00:05:28.139 --> 00:05:36.239 
questions respondents had to click Next
to<00:05:28.229> go<00:05:28.379> to<00:05:28.439> the<00:05:28.619> next<00:05:28.800> image

00:05:36.239 --> 00:05:36.249 

00:05:36.249 --> 00:05:38.309 

you

