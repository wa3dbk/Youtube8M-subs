WEBVTT
Kind: captions
Language: en

00:00:07.630 --> 00:00:11.049 

hi<00:00:08.630> I'm<00:00:09.140> Judd<00:00:09.620> Heep<00:00:09.800> a<00:00:10.040> strategic<00:00:10.700> marketing

00:00:11.049 --> 00:00:11.059 
hi I'm Judd Heep a strategic marketing

00:00:11.059 --> 00:00:13.000 
hi I'm Judd Heep a strategic marketing
manager<00:00:11.450> for<00:00:11.750> the<00:00:11.840> industrial<00:00:12.350> business<00:00:12.710> unit

00:00:13.000 --> 00:00:13.010 
manager for the industrial business unit

00:00:13.010 --> 00:00:15.610 
manager for the industrial business unit
here<00:00:13.190> at<00:00:13.309> altaira<00:00:13.809> while<00:00:14.809> CMOS<00:00:15.170> sensors<00:00:15.500> have

00:00:15.610 --> 00:00:15.620 
here at altaira while CMOS sensors have

00:00:15.620 --> 00:00:16.570 
here at altaira while CMOS sensors have
been<00:00:15.710> around<00:00:15.950> for<00:00:16.220> years

00:00:16.570 --> 00:00:16.580 
been around for years

00:00:16.580 --> 00:00:18.820 
been around for years
versatile<00:00:17.420> high-definition<00:00:18.410> wide<00:00:18.619> dynamic

00:00:18.820 --> 00:00:18.830 
versatile high-definition wide dynamic

00:00:18.830 --> 00:00:22.179 
versatile high-definition wide dynamic
range<00:00:19.279> or<00:00:19.580> wdr<00:00:20.390> CMOS<00:00:21.110> image<00:00:21.410> sensors<00:00:21.800> are<00:00:22.040> now

00:00:22.179 --> 00:00:22.189 
range or wdr CMOS image sensors are now

00:00:22.189 --> 00:00:24.010 
range or wdr CMOS image sensors are now
being<00:00:22.430> introduced<00:00:22.939> to<00:00:23.029> the<00:00:23.180> market<00:00:23.300> by

00:00:24.010 --> 00:00:24.020 
being introduced to the market by

00:00:24.020 --> 00:00:26.019 
being introduced to the market by
familiar<00:00:24.410> names<00:00:24.590> like<00:00:24.829> app<00:00:25.009> Tina<00:00:25.279> &amp;<00:00:25.550> Alta

00:00:26.019 --> 00:00:26.029 
familiar names like app Tina &amp; Alta

00:00:26.029 --> 00:00:28.630 
familiar names like app Tina &amp; Alta
since<00:00:26.349> these<00:00:27.349> types<00:00:27.649> of<00:00:27.770> image<00:00:27.980> sensors<00:00:28.340> can

00:00:28.630 --> 00:00:28.640 
since these types of image sensors can

00:00:28.640 --> 00:00:30.970 
since these types of image sensors can
capture<00:00:28.939> and<00:00:29.300> produce<00:00:29.750> a<00:00:29.989> vast<00:00:30.529> range<00:00:30.800> of

00:00:30.970 --> 00:00:30.980 
capture and produce a vast range of

00:00:30.980 --> 00:00:32.830 
capture and produce a vast range of
image<00:00:31.250> brightness<00:00:31.489> levels<00:00:31.939> simultaneously

00:00:32.830 --> 00:00:32.840 
image brightness levels simultaneously

00:00:32.840 --> 00:00:35.229 
image brightness levels simultaneously
from<00:00:33.590> the<00:00:33.649> ultra<00:00:34.040> dark<00:00:34.160> detail<00:00:34.670> and<00:00:34.850> shadows

00:00:35.229 --> 00:00:35.239 
from the ultra dark detail and shadows

00:00:35.239 --> 00:00:37.660 
from the ultra dark detail and shadows
to<00:00:35.870> the<00:00:35.899> elusive<00:00:36.410> super<00:00:36.770> bright<00:00:36.980> nuances<00:00:37.550> in

00:00:37.660 --> 00:00:37.670 
to the elusive super bright nuances in

00:00:37.670 --> 00:00:40.750 
to the elusive super bright nuances in
direct<00:00:37.940> sunlight<00:00:38.649> this<00:00:39.649> powerful<00:00:40.010> capability

00:00:40.750 --> 00:00:40.760 
direct sunlight this powerful capability

00:00:40.760 --> 00:00:43.750 
direct sunlight this powerful capability
makes<00:00:41.390> wdr<00:00:42.079> CMOS<00:00:42.620> sensors<00:00:43.039> ideal<00:00:43.460> for

00:00:43.750 --> 00:00:43.760 
makes wdr CMOS sensors ideal for

00:00:43.760 --> 00:00:45.220 
makes wdr CMOS sensors ideal for
applications<00:00:43.850> such<00:00:44.570> as<00:00:44.780> surveillance

00:00:45.220 --> 00:00:45.230 
applications such as surveillance

00:00:45.230 --> 00:00:47.829 
applications such as surveillance
cameras<00:00:45.739> and<00:00:46.609> because<00:00:47.059> these<00:00:47.210> sensors<00:00:47.570> lack

00:00:47.829 --> 00:00:47.839 
cameras and because these sensors lack

00:00:47.839 --> 00:00:49.840 
cameras and because these sensors lack
an<00:00:47.989> image<00:00:48.230> pipeline<00:00:48.679> and<00:00:48.949> demand<00:00:49.670> high

00:00:49.840 --> 00:00:49.850 
an image pipeline and demand high

00:00:49.850 --> 00:00:52.389 
an image pipeline and demand high
amounts<00:00:50.210> of<00:00:50.300> bandwidth<00:00:50.890> FPGAs<00:00:51.890> provide<00:00:52.280> an

00:00:52.389 --> 00:00:52.399 
amounts of bandwidth FPGAs provide an

00:00:52.399 --> 00:00:56.110 
amounts of bandwidth FPGAs provide an
ideal<00:00:52.550> technology<00:00:53.089> platform<00:00:53.920> with<00:00:54.920> FPGAs<00:00:55.609> the

00:00:56.110 --> 00:00:56.120 
ideal technology platform with FPGAs the

00:00:56.120 --> 00:00:57.700 
ideal technology platform with FPGAs the
sensors<00:00:56.480> will<00:00:56.600> be<00:00:56.690> equipped<00:00:56.989> to<00:00:57.199> handle<00:00:57.440> the

00:00:57.700 --> 00:00:57.710 
sensors will be equipped to handle the

00:00:57.710 --> 00:01:00.040 
sensors will be equipped to handle the
intense<00:00:58.309> number<00:00:58.670> crunching<00:00:58.969> algorithms<00:00:59.480> that

00:01:00.040 --> 00:01:00.050 
intense number crunching algorithms that

00:01:00.050 --> 00:01:02.079 
intense number crunching algorithms that
transform<00:01:00.649> the<00:01:00.769> vast<00:01:01.010> amount<00:01:01.370> of<00:01:01.460> raw<00:01:01.730> image

00:01:02.079 --> 00:01:02.089 
transform the vast amount of raw image

00:01:02.089 --> 00:01:04.119 
transform the vast amount of raw image
data<00:01:02.300> into<00:01:02.989> a<00:01:03.019> standard<00:01:03.469> digital<00:01:03.710> video

00:01:04.119 --> 00:01:04.129 
data into a standard digital video

00:01:04.129 --> 00:01:07.330 
data into a standard digital video
output<00:01:04.610> that<00:01:05.150> DSP<00:01:05.750> or<00:01:05.930> ASSP<00:01:06.530> based<00:01:06.980> encoder

00:01:07.330 --> 00:01:07.340 
output that DSP or ASSP based encoder

00:01:07.340 --> 00:01:10.300 
output that DSP or ASSP based encoder
devices<00:01:07.820> can<00:01:08.300> then<00:01:08.450> manage<00:01:09.040> we'll<00:01:10.040> give<00:01:10.190> you<00:01:10.280> a

00:01:10.300 --> 00:01:10.310 
devices can then manage we'll give you a

00:01:10.310 --> 00:01:12.069 
devices can then manage we'll give you a
glimpse<00:01:10.640> of<00:01:10.700> how<00:01:10.850> all<00:01:11.030> this<00:01:11.150> works<00:01:11.330> today<00:01:11.659> in

00:01:12.069 --> 00:01:12.079 
glimpse of how all this works today in

00:01:12.079 --> 00:01:14.920 
glimpse of how all this works today in
this<00:01:12.860> video<00:01:13.009> we'll<00:01:13.729> show<00:01:13.759> you<00:01:13.939> a<00:01:14.060> demo<00:01:14.450> using

00:01:14.920 --> 00:01:14.930 
this video we'll show you a demo using

00:01:14.930 --> 00:01:18.969 
this video we'll show you a demo using
the<00:01:15.020> app<00:01:15.140> Tina<00:01:15.409> mt9<00:01:16.250> mo3<00:01:17.000> 3<00:01:17.630> which<00:01:18.380> is<00:01:18.500> a<00:01:18.530> 1/3

00:01:18.969 --> 00:01:18.979 
the app Tina mt9 mo3 3 which is a 1/3

00:01:18.979 --> 00:01:23.219 
the app Tina mt9 mo3 3 which is a 1/3
inch<00:01:19.220> 720p<00:01:20.149> 60<00:01:21.159> wdr<00:01:22.159> CMOS<00:01:22.670> image<00:01:23.030> sensor

00:01:23.219 --> 00:01:23.229 
inch 720p 60 wdr CMOS image sensor

00:01:23.229 --> 00:01:25.330 
inch 720p 60 wdr CMOS image sensor
targeted<00:01:24.229> for<00:01:24.439> use<00:01:24.590> in<00:01:24.860> a<00:01:25.040> surveillance

00:01:25.330 --> 00:01:25.340 
targeted for use in a surveillance

00:01:25.340 --> 00:01:27.880 
targeted for use in a surveillance
camera<00:01:25.549> market<00:01:26.090> and<00:01:26.299> the<00:01:26.810> cyclone<00:01:27.140> 3<00:01:27.439> fpga

00:01:27.880 --> 00:01:27.890 
camera market and the cyclone 3 fpga

00:01:27.890 --> 00:01:30.880 
camera market and the cyclone 3 fpga
development<00:01:28.369> kit<00:01:28.869> you'll<00:01:29.869> see<00:01:30.079> how<00:01:30.200> this<00:01:30.320> FPGA

00:01:30.880 --> 00:01:30.890 
development kit you'll see how this FPGA

00:01:30.890 --> 00:01:33.670 
development kit you'll see how this FPGA
based<00:01:31.280> platform<00:01:31.909> easily<00:01:32.750> performs<00:01:33.170> complex

00:01:33.670 --> 00:01:33.680 
based platform easily performs complex

00:01:33.680 --> 00:01:35.830 
based platform easily performs complex
image<00:01:33.920> processing<00:01:34.340> before<00:01:35.210> we<00:01:35.450> get<00:01:35.540> started

00:01:35.830 --> 00:01:35.840 
image processing before we get started

00:01:35.840 --> 00:01:37.330 
image processing before we get started
with<00:01:35.930> our<00:01:36.079> demo<00:01:36.439> let's<00:01:36.740> take<00:01:36.890> a<00:01:36.920> moment<00:01:37.130> to

00:01:37.330 --> 00:01:37.340 
with our demo let's take a moment to

00:01:37.340 --> 00:01:39.100 
with our demo let's take a moment to
talk<00:01:37.490> about<00:01:37.789> the<00:01:37.939> technology<00:01:38.240> requirements

00:01:39.100 --> 00:01:39.110 
talk about the technology requirements

00:01:39.110 --> 00:01:42.819 
talk about the technology requirements
of<00:01:39.229> wdr<00:01:40.100> CMOS<00:01:40.549> sensors<00:01:41.259> not<00:01:42.259> having<00:01:42.560> an<00:01:42.649> image

00:01:42.819 --> 00:01:42.829 
of wdr CMOS sensors not having an image

00:01:42.829 --> 00:01:44.920 
of wdr CMOS sensors not having an image
pipeline<00:01:43.310> means<00:01:43.579> that<00:01:43.729> today's<00:01:44.060> CMOS<00:01:44.509> sensors

00:01:44.920 --> 00:01:44.930 
pipeline means that today's CMOS sensors

00:01:44.930 --> 00:01:47.200 
pipeline means that today's CMOS sensors
lack<00:01:45.229> intelligence<00:01:45.590> on<00:01:46.070> chip<00:01:46.369> to<00:01:46.939> handle

00:01:47.200 --> 00:01:47.210 
lack intelligence on chip to handle

00:01:47.210 --> 00:01:49.060 
lack intelligence on chip to handle
functions<00:01:47.630> like<00:01:47.810> auto<00:01:48.020> exposure<00:01:48.409> or<00:01:48.799> auto

00:01:49.060 --> 00:01:49.070 
functions like auto exposure or auto

00:01:49.070 --> 00:01:51.730 
functions like auto exposure or auto
white<00:01:49.310> balancing<00:01:50.140> these<00:01:51.140> sensors<00:01:51.530> also

00:01:51.730 --> 00:01:51.740 
white balancing these sensors also

00:01:51.740 --> 00:01:53.859 
white balancing these sensors also
output<00:01:52.039> raw<00:01:52.340> image<00:01:52.609> data<00:01:52.850> at<00:01:53.090> up<00:01:53.270> to<00:01:53.390> 20<00:01:53.689> bits

00:01:53.859 --> 00:01:53.869 
output raw image data at up to 20 bits

00:01:53.869 --> 00:01:56.319 
output raw image data at up to 20 bits
per<00:01:54.140> color<00:01:54.289> per<00:01:54.649> pixel<00:01:54.890> now<00:01:55.850> multiply<00:01:56.270> this

00:01:56.319 --> 00:01:56.329 
per color per pixel now multiply this

00:01:56.329 --> 00:01:58.060 
per color per pixel now multiply this
bit<00:01:56.689> depth<00:01:56.930> by<00:01:57.259> the<00:01:57.320> resolution<00:01:57.619> of<00:01:57.979> the

00:01:58.060 --> 00:01:58.070 
bit depth by the resolution of the

00:01:58.070 --> 00:02:00.310 
bit depth by the resolution of the
sensor<00:01:58.430> and<00:01:58.609> the<00:01:59.390> frame<00:01:59.630> rate<00:01:59.659> these<00:02:00.020> sensors

00:02:00.310 --> 00:02:00.320 
sensor and the frame rate these sensors

00:02:00.320 --> 00:02:02.260 
sensor and the frame rate these sensors
are<00:02:00.380> capable<00:02:00.740> of<00:02:00.829> outputting<00:02:01.189> and<00:02:01.520> you<00:02:02.119> get<00:02:02.240> a

00:02:02.260 --> 00:02:02.270 
are capable of outputting and you get a

00:02:02.270 --> 00:02:03.550 
are capable of outputting and you get a
huge<00:02:02.539> amount<00:02:02.630> of<00:02:02.869> bandwidth<00:02:03.200> that<00:02:03.439> the

00:02:03.550 --> 00:02:03.560 
huge amount of bandwidth that the

00:02:03.560 --> 00:02:06.120 
huge amount of bandwidth that the
backend<00:02:04.009> encoding<00:02:04.460> electronics<00:02:05.030> must<00:02:05.270> handle

00:02:06.120 --> 00:02:06.130 
backend encoding electronics must handle

00:02:06.130 --> 00:02:08.350 
backend encoding electronics must handle
this<00:02:07.130> is<00:02:07.280> why<00:02:07.399> these<00:02:07.609> sensors<00:02:07.969> cannot<00:02:08.210> be

00:02:08.350 --> 00:02:08.360 
this is why these sensors cannot be

00:02:08.360 --> 00:02:11.050 
this is why these sensors cannot be
directly<00:02:08.570> connected<00:02:09.229> to<00:02:09.380> the<00:02:09.530> a<00:02:09.619> SSPs<00:02:10.250> or<00:02:10.460> DSP

00:02:11.050 --> 00:02:11.060 
directly connected to the a SSPs or DSP

00:02:11.060 --> 00:02:12.790 
directly connected to the a SSPs or DSP
devices<00:02:11.660> commonly<00:02:12.140> used<00:02:12.560> in<00:02:12.710> today's

00:02:12.790 --> 00:02:12.800 
devices commonly used in today's

00:02:12.800 --> 00:02:15.850 
devices commonly used in today's
surveillance<00:02:13.400> cameras<00:02:13.790> for<00:02:14.750> today's<00:02:15.020> demo<00:02:15.410> we

00:02:15.850 --> 00:02:15.860 
surveillance cameras for today's demo we

00:02:15.860 --> 00:02:18.160 
surveillance cameras for today's demo we
have<00:02:15.950> the<00:02:16.070> cyclone<00:02:16.490> 3<00:02:16.970> FPGA<00:02:17.510> development<00:02:18.020> kit

00:02:18.160 --> 00:02:18.170 
have the cyclone 3 FPGA development kit

00:02:18.170 --> 00:02:19.810 
have the cyclone 3 FPGA development kit
with<00:02:18.410> some<00:02:18.530> additional<00:02:18.920> cards<00:02:19.220> attached<00:02:19.520> on

00:02:19.810 --> 00:02:19.820 
with some additional cards attached on

00:02:19.820 --> 00:02:21.370 
with some additional cards attached on
the<00:02:20.630> left<00:02:20.810> side<00:02:20.930> of<00:02:21.050> the<00:02:21.110> board

00:02:21.370 --> 00:02:21.380 
the left side of the board

00:02:21.380 --> 00:02:23.260 
the left side of the board
we<00:02:21.890> have<00:02:22.010> the<00:02:22.100> vertically<00:02:22.490> mounted<00:02:22.610> app<00:02:23.000> Tina

00:02:23.260 --> 00:02:23.270 
we have the vertically mounted app Tina

00:02:23.270 --> 00:02:26.800 
we have the vertically mounted app Tina
mt9<00:02:24.230> mo3<00:02:24.860> three<00:02:25.430> headboard<00:02:25.880> that<00:02:26.120> connects<00:02:26.690> to

00:02:26.800 --> 00:02:26.810 
mt9 mo3 three headboard that connects to

00:02:26.810 --> 00:02:29.320 
mt9 mo3 three headboard that connects to
a<00:02:26.840> custom-designed<00:02:27.430> adapter<00:02:28.430> card<00:02:28.640> this

00:02:29.320 --> 00:02:29.330 
a custom-designed adapter card this

00:02:29.330 --> 00:02:31.630 
a custom-designed adapter card this
adapter<00:02:29.810> card<00:02:30.020> transposes<00:02:30.710> the<00:02:30.800> sensors<00:02:31.190> iOS

00:02:31.630 --> 00:02:31.640 
adapter card transposes the sensors iOS

00:02:31.640 --> 00:02:34.120 
adapter card transposes the sensors iOS
to<00:02:32.450> the<00:02:32.570> standard<00:02:32.990> altaira<00:02:33.380> HSMC

00:02:34.120 --> 00:02:34.130 
to the standard altaira HSMC

00:02:34.130 --> 00:02:37.180 
to the standard altaira HSMC
configuration<00:02:35.030> on<00:02:35.590> the<00:02:36.590> right<00:02:36.800> side<00:02:37.010> of<00:02:37.130> the

00:02:37.180 --> 00:02:37.190 
configuration on the right side of the

00:02:37.190 --> 00:02:39.880 
configuration on the right side of the
board<00:02:37.400> we<00:02:38.030> have<00:02:38.120> the<00:02:38.150> popular<00:02:38.630> HSMC<00:02:39.200> card<00:02:39.680> from

00:02:39.880 --> 00:02:39.890 
board we have the popular HSMC card from

00:02:39.890 --> 00:02:42.250 
board we have the popular HSMC card from
our<00:02:40.010> partner<00:02:40.400> by<00:02:40.610> tech<00:02:40.880> corporation<00:02:41.540> which

00:02:42.250 --> 00:02:42.260 
our partner by tech corporation which

00:02:42.260 --> 00:02:44.680 
our partner by tech corporation which
provides<00:02:42.680> a<00:02:42.860> DVI<00:02:43.130> output<00:02:43.670> to<00:02:44.090> a<00:02:44.120> flat<00:02:44.420> screen

00:02:44.680 --> 00:02:44.690 
provides a DVI output to a flat screen

00:02:44.690 --> 00:02:48.250 
provides a DVI output to a flat screen
LCD<00:02:44.900> monitor<00:02:45.530> capable<00:02:46.460> of<00:02:46.610> a<00:02:46.670> 720<00:02:47.300> line<00:02:47.510> 60

00:02:48.250 --> 00:02:48.260 
LCD monitor capable of a 720 line 60

00:02:48.260 --> 00:02:50.860 
LCD monitor capable of a 720 line 60
frame<00:02:48.500> per<00:02:48.530> second<00:02:49.130> progressive<00:02:49.610> input<00:02:49.940> in

00:02:50.860 --> 00:02:50.870 
frame per second progressive input in

00:02:50.870 --> 00:02:53.770 
frame per second progressive input in
this<00:02:51.590> system<00:02:51.770> the<00:02:52.460> low-cost<00:02:52.850> low-power

00:02:53.770 --> 00:02:53.780 
this system the low-cost low-power

00:02:53.780 --> 00:02:56.680 
this system the low-cost low-power
cyclone<00:02:54.530> 3<00:02:54.770> FPGA<00:02:55.420> performs<00:02:56.420> all<00:02:56.570> of<00:02:56.600> the

00:02:56.680 --> 00:02:56.690 
cyclone 3 FPGA performs all of the

00:02:56.690 --> 00:02:59.050 
cyclone 3 FPGA performs all of the
system<00:02:57.110> tasks<00:02:57.470> required<00:02:57.830> to<00:02:58.040> transform<00:02:58.610> the

00:02:59.050 --> 00:02:59.060 
system tasks required to transform the

00:02:59.060 --> 00:03:01.210 
system tasks required to transform the
sensors<00:02:59.450> raw<00:02:59.720> image<00:03:00.020> data<00:03:00.230> into<00:03:00.800> the<00:03:00.890> DVI

00:03:01.210 --> 00:03:01.220 
sensors raw image data into the DVI

00:03:01.220 --> 00:03:06.220 
sensors raw image data into the DVI
output<00:03:01.700> format<00:03:03.400> the<00:03:04.400> board<00:03:04.640> cyclone<00:03:05.090> 3<00:03:05.420> EP<00:03:05.810> 3c

00:03:06.220 --> 00:03:06.230 
output format the board cyclone 3 EP 3c

00:03:06.230 --> 00:03:09.880 
output format the board cyclone 3 EP 3c
120<00:03:06.710> fpga<00:03:07.220> is<00:03:07.550> utilized<00:03:08.450> at<00:03:08.720> only<00:03:09.050> one<00:03:09.710> third

00:03:09.880 --> 00:03:09.890 
120 fpga is utilized at only one third

00:03:09.890 --> 00:03:12.370 
120 fpga is utilized at only one third
of<00:03:09.980> its<00:03:10.100> capacity<00:03:10.220> for<00:03:10.700> this<00:03:10.760> application<00:03:11.380> the

00:03:12.370 --> 00:03:12.380 
of its capacity for this application the

00:03:12.380 --> 00:03:14.350 
of its capacity for this application the
design<00:03:12.680> aside<00:03:12.980> the<00:03:13.160> FPGA<00:03:13.640> is<00:03:13.820> provided<00:03:14.210> by<00:03:14.330> a

00:03:14.350 --> 00:03:14.360 
design aside the FPGA is provided by a

00:03:14.360 --> 00:03:16.570 
design aside the FPGA is provided by a
Pakal<00:03:14.780> limited<00:03:15.200> our<00:03:15.680> partner<00:03:16.130> for<00:03:16.310> sensor

00:03:16.570 --> 00:03:16.580 
Pakal limited our partner for sensor

00:03:16.580 --> 00:03:18.870 
Pakal limited our partner for sensor
processing<00:03:16.790> in<00:03:17.300> a<00:03:17.630> surveillance<00:03:17.900> market

00:03:18.870 --> 00:03:18.880 
processing in a surveillance market

00:03:18.880 --> 00:03:21.430 
processing in a surveillance market
apical<00:03:19.880> IP<00:03:20.090> functions<00:03:20.720> implemented<00:03:21.200> in<00:03:21.350> the

00:03:21.430 --> 00:03:21.440 
apical IP functions implemented in the

00:03:21.440 --> 00:03:23.830 
apical IP functions implemented in the
fpga<00:03:21.980> include<00:03:22.910> the<00:03:23.030> full<00:03:23.210> image<00:03:23.480> sensor

00:03:23.830 --> 00:03:23.840 
fpga include the full image sensor

00:03:23.840 --> 00:03:26.650 
fpga include the full image sensor
pipeline<00:03:24.290> or<00:03:24.560> isp<00:03:25.130> d<00:03:25.910> mosaicing<00:03:26.450> of<00:03:26.540> the

00:03:26.650 --> 00:03:26.660 
pipeline or isp d mosaicing of the

00:03:26.660 --> 00:03:29.200 
pipeline or isp d mosaicing of the
sensor<00:03:27.020> local<00:03:27.920> tone<00:03:28.130> mapping<00:03:28.340> a<00:03:28.610> function<00:03:29.120> a

00:03:29.200 --> 00:03:29.210 
sensor local tone mapping a function a

00:03:29.210 --> 00:03:31.630 
sensor local tone mapping a function a
Pakal<00:03:29.540> calls<00:03:29.780> a<00:03:30.020> ridic<00:03:30.320> sand<00:03:30.560> 2d<00:03:31.430> noise

00:03:31.630 --> 00:03:31.640 
Pakal calls a ridic sand 2d noise

00:03:31.640 --> 00:03:33.610 
Pakal calls a ridic sand 2d noise
reduction<00:03:31.910> a<00:03:32.240> function<00:03:32.900> a<00:03:33.020> Pakal<00:03:33.350> calls

00:03:33.610 --> 00:03:33.620 
reduction a function a Pakal calls

00:03:33.620 --> 00:03:36.520 
reduction a function a Pakal calls
center<00:03:34.390> apical<00:03:35.390> has<00:03:35.540> vast<00:03:35.750> experience<00:03:35.900> in<00:03:36.410> the

00:03:36.520 --> 00:03:36.530 
center apical has vast experience in the

00:03:36.530 --> 00:03:38.770 
center apical has vast experience in the
image<00:03:36.710> processing<00:03:36.920> arena<00:03:37.430> with<00:03:38.090> multiple<00:03:38.570> man

00:03:38.770 --> 00:03:38.780 
image processing arena with multiple man

00:03:38.780 --> 00:03:40.180 
image processing arena with multiple man
years<00:03:38.990> of<00:03:39.140> development<00:03:39.560> invested<00:03:40.010> and

00:03:40.180 --> 00:03:40.190 
years of development invested and

00:03:40.190 --> 00:03:42.250 
years of development invested and
several<00:03:40.880> customers<00:03:41.300> that<00:03:41.540> have<00:03:41.660> successfully

00:03:42.250 --> 00:03:42.260 
several customers that have successfully

00:03:42.260 --> 00:03:44.680 
several customers that have successfully
adopted<00:03:42.800> their<00:03:43.010> solutions<00:03:43.490> in<00:03:43.850> consumer<00:03:44.510> and

00:03:44.680 --> 00:03:44.690 
adopted their solutions in consumer and

00:03:44.690 --> 00:03:46.810 
adopted their solutions in consumer and
professional<00:03:44.840> products<00:03:45.640> even<00:03:46.640> among

00:03:46.810 --> 00:03:46.820 
professional products even among

00:03:46.820 --> 00:03:48.490 
professional products even among
companies<00:03:47.060> known<00:03:47.420> for<00:03:47.690> superior<00:03:48.140> imaging

00:03:48.490 --> 00:03:48.500 
companies known for superior imaging

00:03:48.500 --> 00:03:50.470 
companies known for superior imaging
products<00:03:48.920> apical<00:03:49.880> is<00:03:49.970> known<00:03:50.150> for<00:03:50.360> providing

00:03:50.470 --> 00:03:50.480 
products apical is known for providing

00:03:50.480 --> 00:03:52.390 
products apical is known for providing
world-class<00:03:51.050> image<00:03:51.620> and<00:03:51.860> video<00:03:52.220> processing

00:03:52.390 --> 00:03:52.400 
world-class image and video processing

00:03:52.400 --> 00:03:56.020 
world-class image and video processing
IP<00:03:53.680> the<00:03:54.680> configuration<00:03:55.310> flash<00:03:55.520> on<00:03:55.700> this<00:03:55.790> board

00:03:56.020 --> 00:03:56.030 
IP the configuration flash on this board

00:03:56.030 --> 00:03:57.880 
IP the configuration flash on this board
has<00:03:56.120> been<00:03:56.150> pre-programmed<00:03:56.630> with<00:03:57.380> the<00:03:57.530> apical

00:03:57.880 --> 00:03:57.890 
has been pre-programmed with the apical

00:03:57.890 --> 00:04:00.100 
has been pre-programmed with the apical
design<00:03:58.280> so<00:03:59.000> we<00:03:59.120> won't<00:03:59.300> have<00:03:59.390> to<00:03:59.630> download<00:03:59.810> the

00:04:00.100 --> 00:04:00.110 
design so we won't have to download the

00:04:00.110 --> 00:04:02.500 
design so we won't have to download the
configuration<00:04:00.260> via<00:04:00.950> a<00:04:01.010> USB<00:04:01.250> cable<00:04:01.850> we<00:04:02.360> can

00:04:02.500 --> 00:04:02.510 
configuration via a USB cable we can

00:04:02.510 --> 00:04:05.290 
configuration via a USB cable we can
simply<00:04:02.810> turn<00:04:02.990> on<00:04:03.020> the<00:04:03.140> board<00:04:03.470> and<00:04:03.970> the<00:04:04.970> cyclone

00:04:05.290 --> 00:04:05.300 
simply turn on the board and the cyclone

00:04:05.300 --> 00:04:07.480 
simply turn on the board and the cyclone
3<00:04:05.630> FPGA<00:04:06.140> loads<00:04:06.620> apik<00:04:06.980> Al's<00:04:07.130> design

00:04:07.480 --> 00:04:07.490 
3 FPGA loads apik Al's design

00:04:07.490 --> 00:04:09.430 
3 FPGA loads apik Al's design
automatically<00:04:08.270> we're<00:04:08.900> going<00:04:09.050> to<00:04:09.110> take<00:04:09.290> our

00:04:09.430 --> 00:04:09.440 
automatically we're going to take our

00:04:09.440 --> 00:04:11.410 
automatically we're going to take our
demo<00:04:09.740> setup<00:04:10.010> and<00:04:10.250> point<00:04:10.970> it<00:04:11.090> towards<00:04:11.330> the

00:04:11.410 --> 00:04:11.420 
demo setup and point it towards the

00:04:11.420 --> 00:04:12.940 
demo setup and point it towards the
window<00:04:11.690> where<00:04:11.870> my<00:04:11.960> colleague<00:04:12.380> Rashmi<00:04:12.800> is

00:04:12.940 --> 00:04:12.950 
window where my colleague Rashmi is

00:04:12.950 --> 00:04:20.050 
window where my colleague Rashmi is
standing

00:04:20.050 --> 00:04:20.060 

00:04:20.060 --> 00:04:21.879 

now<00:04:20.660> that<00:04:20.840> the<00:04:20.930> board<00:04:21.109> is<00:04:21.170> on<00:04:21.320> let's<00:04:21.709> take<00:04:21.829> a

00:04:21.879 --> 00:04:21.889 
now that the board is on let's take a

00:04:21.889 --> 00:04:24.340 
now that the board is on let's take a
look<00:04:22.130> at<00:04:22.220> the<00:04:22.310> image<00:04:22.580> on<00:04:22.730> the<00:04:22.790> screen<00:04:23.350> we're

00:04:24.340 --> 00:04:24.350 
look at the image on the screen we're

00:04:24.350 --> 00:04:25.629 
look at the image on the screen we're
going<00:04:24.530> to<00:04:24.620> show<00:04:24.770> you<00:04:24.830> the<00:04:25.010> image<00:04:25.160> in<00:04:25.370> linear

00:04:25.629 --> 00:04:25.639 
going to show you the image in linear

00:04:25.639 --> 00:04:27.970 
going to show you the image in linear
mode<00:04:25.850> first<00:04:26.150> as<00:04:26.480> you<00:04:27.020> can<00:04:27.170> see<00:04:27.350> this<00:04:27.500> image<00:04:27.830> is

00:04:27.970 --> 00:04:27.980 
mode first as you can see this image is

00:04:27.980 --> 00:04:30.190 
mode first as you can see this image is
similar<00:04:28.520> to<00:04:28.760> what's<00:04:29.480> produced<00:04:29.870> by<00:04:30.050> any

00:04:30.190 --> 00:04:30.200 
similar to what's produced by any

00:04:30.200 --> 00:04:31.600 
similar to what's produced by any
standard<00:04:30.620> video<00:04:30.740> camera<00:04:30.889> on<00:04:31.310> the<00:04:31.430> market

00:04:31.600 --> 00:04:31.610 
standard video camera on the market

00:04:31.610 --> 00:04:34.090 
standard video camera on the market
today<00:04:31.910> we<00:04:32.810> can<00:04:32.930> see<00:04:33.080> details<00:04:33.290> in<00:04:33.710> the<00:04:33.800> darker

00:04:34.090 --> 00:04:34.100 
today we can see details in the darker

00:04:34.100 --> 00:04:36.250 
today we can see details in the darker
areas<00:04:34.430> of<00:04:34.460> the<00:04:34.669> scene<00:04:34.910> but<00:04:35.540> the<00:04:35.690> bright<00:04:35.900> areas

00:04:36.250 --> 00:04:36.260 
areas of the scene but the bright areas

00:04:36.260 --> 00:04:38.470 
areas of the scene but the bright areas
like<00:04:36.410> the<00:04:36.530> details<00:04:36.889> outside<00:04:37.400> are<00:04:37.820> blown<00:04:38.300> out

00:04:38.470 --> 00:04:38.480 
like the details outside are blown out

00:04:38.480 --> 00:04:41.770 
like the details outside are blown out
or<00:04:38.510> oversaturated<00:04:39.500> in<00:04:40.430> this<00:04:40.669> mode<00:04:40.940> the<00:04:41.180> CMOS

00:04:41.770 --> 00:04:41.780 
or oversaturated in this mode the CMOS

00:04:41.780 --> 00:04:43.300 
or oversaturated in this mode the CMOS
sensor<00:04:42.080> does<00:04:42.230> not<00:04:42.380> output<00:04:42.620> the<00:04:43.010> amount<00:04:43.250> of

00:04:43.300 --> 00:04:43.310 
sensor does not output the amount of

00:04:43.310 --> 00:04:46.150 
sensor does not output the amount of
bits<00:04:43.550> per<00:04:43.639> pixel<00:04:43.760> or<00:04:44.360> dynamic<00:04:44.960> range<00:04:45.230> capable

00:04:46.150 --> 00:04:46.160 
bits per pixel or dynamic range capable

00:04:46.160 --> 00:04:48.040 
bits per pixel or dynamic range capable
of<00:04:46.250> displaying<00:04:46.490> details<00:04:47.000> in<00:04:47.240> both<00:04:47.570> the<00:04:47.840> dark

00:04:48.040 --> 00:04:48.050 
of displaying details in both the dark

00:04:48.050 --> 00:04:50.860 
of displaying details in both the dark
and<00:04:48.290> bright<00:04:48.710> areas<00:04:49.100> simultaneously<00:04:49.720> we<00:04:50.720> can

00:04:50.860 --> 00:04:50.870 
and bright areas simultaneously we can

00:04:50.870 --> 00:04:52.630 
and bright areas simultaneously we can
choose<00:04:51.110> to<00:04:51.200> produce<00:04:51.500> details<00:04:51.889> in<00:04:52.070> one<00:04:52.220> area<00:04:52.490> or

00:04:52.630 --> 00:04:52.640 
choose to produce details in one area or

00:04:52.640 --> 00:05:04.710 
choose to produce details in one area or
another<00:04:52.760> by<00:04:53.510> changing<00:04:53.960> the<00:04:54.020> lens<00:04:54.200> iris

00:05:04.710 --> 00:05:04.720 

00:05:04.720 --> 00:05:07.450 

however<00:05:05.720> it's<00:05:06.380> impossible<00:05:06.710> to<00:05:07.070> properly

00:05:07.450 --> 00:05:07.460 
however it's impossible to properly

00:05:07.460 --> 00:05:09.850 
however it's impossible to properly
reproduce<00:05:08.060> details<00:05:08.540> in<00:05:08.750> both<00:05:09.080> areas<00:05:09.410> unless

00:05:09.850 --> 00:05:09.860 
reproduce details in both areas unless

00:05:09.860 --> 00:05:12.280 
reproduce details in both areas unless
we<00:05:10.340> enable<00:05:10.700> the<00:05:10.820> wdr<00:05:11.330> capability<00:05:12.020> of<00:05:12.169> the

00:05:12.280 --> 00:05:12.290 
we enable the wdr capability of the

00:05:12.290 --> 00:05:13.770 
we enable the wdr capability of the
sensor<00:05:12.650> and<00:05:12.830> the<00:05:13.130> FPGA

00:05:13.770 --> 00:05:13.780 
sensor and the FPGA

00:05:13.780 --> 00:05:16.450 
sensor and the FPGA
let's<00:05:14.780> reconfigure<00:05:15.260> the<00:05:15.410> FPGA<00:05:15.860> to<00:05:15.979> place<00:05:16.280> the

00:05:16.450 --> 00:05:16.460 
let's reconfigure the FPGA to place the

00:05:16.460 --> 00:05:18.790 
let's reconfigure the FPGA to place the
sensor<00:05:16.820> in<00:05:16.970> wdr<00:05:17.570> mode<00:05:17.810> instead<00:05:18.530> of<00:05:18.650> linear

00:05:18.790 --> 00:05:18.800 
sensor in wdr mode instead of linear

00:05:18.800 --> 00:05:33.049 
sensor in wdr mode instead of linear
mode

00:05:33.049 --> 00:05:33.059 

00:05:33.059 --> 00:05:35.879 

now<00:05:34.059> we<00:05:34.119> can<00:05:34.360> see<00:05:34.479> the<00:05:34.599> impact<00:05:34.930> the<00:05:35.139> wdr<00:05:35.680> mode

00:05:35.879 --> 00:05:35.889 
now we can see the impact the wdr mode

00:05:35.889 --> 00:05:38.010 
now we can see the impact the wdr mode
has<00:05:36.159> on<00:05:36.369> image<00:05:36.610> quality<00:05:36.849> we<00:05:37.719> can<00:05:37.869> see

00:05:38.010 --> 00:05:38.020 
has on image quality we can see

00:05:38.020 --> 00:05:39.540 
has on image quality we can see
highlights<00:05:38.439> in<00:05:38.710> the<00:05:38.830> bright<00:05:39.009> areas<00:05:39.339> outside

00:05:39.540 --> 00:05:39.550 
highlights in the bright areas outside

00:05:39.550 --> 00:05:42.299 
highlights in the bright areas outside
such<00:05:40.479> as<00:05:40.629> the<00:05:40.749> details<00:05:41.139> and<00:05:41.319> the<00:05:41.409> clouds<00:05:41.680> trees

00:05:42.299 --> 00:05:42.309 
such as the details and the clouds trees

00:05:42.309 --> 00:05:44.909 
such as the details and the clouds trees
and<00:05:42.580> buildings<00:05:43.059> at<00:05:43.719> the<00:05:43.809> same<00:05:44.080> time<00:05:44.349> details

00:05:44.909 --> 00:05:44.919 
and buildings at the same time details

00:05:44.919 --> 00:05:47.010 
and buildings at the same time details
inside<00:05:45.369> the<00:05:45.520> office<00:05:45.879> such<00:05:46.330> as<00:05:46.449> my<00:05:46.599> colleague

00:05:47.010 --> 00:05:47.020 
inside the office such as my colleague

00:05:47.020 --> 00:05:49.049 
inside the office such as my colleague
Rashmi<00:05:47.469> standing<00:05:48.369> in<00:05:48.460> front<00:05:48.520> of<00:05:48.639> the<00:05:48.729> window

00:05:49.049 --> 00:05:49.059 
Rashmi standing in front of the window

00:05:49.059 --> 00:05:51.420 
Rashmi standing in front of the window
are<00:05:49.270> also<00:05:49.509> visible<00:05:49.839> this<00:05:50.830> shows<00:05:51.069> the<00:05:51.249> vast

00:05:51.420 --> 00:05:51.430 
are also visible this shows the vast

00:05:51.430 --> 00:05:53.399 
are also visible this shows the vast
dynamic<00:05:51.909> range<00:05:52.119> of<00:05:52.270> the<00:05:52.330> app<00:05:52.539> Tina<00:05:52.779> sensor<00:05:53.199> and

00:05:53.399 --> 00:05:53.409 
dynamic range of the app Tina sensor and

00:05:53.409 --> 00:05:55.379 
dynamic range of the app Tina sensor and
highlights<00:05:54.099> the<00:05:54.309> depth<00:05:54.520> of<00:05:54.669> image<00:05:54.939> processing

00:05:55.379 --> 00:05:55.389 
highlights the depth of image processing

00:05:55.389 --> 00:05:58.409 
highlights the depth of image processing
that<00:05:55.569> a<00:05:55.629> Pakal<00:05:56.050> provides<00:05:56.969> you've<00:05:57.969> now<00:05:58.149> seen

00:05:58.409 --> 00:05:58.419 
that a Pakal provides you've now seen

00:05:58.419 --> 00:06:01.170 
that a Pakal provides you've now seen
how<00:05:58.479> easily<00:05:58.839> you<00:05:59.349> can<00:05:59.379> incorporate<00:05:59.770> new<00:06:00.369> wdr

00:06:01.170 --> 00:06:01.180 
how easily you can incorporate new wdr

00:06:01.180 --> 00:06:03.239 
how easily you can incorporate new wdr
CMOS<00:06:01.659> image<00:06:01.960> sensors<00:06:02.349> into<00:06:02.889> your<00:06:03.009> camera

00:06:03.239 --> 00:06:03.249 
CMOS image sensors into your camera

00:06:03.249 --> 00:06:05.339 
CMOS image sensors into your camera
designs<00:06:03.639> by<00:06:04.029> using<00:06:04.180> a<00:06:04.330> low-power<00:06:04.689> low-cost

00:06:05.339 --> 00:06:05.349 
designs by using a low-power low-cost

00:06:05.349 --> 00:06:09.629 
designs by using a low-power low-cost
cyclone<00:06:06.129> 3<00:06:06.430> FPGA<00:06:07.379> the<00:06:08.379> FPGA<00:06:08.860> provides<00:06:09.219> support

00:06:09.629 --> 00:06:09.639 
cyclone 3 FPGA the FPGA provides support

00:06:09.639 --> 00:06:11.510 
cyclone 3 FPGA the FPGA provides support
from<00:06:09.759> image<00:06:09.999> capture<00:06:10.419> through<00:06:10.779> image<00:06:11.110> display

00:06:11.510 --> 00:06:11.520 
from image capture through image display

00:06:11.520 --> 00:06:14.459 
from image capture through image display
and<00:06:12.520> with<00:06:12.639> the<00:06:12.759> apical<00:06:13.089> IP<00:06:13.419> core<00:06:13.629> you<00:06:14.020> get<00:06:14.259> in

00:06:14.459 --> 00:06:14.469 
and with the apical IP core you get in

00:06:14.469 --> 00:06:16.920 
and with the apical IP core you get in
the<00:06:14.589> FPGA<00:06:15.039> the<00:06:15.759> entire<00:06:16.149> image<00:06:16.479> processing

00:06:16.920 --> 00:06:16.930 
the FPGA the entire image processing

00:06:16.930 --> 00:06:18.959 
the FPGA the entire image processing
pipeline<00:06:17.409> as<00:06:17.649> well<00:06:18.069> as<00:06:18.339> the<00:06:18.460> timing<00:06:18.699> and

00:06:18.959 --> 00:06:18.969 
pipeline as well as the timing and

00:06:18.969 --> 00:06:20.939 
pipeline as well as the timing and
control<00:06:19.180> to<00:06:19.599> drive<00:06:19.779> out<00:06:19.990> to<00:06:20.620> an<00:06:20.710> external

00:06:20.939 --> 00:06:20.949 
control to drive out to an external

00:06:20.949 --> 00:06:24.179 
control to drive out to an external
monitor<00:06:21.099> with<00:06:21.699> a<00:06:21.729> DVI<00:06:22.059> input<00:06:22.830> if<00:06:23.830> you're<00:06:24.039> ready

00:06:24.179 --> 00:06:24.189 
monitor with a DVI input if you're ready

00:06:24.189 --> 00:06:26.730 
monitor with a DVI input if you're ready
to<00:06:24.309> get<00:06:24.399> started<00:06:24.520> with<00:06:25.029> your<00:06:25.149> own<00:06:25.209> FPGA<00:06:25.990> based

00:06:26.730 --> 00:06:26.740 
to get started with your own FPGA based

00:06:26.740 --> 00:06:29.459 
to get started with your own FPGA based
wdr<00:06:27.520> CMOS<00:06:27.909> sensor<00:06:28.300> video<00:06:28.599> processing<00:06:29.139> design

00:06:29.459 --> 00:06:29.469 
wdr CMOS sensor video processing design

00:06:29.469 --> 00:06:32.309 
wdr CMOS sensor video processing design
go<00:06:30.189> to<00:06:30.249> altair<00:06:30.789> accom<00:06:31.270> slash<00:06:31.719> surveillance

00:06:32.309 --> 00:06:32.319 
go to altair accom slash surveillance

00:06:32.319 --> 00:06:34.170 
go to altair accom slash surveillance
where<00:06:33.099> you'll<00:06:33.219> find<00:06:33.399> more<00:06:33.580> information<00:06:34.089> about

00:06:34.170 --> 00:06:34.180 
where you'll find more information about

00:06:34.180 --> 00:06:37.199 
where you'll find more information about
the<00:06:34.509> solution<00:06:34.930> we<00:06:35.080> demonstrated<00:06:35.649> today<00:06:36.209> you

00:06:37.199 --> 00:06:37.209 
the solution we demonstrated today you

00:06:37.209 --> 00:06:38.850 
the solution we demonstrated today you
can<00:06:37.360> also<00:06:37.509> contact<00:06:37.839> your<00:06:38.169> local<00:06:38.229> altaira

00:06:38.850 --> 00:06:38.860 
can also contact your local altaira

00:06:38.860 --> 00:06:41.010 
can also contact your local altaira
sales<00:06:39.129> representative<00:06:39.729> for<00:06:39.909> a<00:06:40.240> live<00:06:40.479> demo<00:06:40.809> or

00:06:41.010 --> 00:06:41.020 
sales representative for a live demo or

00:06:41.020 --> 00:06:43.110 
sales representative for a live demo or
evaluation<00:06:41.860> of<00:06:42.039> our<00:06:42.580> image<00:06:42.819> sensor

00:06:43.110 --> 00:06:43.120 
evaluation of our image sensor

00:06:43.120 --> 00:06:45.709 
evaluation of our image sensor
processing<00:06:43.330> design<00:06:43.870> on<00:06:44.110> the<00:06:44.439> cyclone<00:06:44.649> 3<00:06:45.069> board

00:06:45.709 --> 00:06:45.719 
processing design on the cyclone 3 board

00:06:45.719 --> 00:06:47.969 
processing design on the cyclone 3 board
will<00:06:46.719> also<00:06:46.749> be<00:06:47.050> presenting<00:06:47.439> this<00:06:47.529> demo<00:06:47.830> at

00:06:47.969 --> 00:06:47.979 
will also be presenting this demo at

00:06:47.979 --> 00:06:50.040 
will also be presenting this demo at
upcoming<00:06:48.099> trade<00:06:48.490> shows<00:06:48.759> check<00:06:49.719> out<00:06:49.899> the

00:06:50.040 --> 00:06:50.050 
upcoming trade shows check out the

00:06:50.050 --> 00:06:52.679 
upcoming trade shows check out the
schedule<00:06:50.259> on<00:06:50.559> altaira<00:06:51.039> comm<00:06:51.849> /<00:06:52.180> surveillance

00:06:52.679 --> 00:06:52.689 
schedule on altaira comm / surveillance

00:06:52.689 --> 00:06:55.259 
schedule on altaira comm / surveillance
for<00:06:52.870> details<00:06:53.229> I<00:06:53.789> hope<00:06:54.789> you<00:06:54.909> found<00:06:54.999> today's

00:06:55.259 --> 00:06:55.269 
for details I hope you found today's

00:06:55.269 --> 00:06:57.299 
for details I hope you found today's
demo<00:06:55.569> useful<00:06:55.930> and<00:06:56.050> informative<00:06:56.139> I'm<00:06:56.740> Judd

00:06:57.299 --> 00:06:57.309 
demo useful and informative I'm Judd

00:06:57.309 --> 00:07:00.599 
demo useful and informative I'm Judd
Heep<00:06:57.490> thanks<00:06:58.149> for<00:06:58.269> watching

